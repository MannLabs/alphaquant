{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp ptmsite_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import alphaquant.diffquant_utils as utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "class ModifiedPeptide():\n",
    "    \"\"\"\n",
    "    helper class for convenient access of modified peptide variables\n",
    "    \"\"\"\n",
    "    def __init__(self, input_type, df_line, protein_sequence, modification_type):\n",
    "        if input_type == \"Spectronaut\":\n",
    "            self.init_spectronaut(df_line, protein_sequence,modification_type)\n",
    "        if input_type == \"DIANN\":\n",
    "            self.init_diann(df_line, protein_sequence, modification_type)\n",
    "\n",
    "    def init_spectronaut(self, df_line, protein_sequence, modification_type ):\n",
    "        self.id = df_line[\"IonID\"]\n",
    "        self.ionname = df_line[\"FG.Id\"]\n",
    "        self.sample = df_line[\"R.Label\"]\n",
    "        self.seq = df_line[\"PEP.StrippedSequence\"]\n",
    "        self.prot = df_line[\"PG.UniProtIds\"]\n",
    "        self.start_idx = protein_sequence.find(self.seq)\n",
    "        positions_parsed = np.array(df_line[f\"EG.PTMPositions {modification_type}\"].split(\";\")).astype(\"int\")\n",
    "        probabilities_parsed =  np.array(df_line[f\"EG.PTMProbabilities {modification_type}\"].split(\";\")).astype(\"float\")\n",
    "        self.positions = scale_site_idxs_to_protein(protein_sequence, self.seq, positions_parsed)\n",
    "        self.num_sites = get_num_sites(probabilities_parsed)\n",
    "        self.probabilities = probabilities_parsed\n",
    "        self.encoded_probs = None#encode_probabilities(probabilities_parsed, id_thresh, excl_thresh)\n",
    "\n",
    "    def init_diann(self, df_line, protein_sequence, modification_type):\n",
    "        self.id = df_line[\"IonID\"]\n",
    "        self.ionname = df_line[\"Precursor.Id\"]\n",
    "        self.sample = df_line[\"Run\"]\n",
    "        self.seq = df_line[\"Stripped.Sequence\"]\n",
    "        self.prot = df_line[\"Protein.Ids\"]\n",
    "        self.start_idx = protein_sequence.find(self.seq)\n",
    "        modified_sequence = df_line[\"Modified.Sequence\"]\n",
    "        positions_parsed = retrieve_relative_positions_diann(modification_type, modified_sequence)#digly mod: \"(UniMod:121)\"\n",
    "        probabilities_parsed =  retrieve_probabilities_diann(df_line[\"PTM.Site.Confidence\"])\n",
    "        self.positions = scale_site_idxs_to_protein(protein_sequence, self.seq, positions_parsed)\n",
    "        self.num_sites = get_num_sites(probabilities_parsed)\n",
    "        self.probabilities = probabilities_parsed\n",
    "        self.encoded_probs = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group ions and reduce redundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import copy\n",
    "def merge_samecond_modpeps(ions, sample2cond, id_thresh, excl_thresh):\n",
    "    \"\"\"\n",
    "    identical ions from the same condition are merged and their site localization probabilities are averaged\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    condid2ionids = {}\n",
    "    \n",
    "    condion2modpeps = {}\n",
    "    for ion in ions:\n",
    "        condid = f\"{sample2cond.get(ion.sample)}{ion.ionname}\"\n",
    "        condion2modpeps[condid] = condion2modpeps.get(condid, []) + [ion]\n",
    "        condid2ionids[condid] = condid2ionids.get(condid, []) + [ion.id]\n",
    "    \n",
    "    for condid,modpeps in condion2modpeps.items():\n",
    "        modpep_selected = copy.deepcopy(modpeps[0])\n",
    "        allprobs = [x.probabilities for x in modpeps]\n",
    "        meanprobs = np.mean(allprobs, axis = 0)\n",
    "        modpep_selected.id = condid\n",
    "        modpep_selected.probabilities = meanprobs\n",
    "        modpep_selected.encoded_probs = encode_probabilities(meanprobs, id_thresh, excl_thresh)\n",
    "        res.append(modpep_selected)\n",
    "    return res, condid2ionids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def scale_site_idxs_to_protein(protseq, pepseq, localization_array):\n",
    "    \"\"\"align peptide sequence along protein, express idxs relative to start\"\"\"\n",
    "    start_idx = protseq.find(pepseq)\n",
    "    localization_array = localization_array + start_idx\n",
    "    return localization_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_num_sites(probabilities_parsed):\n",
    "    return round(sum(probabilities_parsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def group_by_nummods_posv(ions):\n",
    "    \"\"\"ions with identical position vector and number of modifications are grouped together\"\"\"\n",
    "    nmod2ions = {}\n",
    "    for ion in ions:\n",
    "        nmodposv = f\"{ion.num_sites}_{ion.positions}\"\n",
    "        nmod2ions[nmodposv] = nmod2ions.get(nmodposv, []) + [ion]\n",
    "    return list(nmod2ions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def condense_ions(ions):\n",
    "    \"\"\"\n",
    "    group ions together, which have identical sequence and encoded probabilities. This way you only need to \n",
    "    compare these in the distance matrix\n",
    "    \"\"\"\n",
    "    key2equivions = {}\n",
    "    for ion in ions:\n",
    "        key = f\"{ion.seq}_{ion.encoded_probs}\"\n",
    "        key2equivions[key] = key2equivions.get(key, []) + [ion]\n",
    "    ion2equiv_ions = {gr_ions[0] : gr_ions for gr_ions in key2equivions.values()}\n",
    "    representative_ions = list(ion2equiv_ions.keys())\n",
    "    return representative_ions, ion2equiv_ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def encode_probabilities(probabilties_parsed, id_thresh, excl_thresh):\n",
    "    prob_copy = probabilties_parsed.copy()\n",
    "    prob_copy[prob_copy>id_thresh] = 5\n",
    "    prob_copy[prob_copy < excl_thresh] = 3\n",
    "    prob_copy[(prob_copy!=3) & (prob_copy!=5)] = 0\n",
    "\n",
    "    return prob_copy.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "import numpy as np\n",
    "def retrieve_relative_positions_diann(modification,modified_sequence):\n",
    "    return np.array([m.start() for m in re.finditer(modification, modified_sequence)])\n",
    "\n",
    "def retrieve_probabilities_diann(localisation_probability):\n",
    "    if not np.isscalar(localisation_probability):\n",
    "        raise ValueError(f\"The case of localisation probability {localisation_probability} in type {type(localisation_probability)} is not yet implemented for DIANN type input!\")\n",
    "    return np.array([localisation_probability])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare and cluster ions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def cluster_ions(ions):\n",
    "    res = []\n",
    "    nmod_posv_grouped = group_by_nummods_posv(ions)\n",
    "    for candidates in nmod_posv_grouped:\n",
    "        if len(candidates)==1: #check if only one ion, then no pairwise comparison needed\n",
    "            res.extend([candidates])\n",
    "            continue\n",
    "        \n",
    "        representative_ions, ion2equiv_ions = condense_ions(candidates) \n",
    "        if len(representative_ions)==1:#check if only one condensed ion, then also no pairwise comparison needed\n",
    "            equiv_ions = ion2equiv_ions.get(representative_ions[0])\n",
    "            res.extend([equiv_ions])\n",
    "            continue\n",
    "\n",
    "        ionclustered = cluster_ions_pairwise(representative_ions) #if multiple ions to compare, do pairwise comparisons\n",
    "        for cluster in ionclustered:\n",
    "            clust_copy = cluster.copy()\n",
    "            for ion in clust_copy:\n",
    "                equiv_ions = ion2equiv_ions.get(ion)\n",
    "                if len(equiv_ions)>1:\n",
    "                    cluster.extend(equiv_ions)\n",
    "        res.extend(ionclustered)\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "\n",
    "def cluster_ions_pairwise(ions):\n",
    "    \"\"\"form complete linkage clusters (every ion is a neighbor to every ion in the cluster) for a given set of ions. Distance matrix define in 'compare ion similarities'\"\"\"\n",
    "    ions.sort(key = lambda x : len(x.seq),reverse = True)\n",
    "    condensed_distance_matrix = compare_ion_similarities(ions)\n",
    "    after_clust = hierarchy.complete(condensed_distance_matrix)\n",
    "    clustered = hierarchy.fcluster(after_clust, 0.1, criterion='distance')\n",
    "    clust2ions = {}\n",
    "    for i in range(len(clustered)):\n",
    "       clustions = clust2ions.get(clustered[i],list())\n",
    "       clustions.append(ions[i])\n",
    "       clust2ions[clustered[i]] = clustions\n",
    "\n",
    "    return list(clust2ions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def compare_ion_similarities(ions):\n",
    "    \"\"\"returns a condensed distance matrix for a given set of ions. Distances are calculated based on the encoded site localization probabilities, as described below\"\"\"\n",
    "    seqs = np.array([x.seq for x in ions])\n",
    "    encoded = np.array([x.encoded_probs for x in ions])\n",
    "    distances = get_condensed_matrix(seqs, encoded)\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_condensed_matrix(seqs, encoded):\n",
    "    \"\"\"checks pairwise occpancy vectors based on the following encoding: 3 == clearly not occupied, 5 == clearly occupied. \n",
    "    If a sum=vec1+vec2 contains 3+5=8, this means it is dissimilar and is assigned distance = 1, distance =0 otherwise\n",
    "    \"\"\"\n",
    "    res = np.zeros(int(len(seqs) * (len(seqs)-1)/2))\n",
    "    count = 0\n",
    "    for i in range(len(seqs)):\n",
    "        for j in range(i+1, len(seqs)):\n",
    "            seq1 = seqs[i]\n",
    "            seq2 = seqs[j]\n",
    "            if seq2 in seq1:\n",
    "                encode1 = encoded[i]\n",
    "                encode2 = encoded[j]\n",
    "                summed = encode1 + encode2\n",
    "                if 8 in summed:\n",
    "                    res[count] = 1\n",
    "            count+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and reformat input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "\n",
    "def read_df_spectronaut_reduce_cols(input_file, modification_type):\n",
    "    relevant_cols = get_relevant_cols_spectronaut(modification_type)\n",
    "    input_df = read_df_reduce_cols(input_file, relevant_cols)\n",
    "    return input_df\n",
    "\n",
    "def read_df_diann_reduce_cols(input_file):\n",
    "    relevant_cols = get_relevant_cols_diann()\n",
    "    input_df = read_df_reduce_cols(input_file, relevant_cols)\n",
    "    return input_df\n",
    "\n",
    "def read_df_reduce_cols(input_file, relevant_cols):\n",
    "    input_df_it = pd.read_csv(input_file, sep = \"\\t\", usecols = relevant_cols, encoding ='latin1', chunksize=1000000)\n",
    "    input_df_list = []\n",
    "    for input_df_subset in input_df_it:\n",
    "        input_df_subset = input_df_subset.drop_duplicates()\n",
    "        input_df_list.append(input_df_subset)\n",
    "    input_df = pd.concat(input_df_list)\n",
    "    return input_df\n",
    "\n",
    "def get_relevant_cols_spectronaut(modification_type):\n",
    "    relevant_cols = list(headers_dicts.get('Spectronaut').values())\n",
    "    relevant_cols = relevant_cols  + [f\"EG.PTMPositions {modification_type}\", f\"EG.PTMProbabilities {modification_type}\"]\n",
    "    return relevant_cols\n",
    "\n",
    "def get_relevant_cols_diann():\n",
    "    relevant_cols = list(headers_dicts.get('DIANN').values())\n",
    "    relevant_cols = relevant_cols  + [\"Modified.Sequence\", \"PTM.Site.Confidence\"]\n",
    "    return relevant_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_idmap_column(protgroups, swissprots):\n",
    "    \"\"\"go through protein groups and map to swissprot ID if possible\"\"\"\n",
    "    res = []\n",
    "    for protgroup in protgroups:\n",
    "        mapped = False\n",
    "        proteins = list(protgroup.split(\";\"))\n",
    "        for protein in proteins:\n",
    "            if protein in swissprots:\n",
    "                res.append(protein)\n",
    "                mapped = True\n",
    "                break\n",
    "        if not mapped:\n",
    "            res.append(proteins[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "def get_site_prob_overview(modpeps, refprot, refgene):\n",
    "    \"\"\"reformats the modified peptide objects for a given protein. The returned series objects contain the mean probabilities for a given site and experimental sample\"\"\"\n",
    "    site2sample2probs = {}\n",
    "    for modpep in modpeps:\n",
    "        for idx in range(len(modpep.positions)):\n",
    "            site = modpep.positions[idx]\n",
    "            prob = modpep.probabilities[idx]\n",
    "            sample = modpep.sample\n",
    "            site2sample2probs[site] = site2sample2probs.get(site, {}) #.update({sample:[]})\n",
    "            site2sample2probs.get(site)[sample] = site2sample2probs.get(site).get(sample, []) + [prob]\n",
    "    \n",
    "    series_collected = []\n",
    "    for site in site2sample2probs.keys():\n",
    "        sample2probs = site2sample2probs.get(site)\n",
    "        header = list(sample2probs.keys())\n",
    "        probs = [np.mean(sample2probs.get(x)) for x in header]\n",
    "        site_series = pd.Series(probs, index=header)\n",
    "        site_series = site_series.append(pd.Series([int(site)], index=[\"site\"]))\n",
    "        site_series = site_series.append(pd.Series(refprot, index= [\"REFPROT\"]))\n",
    "        site_series = site_series.append(pd.Series(refgene, index= [\"gene\"]))\n",
    "        series_collected.append(site_series)\n",
    "\n",
    "    return series_collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_ptmsite_infos_spectronaut(input_df, ptm_ids_df):\n",
    "    intersect_columns = input_df.columns.intersection(ptm_ids_df.columns)\n",
    "    if(len(intersect_columns)==2):\n",
    "        print(f\"assigning ptms based on columns {intersect_columns}\")\n",
    "        input_df = input_df.merge(ptm_ids_df, on=list(intersect_columns), how= 'left')\n",
    "    else:\n",
    "        raise Exception(f\"Number of intersecting columns {intersect_columns} not as expected\")\n",
    "    input_df = add_ptm_precursor_names_spectronaut(input_df)\n",
    "    input_df = input_df[~input_df[\"conditions\"].isna()]\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def add_ptm_precursor_names_spectronaut(ptm_annotated_input):\n",
    "    delimiter = pd.Series([\"_\" for x in range(len(ptm_annotated_input.index))])\n",
    "    ptm_annotated_input[\"ion\"] = ptm_annotated_input[\"PEP.StrippedSequence\"] + delimiter + ptm_annotated_input[\"FG.PrecMz\"].astype('str') + delimiter + ptm_annotated_input[\"FG.Charge\"].astype('str') + delimiter + ptm_annotated_input[\"REFPROT\"] + delimiter +ptm_annotated_input[\"site\"].astype('str')\n",
    "    ptm_annotated_input.gene.fillna('', inplace=True)\n",
    "    ptm_annotated_input[\"site_id\"] = ptm_annotated_input[\"gene\"].astype('str')+delimiter+ptm_annotated_input[\"REFPROT\"].astype('str') + delimiter +ptm_annotated_input[\"site\"].astype('str')\n",
    "    return ptm_annotated_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def filter_input_table(input_type, modification_type,input_df):\n",
    "    if input_type == \"Spectronaut\":\n",
    "        non_fragion_columns = [x for x in input_df.columns if not x.startswith(\"F.\")]\n",
    "        \n",
    "        return input_df[~input_df[f\"EG.PTMProbabilities {modification_type}\"].isna()]\n",
    "    if input_type == \"DIANN\":\n",
    "        return input_df[[(modification_type in x) for x in input_df[\"Modified.Sequence\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "headers_dicts = {'Spectronaut' : {\"label_column\" : \"R.Label\", \"fg_id_column\" : \"FG.Id\", 'sequence' : \"PEP.StrippedSequence\", 'proteins' : \"PG.UniProtIds\", 'precursor_mz' : \"FG.PrecMz\", \"precursor_charge\" : \"FG.Charge\"}, \n",
    "'DIANN' : {\"label_column\" : \"Run\", \"fg_id_column\" : \"Precursor.Id\", 'sequence' : \"Stripped.Sequence\",'proteins' :\"Protein.Ids\", 'precursor_mz' : \"Precursor.Mz\", \"precursor_charge\" : \"Precursor.Charge\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_ptmpos_header(input_type, modification_type):\n",
    "    if input_type == 'Spectronaut':\n",
    "        return f\"EG.PTMPositions {modification_type}\"\n",
    "    if input_type == 'DIANN':\n",
    "        return \"Modified.Sequence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_ptmprob_header(input_type, modification_type):\n",
    "    if input_type == 'Spectronaut':\n",
    "        return f\"EG.PTMProbabilities {modification_type}\"\n",
    "    if input_type == 'DIANN':\n",
    "        return \"PTM.Site.Confidence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "def get_uniprot_path(database_tsv, organism= \"human\"):\n",
    "    return get_path_to_database(database_tsv, \"uniprot_mapping.tsv.zip\",organism)\n",
    "\n",
    "def get_swissprot_path(database_tsv, organism = \"human\"):\n",
    "    return get_path_to_database(database_tsv, \"swissprot_mapping.tsv.zip\",organism)\n",
    "\n",
    "def get_path_to_database(database_path, database_name, organism):\n",
    "    if database_path != None:\n",
    "        if os.path.exists(database_path):\n",
    "            return database_path\n",
    "    else:\n",
    "        database_path =  os.path.join(pathlib.Path(__file__).parent.absolute(), \"..\", \"reference_databases\", organism, database_name)\n",
    "        return database_path\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign all ions for a given protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def assign_protein(modpeps,condid2ionids, refprot, id_thresh):\n",
    "    \"\"\"go through ions of a given protein, cluster if necessary and map each ion to a ptm_site ID\"\"\"\n",
    "    id2groupid = {}\n",
    "    id2normedid = {}\n",
    "\n",
    "    if len(modpeps) == 1:\n",
    "        grouped_ions = [modpeps]\n",
    "    else:\n",
    "        grouped_ions = cluster_ions(modpeps)\n",
    "\n",
    "    for group in grouped_ions:\n",
    "        summed_probs = np.sum([x.probabilities for x in group], axis = 0)\n",
    "        max_probs = np.max([x.probabilities for x in group], axis = 0)\n",
    "        num_sites = group[0].num_sites\n",
    "\n",
    "        idxs_most_likely = np.argpartition(summed_probs, -num_sites)[-num_sites:] #get the indices of the most likely sites\n",
    "        idxs_most_likely = np.sort(idxs_most_likely)\n",
    "        idxs_confident = set(np.where(max_probs>=id_thresh)[0]) #check which sites are above the confidence threshold\n",
    "        \n",
    "        positions = list(group[0].positions)\n",
    "        positions_final = []\n",
    "        for idx in idxs_most_likely:#set those sites that are not confident enough to np.nan\n",
    "            if idx in idxs_confident:\n",
    "                positions_final.append(positions[idx])\n",
    "            else:\n",
    "                positions_final.append(np.nan)\n",
    "        \n",
    "        #positions = np.sort(positions)\n",
    "        ptm_group_id = positions_final\n",
    "        ptm_group_id_normed = f\"{refprot}_{np.array(positions_final)-group[0].start_idx}\"\n",
    "        all_ions = sum([condid2ionids.get(x.id) for x in group], [])#the condition-level merged ions are mapped back to the existin ion-level IDs\n",
    "        id2groupid.update({x:ptm_group_id for x in all_ions})\n",
    "\n",
    "        id2normedid.update({x:ptm_group_id_normed for x in all_ions})\n",
    "\n",
    "\n",
    "    return id2groupid, id2normedid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def assign_dataset_inmemory(input_file, results_dir, samplemap = 'samples.map.tsv', modification_type = \"[Phospho (STY)]\", id_thresh = 0.6, excl_thresh =0.2 ,swissprot_file = None, \n",
    "sequence_file=None, input_type = \"Spectronaut\", organism = \"human\"):\n",
    "    if input_type == \"Spectronaut\":\n",
    "        input_df = read_df_spectronaut_reduce_cols(input_file, modification_type)\n",
    "    if input_type == \"DIANN\":\n",
    "        input_df = read_df_diann_reduce_cols(input_file)\n",
    "    \n",
    "    assign_dataset(input_df, id_thresh = id_thresh, excl_thresh =excl_thresh, results_folder = results_dir, samplemap = samplemap, swissprot_file = swissprot_file, sequence_file=sequence_file, modification_type = modification_type, input_type = input_type, \n",
    "        organism = organism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "def assign_dataset_chunkwise(input_file, results_dir, samplemap = 'samples.map.tsv', modification_type = \"[Phospho (STY)]\", id_thresh = 0.6, excl_thresh =0.2 ,swissprot_file = None, \n",
    "sequence_file=None, input_type = \"Spectronaut\", organism = \"human\"):\n",
    "    \"\"\"go through the dataset chunkwise. The crucial step here is, that the dataset needs to be sorted by protein (realized via set_index) such that the chunks are independent (different proteins are independent)\n",
    "    \"\"\"\n",
    "    clean_up_previous_processings(results_dir)\n",
    "    \n",
    "    if input_type == 'Spectronaut':\n",
    "        relevant_cols = get_relevant_cols_spectronaut(modification_type)\n",
    "        input_df = dd.read_csv(input_file, sep = \"\\t\", dtype='str', blocksize = 100*1024*1024, usecols = relevant_cols)\n",
    "        input_df = input_df.set_index('PG.UniProtIds')\n",
    "    \n",
    "    if input_type == 'DIANN':\n",
    "        relevant_cols = get_relevant_cols_diann(modification_type)\n",
    "        input_df = dd.read_csv(input_file, sep = \"\\t\", dtype='str', blocksize = 100*1024*1024, usecols = relevant_cols)\n",
    "        input_df = input_df.set_index('ProteinGroup')\n",
    "    \n",
    "    input_df = input_df.drop_duplicates()\n",
    "    sorted_reduced_input = f\"{input_file}.sorted_reduced.xz\"\n",
    "    if os.path.exists(sorted_reduced_input):\n",
    "        os.remove(sorted_reduced_input)\n",
    "    input_df.to_csv(sorted_reduced_input, single_file = True, sep = \"\\t\", compression = 'xz')\n",
    "\n",
    "    input_df_it = pd.read_csv(sorted_reduced_input, sep = \"\\t\", chunksize = 1000_000, encoding ='latin1')\n",
    "    for input_df in input_df_it:\n",
    "\n",
    "        assign_dataset(input_df, id_thresh = id_thresh, excl_thresh =excl_thresh, results_folder = results_dir, samplemap = samplemap, swissprot_file = swissprot_file, sequence_file=sequence_file, modification_type = modification_type, input_type = input_type, \n",
    "        organism = organism)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def clean_up_previous_processings(results_folder):\n",
    "    file_ptm_ids = os.path.join(results_folder, \"ptm_ids.tsv\")\n",
    "    file_siteprobs = os.path.join(results_folder, \"siteprobs.tsv\")\n",
    "\n",
    "    if os.path.exists(file_ptm_ids):\n",
    "        os.remove(file_ptm_ids)\n",
    "    if os.path.exists(file_siteprobs):\n",
    "        os.remove(file_siteprobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import alphaquant.visualizations as aqviz\n",
    "def assign_dataset(input_df, id_thresh = 0.6, excl_thresh =0.2, results_folder = None, samplemap = 'samples.map.tsv',swissprot_file = None, \n",
    "sequence_file=None, modification_type = \"[Phospho (STY)]\", input_type = \"Spectronaut\", organism = \"human\", header = True):\n",
    "\n",
    "    \"\"\"wrapper function reformats Spectronaut inputs tables and iterates through the whole dataset.\n",
    "    Needed columns:\n",
    "    \"EG.PTMProbabilities {modification_type}\"\n",
    "    \"EG.PTMPositions {modification_type}\"\n",
    "    \"PEP.StrippedSequence\"\n",
    "    \"FG.PrecMz\"\n",
    "    \"FG.Charge\"\n",
    "    \n",
    "    \"\"\"\"\"\n",
    "    if(id_thresh < 0.5):\n",
    "        print(\"id threshold was set below 0.5, which can lead to ambigous ID sites. Setting to 0.51\")\n",
    "        id_thresh = 0.51\n",
    "    swissprot_file = get_swissprot_path(swissprot_file, organism)\n",
    "    sequence_file = get_uniprot_path(sequence_file, organism)\n",
    "    #input_df = pd.read_csv(ptmprob_file, sep = sep).drop_duplicates()\n",
    "    headers_dict = headers_dicts.get(input_type)\n",
    "    label_column = headers_dict.get(\"label_column\")\n",
    "    fg_id_column = headers_dict.get(\"fg_id_column\")\n",
    "    _,sample2cond = aqviz.initialize_sample2cond(samplemap)\n",
    "    len_before = len(input_df.index)\n",
    "    input_df = filter_input_table(input_type, modification_type, input_df)\n",
    "    print(f\"filtered PTM peptides from {len_before} to {len(input_df.index)}\")\n",
    "    swissprot_ids = set(pd.read_csv(swissprot_file, sep = \"\\t\", usecols = [\"Entry\"])[\"Entry\"])\n",
    "    sequence_df = pd.read_csv(sequence_file, sep = \"\\t\", usecols = [\"Entry\", \"Sequence\", \"Gene names\"])\n",
    "    sequence_map = dict(zip(sequence_df[\"Entry\"], sequence_df[\"Sequence\"]))\n",
    "    sequence_df = sequence_df.dropna()\n",
    "    \n",
    "    refgene_map = dict(zip(sequence_df[\"Entry\"], [x.split(\" \")[0] for x in sequence_df[\"Gene names\"]]))\n",
    "\n",
    "    input_df[\"REFPROT\"] = get_idmap_column(input_df[headers_dict.get(\"proteins\")],swissprot_ids)\n",
    "    input_df[\"IonID\"] = input_df[label_column] + input_df[fg_id_column]\n",
    "    input_df = input_df.set_index(\"REFPROT\")\n",
    "    input_df.sort_index(inplace=True)\n",
    "    #input_df.to_csv(f\"{ptmprob_file}.sorted\", sep = \"\\t\")\n",
    "    site_ids = []\n",
    "    fg_ids = []\n",
    "    run_ids = []\n",
    "    prot_ids = []\n",
    "    gene_ids = []\n",
    "    ptmlocs = []\n",
    "    locprobs = []\n",
    "    siteprobs = []\n",
    "    stripped_seqs = []\n",
    "    prec_mz = []\n",
    "    fg_charge = []\n",
    "    ptm_id = []\n",
    "    ion_id = []\n",
    "\n",
    "    \n",
    "    count_peps = 0\n",
    "    fraction_count = 0\n",
    "    one_fraction = int(len(input_df.index)/100)\n",
    "    for prot in input_df.index.unique():#input_df[\"REFPROT\"].unique():\n",
    "\n",
    "        if int(count_peps/one_fraction)>fraction_count:\n",
    "            print(f\"assigned {count_peps} of {len(input_df.index)} {count_peps/len(input_df.index)}\")\n",
    "            fraction_count = int(count_peps/one_fraction) +1\n",
    "        \n",
    "        #filtvec = [prot in x for x in input_df[\"REFPROT\"]]\n",
    "\n",
    "        protein_df = input_df.loc[[prot]].copy()#input_df[filtvec].copy()\n",
    "        protein_df = protein_df.reset_index()\n",
    "        \n",
    "        count_peps+= len(protein_df)\n",
    "\n",
    "        sequence = sequence_map.get(prot)\n",
    "        if sequence == None:\n",
    "            continue\n",
    "        gene = refgene_map.get(prot)\n",
    "\n",
    "        modpeps_per_sample = [ModifiedPeptide(input_type,protein_df.loc[x],sequence, modification_type) for x in protein_df.index]\n",
    "        merged_siteprobs = get_site_prob_overview(modpeps_per_sample, prot, gene)\n",
    "        siteprobs.extend(merged_siteprobs)\n",
    "        modpeps, condid2ionids = merge_samecond_modpeps(modpeps_per_sample, sample2cond, id_thresh, excl_thresh) #all ions coming from the same condition are merged\n",
    "        ionid2ptmid,_ = assign_protein(modpeps, condid2ionids, prot,id_thresh)##after clustering, conditions are mapped back to the original run\n",
    "\n",
    "        ptm_ids_prot = [ionid2ptmid.get(x) for x in protein_df[\"IonID\"]]\n",
    "        \n",
    "        ptmlocs.extend([x for x in protein_df[get_ptmpos_header(input_type, modification_type)]])\n",
    "        locprobs.extend([x for x in protein_df[get_ptmprob_header(input_type, modification_type)]])\n",
    "        site_ids.extend(ptm_ids_prot)\n",
    "        fg_ids.extend(protein_df[fg_id_column].tolist())\n",
    "        ion_id.extend([f\"{fg}_{site_num}\" for fg, site_num in zip(protein_df[fg_id_column].tolist(), ptm_ids_prot)])\n",
    "        run_ids.extend(protein_df[label_column].tolist())\n",
    "        prot_ids.extend([prot for x in range(len(ptm_ids_prot))])\n",
    "        gene_ids.extend([gene for x in range(len(ptm_ids_prot))])\n",
    "        stripped_seqs.extend(protein_df[headers_dict.get(\"sequence\")])\n",
    "        prec_mz.extend(protein_df[headers_dict.get(\"precursor_mz\")])\n",
    "        fg_charge.extend(protein_df[headers_dict.get(\"precursor_charge\")])\n",
    "        ptm_id.extend([f\"{gene}_{prot}_{ionid2ptmid.get(x)}\" for x in protein_df[\"IonID\"]])\n",
    "        \n",
    "    \n",
    "    conditions = [sample2cond.get(x) for x in run_ids]\n",
    "\n",
    "    mapped_df = pd.DataFrame({label_column : run_ids, \"conditions\" : conditions, fg_id_column : fg_ids, \"REFPROT\" : prot_ids, \"gene\" : gene_ids,\"site\" : site_ids, \"ptmlocs\":ptmlocs ,\n",
    "    \"locprob\" : locprobs, \"PEP.StrippedSequence\" : stripped_seqs, \"FG.PrecMz\" : prec_mz, \"FG.Charge\": fg_charge, \"FG.Id.ptm\" : ion_id, \"ptm_id\" : ptm_id})\n",
    "\n",
    "    \n",
    "    siteprob_df = pd.DataFrame(siteprobs)\n",
    "    siteprob_df = siteprob_df.astype({\"site\" : \"int\"})\n",
    "    siteprob_df.set_index([\"REFPROT\", \"site\"], inplace=True)\n",
    "    siteprob_df = siteprob_df.sort_index().reset_index()\n",
    "    \n",
    "    if results_folder != None:\n",
    "        os.makedirs(results_folder, exist_ok=True)\n",
    "        mapped_df.to_csv(os.path.join(results_folder, \"ptm_ids.tsv\"), sep = \"\\t\", index = None, header = header, mode = 'a')\n",
    "        siteprob_df.to_csv(os.path.join(results_folder, \"siteprobs.tsv\"), sep = \"\\t\", index = None, header = header, mode = 'a')\n",
    "    \n",
    "    return mapped_df, siteprob_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ptm mapped input tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import numpy as np\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "import os\n",
    "\n",
    "def merge_ptmsite_mappings_write_table(spectronaut_file, mapped_df, modification_type, ptm_type_config_dict = 'spectronaut_ptm_fragion_isotopes', chunksize = 100_000):\n",
    "    #load configs, determine\n",
    "    config_dict = aqutils.import_config_dict()\n",
    "    config_dict_ptm = config_dict.get(ptm_type_config_dict)\n",
    "    relevant_columns = aqutils.get_relevant_columns_config_dict(config_dict_ptm)#the columns that will be relevant in the ptm table\n",
    "    relevant_columns_spectronaut = list(set(relevant_columns).intersection(set(pd.read_csv(spectronaut_file, sep = \"\\t\", nrows=2).columns)))# the relevant columsn in the spectronaut table ()\n",
    "    relevant_columns_spectronaut = relevant_columns_spectronaut+[\"EG.ModifiedSequence\"]\n",
    "    file_modified = spectronaut_file.replace(\".tsv\", \"\")\n",
    "    ptmmapped_table_filename = f'{file_modified}_ptmsite_mapped.tsv'\n",
    "    lines_read = 0\n",
    "\n",
    "    labelid2ptmid, labelid2site = get_ptmid_mappings(mapped_df) #get precursor+experiment to site mappings\n",
    "    specnaut_df_it = pd.read_csv(spectronaut_file, sep = \"\\t\", chunksize=chunksize, usecols=relevant_columns_spectronaut)\n",
    "\n",
    "    print(f\"adding ptm info to spectronaut file\")\n",
    "\n",
    "    if os.path.exists(ptmmapped_table_filename):\n",
    "        os.remove(ptmmapped_table_filename)\n",
    "    \n",
    "    header = True\n",
    "    for specnaut_df in specnaut_df_it:\n",
    "        specnaut_df_annot = add_ptmsite_info_to_subtable(specnaut_df, labelid2ptmid, labelid2site, modification_type, relevant_columns)\n",
    "        write_chunk_to_file(specnaut_df_annot, ptmmapped_table_filename, header)\n",
    "        lines_read +=chunksize\n",
    "        print(f\"{lines_read} lines read\")\n",
    "        header = False\n",
    "    return ptmmapped_table_filename\n",
    "\n",
    "def add_ptmsite_info_to_subtable(spectronaut_df, labelid2ptmid, labelid2site, modification_type, relevant_columns):\n",
    "\n",
    "    spectronaut_df[\"labelid\"] = spectronaut_df[\"R.Label\"].astype('str').to_numpy() + spectronaut_df[\"FG.Id\"].astype('str').to_numpy() #derive the id to map from Spectronaut\n",
    "    spectronaut_df = spectronaut_df[[x in labelid2ptmid.keys() for x in spectronaut_df[\"labelid\"]]].copy() #drop peptides that have no ptm\n",
    "\n",
    "    spectronaut_df[\"ptm_id\"] = np.array([labelid2ptmid.get(x) for x in spectronaut_df[\"labelid\"]]) #add the ptm_id row to the spectronaut table\n",
    "    modseq_typereplaced = np.array([str(x.replace(modification_type, \"\")) for x in spectronaut_df[\"EG.ModifiedSequence\"]]) #EG.ModifiedSequence already determines a localization of the modification type. Replace all localizations and add the new localizations below\n",
    "    sites = np.array([str(labelid2site.get(x)) for x in spectronaut_df[\"labelid\"]])\n",
    "    spectronaut_df[\"ptm_mapped_modseq\"] = np.char.add(modseq_typereplaced, sites)\n",
    "\n",
    "    return spectronaut_df\n",
    "\n",
    "\n",
    "def get_ptmid_mappings(mapped_df):\n",
    "    labelid = mapped_df[\"R.Label\"].astype('str').to_numpy() + mapped_df[\"FG.Id\"].astype('str').to_numpy()\n",
    "    ptm_ids = mapped_df[\"ptm_id\"].to_numpy()\n",
    "    site = mapped_df[\"site\"].to_numpy()\n",
    "    labelid2ptmid = dict(zip(labelid, ptm_ids))\n",
    "    labelid2site = dict(zip(labelid, site))\n",
    "    return labelid2ptmid, labelid2site\n",
    "\n",
    "\n",
    "def write_chunk_to_file(chunk, filepath ,write_header):\n",
    "    chunk.to_csv(filepath, header=write_header, mode='a', sep = \"\\t\", index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Changes in site occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def initialize_ptmsite_df(ptmsite_file, samplemap_file):\n",
    "    \"\"\"returns ptmsite_df, samplemap_df from files\"\"\"\n",
    "    samplemap_df, _ = initialize_sample2cond(samplemap_file)\n",
    "    ptmsite_df = pd.read_csv(ptmsite_file, sep = \"\\t\")\n",
    "    return ptmsite_df, samplemap_df\n",
    "\n",
    "def detect_site_occupancy_change(cond1, cond2, ptmsite_df ,samplemap_df, minrep = 2, threshold_prob = 0.05):\n",
    "    \"\"\"\n",
    "    uses a PTMsite df with headers \"REFPROT\", \"gene\",\"site\", and headers for sample1, sample2, etc and determines\n",
    "    whether a site appears/dissappears between conditions based on some probability threshold\n",
    "    \"\"\"\n",
    "\n",
    "    ptmsite_df[\"site_id\"] = ptmsite_df[\"REFPROT\"] + ptmsite_df[\"site\"].astype(\"str\")\n",
    "    ptmsite_df = ptmsite_df.set_index(\"site_id\")\n",
    "    cond1_samples = list(set(samplemap_df[(samplemap_df[\"condition\"]==cond1)][\"sample\"]).intersection(set(ptmsite_df.columns)))\n",
    "    cond2_samples = list(set(samplemap_df[(samplemap_df[\"condition\"]==cond2)][\"sample\"]).intersection(set(ptmsite_df.columns)))\n",
    "\n",
    "    ptmsite_df = ptmsite_df[cond1_samples + cond2_samples + [\"REFPROT\", \"gene\", \"site\"]]\n",
    "    filtvec = [(sum(~np.isnan(x))>0) for _, x in ptmsite_df[cond1_samples + cond2_samples].iterrows()]\n",
    "    ptmsite_df = ptmsite_df[filtvec]\n",
    "    ptmsite_df = ptmsite_df.sort_index()\n",
    "\n",
    "    regulated_sites = []\n",
    "    count = 0\n",
    "    for ptmsite in ptmsite_df.index.unique():\n",
    "\n",
    "        site_df = ptmsite_df.loc[[ptmsite]]\n",
    "        if count%1000 ==0:\n",
    "            num_checks = len(ptmsite_df.index.unique())\n",
    "            print(f\"{count} of {num_checks} {count/num_checks :.2f}\")\n",
    "        count+=1\n",
    "\n",
    "        cond1_vals = site_df[cond1_samples].to_numpy()\n",
    "        cond2_vals = site_df[cond2_samples].to_numpy()\n",
    "\n",
    "        cond1_vals = cond1_vals[~np.isnan(cond1_vals)]\n",
    "        cond2_vals = cond2_vals[~np.isnan(cond2_vals)]\n",
    "\n",
    "        numrep_c1 = len(cond1_vals)\n",
    "        numrep_c2 = len(cond2_vals)\n",
    "\n",
    "        if(numrep_c1<minrep) | (numrep_c2 < minrep):\n",
    "            continue\n",
    "        \n",
    "        cond1_prob = np.mean(cond1_vals)\n",
    "        cond2_prob = np.mean(cond2_vals)\n",
    "\n",
    "        unlikely_c1 = cond1_prob<threshold_prob\n",
    "        unlikely_c2 = cond2_prob<threshold_prob\n",
    "        likely_c1 = cond1_prob>1-threshold_prob\n",
    "        likely_c2 = cond2_prob>1-threshold_prob\n",
    "        direction = 0\n",
    "\n",
    "        if(unlikely_c1&likely_c2):\n",
    "            direction = -1\n",
    "        if(unlikely_c2&likely_c1):\n",
    "            direction = 1\n",
    "\n",
    "        if direction!=0:\n",
    "            print(\"occpancy change detected\")\n",
    "            refprot = site_df[\"REFPROT\"].values[0]\n",
    "            gene = site_df[\"gene\"].values[0]\n",
    "            site = site_df[\"site\"].values[0]\n",
    "            regulated_sites.append([refprot, gene, site, direction, cond1_prob, cond2_prob, numrep_c1, numrep_c2])\n",
    "\n",
    "\n",
    "    df_occupancy_change = pd.DataFrame(regulated_sites, columns=[\"REFPROT\", \"gene\", \"site\", \"direction\", \"c1_meanprob\", \"c2_meanprob\", \"c1_nrep\", \"c2_nrep\"])\n",
    "    return df_occupancy_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def check_site_occupancy_changes_all_diffresults(results_folder = os.path.join(\".\",\"results\"), siteprobs_filename = \"siteprobs.tsv\",samplemap_file = \"samples.map\",condpairs_to_compare = [], threshold_prob = 0.05, minrep = 2):\n",
    "    \n",
    "    samplemap_df, _ = get_sample2cond_dataframe(samplemap_file)\n",
    "    ptmsite_map = os.path.join(results_folder, siteprobs_filename)\n",
    "    ptmsite_df = pd.read_csv(ptmsite_map, sep = \"\\t\")\n",
    "    ptmsite_df[\"site_id\"] = ptmsite_df[\"REFPROT\"] + ptmsite_df[\"site\"].astype(\"str\")\n",
    "    ptmsite_df = ptmsite_df.set_index(\"site_id\")\n",
    "\n",
    "\n",
    "    if len(condpairs_to_compare) == 0:\n",
    "        condpairs_to_compare = [f.replace(\".results.tsv\", \"\").split(\"_VS_\") for f in os.listdir(results_folder) if re.match(r'.*results.tsv', f)]\n",
    "    for condpair in condpairs_to_compare:\n",
    "        print(f\"check condpair {condpair}\")\n",
    "        cond1 = condpair[0]\n",
    "        cond2 = condpair[1]\n",
    "        cond1_samples = list(set(samplemap_df[(samplemap_df[\"condition\"]==cond1)][\"sample\"]).intersection(set(ptmsite_df.columns)))\n",
    "        cond2_samples = list(set(samplemap_df[(samplemap_df[\"condition\"]==cond2)][\"sample\"]).intersection(set(ptmsite_df.columns)))\n",
    "\n",
    "        ptmsite_df_cpair = ptmsite_df[cond1_samples + cond2_samples + [\"REFPROT\", \"gene\", \"site\"]]\n",
    "        filtvec = [(sum(~np.isnan(x))>0) for _, x in ptmsite_df[cond1_samples + cond2_samples].iterrows()]\n",
    "        ptmsite_df_cpair = ptmsite_df_cpair[filtvec]\n",
    "        ptmsite_df_cpair = ptmsite_df_cpair.sort_index()\n",
    "\n",
    "        condpairname = utils.get_condpairname(condpair)\n",
    "        df_occupancy = detect_site_occupancy_change(cond1, cond2, ptmsite_df_cpair, samplemap_df, minrep = minrep, threshold_prob = threshold_prob)\n",
    "        df_occupancy.to_csv(os.path.join(results_folder, f\"{condpairname}.ptm_occupancy_changes.tsv\"), sep = \"\\t\", index = None)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered PTM peptides from 1000 to 947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantin/workspace/alphaquant/alphaquant/ptmsite_mapping.py:417: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df[\"REFPROT\"] = get_idmap_column(input_df[headers_dict.get(\"proteins\")],swissprot_ids)\n",
      "/Users/constantin/workspace/alphaquant/alphaquant/ptmsite_mapping.py:418: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df[\"IonID\"] = input_df[label_column] + input_df[fg_id_column]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigned 11 of 947 0.011615628299894404\n",
      "assigned 32 of 947 0.0337909186906019\n",
      "assigned 89 of 947 0.09398099260823653\n",
      "assigned 99 of 947 0.10454065469904963\n",
      "assigned 119 of 947 0.12565997888067582\n",
      "assigned 135 of 947 0.14255543822597677\n",
      "assigned 156 of 947 0.16473072861668428\n",
      "assigned 173 of 947 0.18268215417106654\n",
      "assigned 189 of 947 0.19957761351636746\n",
      "assigned 209 of 947 0.22069693769799367\n",
      "assigned 229 of 947 0.24181626187961985\n",
      "assigned 244 of 947 0.2576557550158395\n",
      "assigned 265 of 947 0.27983104540654696\n",
      "assigned 290 of 947 0.30623020063357975\n",
      "assigned 308 of 947 0.3252375923970433\n",
      "assigned 342 of 947 0.3611404435058078\n",
      "assigned 365 of 947 0.38542766631467795\n",
      "assigned 380 of 947 0.4012671594508976\n",
      "assigned 396 of 947 0.41816261879619854\n",
      "assigned 426 of 947 0.4498416050686378\n",
      "assigned 452 of 947 0.47729672650475186\n",
      "assigned 476 of 947 0.5026399155227033\n",
      "assigned 487 of 947 0.5142555438225976\n",
      "assigned 509 of 947 0.5374868004223865\n",
      "assigned 523 of 947 0.5522703273495249\n",
      "assigned 540 of 947 0.5702217529039071\n",
      "assigned 558 of 947 0.5892291446673706\n",
      "assigned 579 of 947 0.6114044350580782\n",
      "assigned 599 of 947 0.6325237592397043\n",
      "assigned 625 of 947 0.6599788806758183\n",
      "assigned 647 of 947 0.6832101372756072\n",
      "assigned 657 of 947 0.6937697993664202\n",
      "assigned 676 of 947 0.7138331573389651\n",
      "assigned 693 of 947 0.7317845828933475\n",
      "assigned 711 of 947 0.750791974656811\n",
      "assigned 736 of 947 0.7771911298838438\n",
      "assigned 763 of 947 0.805702217529039\n",
      "assigned 780 of 947 0.8236536430834214\n",
      "assigned 793 of 947 0.8373812038014784\n",
      "assigned 810 of 947 0.8553326293558606\n",
      "assigned 832 of 947 0.8785638859556494\n",
      "assigned 846 of 947 0.8933474128827877\n",
      "assigned 864 of 947 0.9123548046462513\n",
      "assigned 883 of 947 0.9324181626187962\n",
      "assigned 900 of 947 0.9503695881731784\n",
      "assigned 932 of 947 0.9841605068637803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R.Label</th>\n",
       "      <th>conditions</th>\n",
       "      <th>FG.Id</th>\n",
       "      <th>REFPROT</th>\n",
       "      <th>gene</th>\n",
       "      <th>site</th>\n",
       "      <th>ptmlocs</th>\n",
       "      <th>locprob</th>\n",
       "      <th>PEP.StrippedSequence</th>\n",
       "      <th>FG.PrecMz</th>\n",
       "      <th>FG.Charge</th>\n",
       "      <th>FG.Id.ptm</th>\n",
       "      <th>ptm_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_EQAEAEVAS[Phospho (STY)]LNRR_.3</td>\n",
       "      <td>A0A087WWU8</td>\n",
       "      <td>TPM3</td>\n",
       "      <td>[51]</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>EQAEAEVASLNRR</td>\n",
       "      <td>518.242004</td>\n",
       "      <td>3</td>\n",
       "      <td>_EQAEAEVAS[Phospho (STY)]LNRR_.3_[51]</td>\n",
       "      <td>TPM3_A0A087WWU8_[51]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_GELAELPNGLGET[Phospho (STY)]RGSEDET[Phospho (...</td>\n",
       "      <td>A0A087WYP0</td>\n",
       "      <td>HNF1A</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>13;16;20;28</td>\n",
       "      <td>0.5;0.5;0.5;0.5</td>\n",
       "      <td>GELAELPNGLGETRGSEDETDDDGEDFTPPILK</td>\n",
       "      <td>919.892029</td>\n",
       "      <td>4</td>\n",
       "      <td>_GELAELPNGLGET[Phospho (STY)]RGSEDET[Phospho (...</td>\n",
       "      <td>HNF1A_A0A087WYP0_[nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...</td>\n",
       "      <td>A0A087WZ13</td>\n",
       "      <td>RAVER1</td>\n",
       "      <td>[14]</td>\n",
       "      <td>5;7;13</td>\n",
       "      <td>0;0;1</td>\n",
       "      <td>AADVSVTHRPPLSPK</td>\n",
       "      <td>566.285461</td>\n",
       "      <td>3</td>\n",
       "      <td>_[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...</td>\n",
       "      <td>RAVER1_A0A087WZ13_[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...</td>\n",
       "      <td>A0A087WZ13</td>\n",
       "      <td>RAVER1</td>\n",
       "      <td>[14]</td>\n",
       "      <td>5;7;13</td>\n",
       "      <td>0;0;1</td>\n",
       "      <td>AADVSVTHRPPLSPK</td>\n",
       "      <td>848.924561</td>\n",
       "      <td>2</td>\n",
       "      <td>_[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...</td>\n",
       "      <td>RAVER1_A0A087WZ13_[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_M[Oxidation (M)]S[Phospho (STY)]PPPSGFGER_.2</td>\n",
       "      <td>A0A087WZ13</td>\n",
       "      <td>RAVER1</td>\n",
       "      <td>[617]</td>\n",
       "      <td>2;6</td>\n",
       "      <td>1;0</td>\n",
       "      <td>MSPPPSGFGER</td>\n",
       "      <td>629.252136</td>\n",
       "      <td>2</td>\n",
       "      <td>_M[Oxidation (M)]S[Phospho (STY)]PPPSGFGER_.2_...</td>\n",
       "      <td>RAVER1_A0A087WZ13_[617]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...</td>\n",
       "      <td>Q9Y6R0</td>\n",
       "      <td>NUMBL</td>\n",
       "      <td>[263]</td>\n",
       "      <td>9;21;23;26;27;28</td>\n",
       "      <td>0;1;0;0;0;0</td>\n",
       "      <td>KAEAAAAPTVAPGPAQPGHVSPTPATTSPGEK</td>\n",
       "      <td>769.130188</td>\n",
       "      <td>4</td>\n",
       "      <td>_KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...</td>\n",
       "      <td>NUMBL_Q9Y6R0_[263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_AEAAAAPTVAPGPAQPGHVSPT[Phospho (STY)]PATTSPGE...</td>\n",
       "      <td>Q9Y6R0</td>\n",
       "      <td>NUMBL</td>\n",
       "      <td>[263]</td>\n",
       "      <td>8;20;22;25;26;27</td>\n",
       "      <td>0;0.99;0;0;0;0</td>\n",
       "      <td>AEAAAAPTVAPGPAQPGHVSPTPATTSPGEK</td>\n",
       "      <td>982.472900</td>\n",
       "      <td>3</td>\n",
       "      <td>_AEAAAAPTVAPGPAQPGHVSPT[Phospho (STY)]PATTSPGE...</td>\n",
       "      <td>NUMBL_Q9Y6R0_[263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_AEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPGE...</td>\n",
       "      <td>Q9Y6R0</td>\n",
       "      <td>NUMBL</td>\n",
       "      <td>[263]</td>\n",
       "      <td>8;20;22;25;26;27</td>\n",
       "      <td>0;0.99;0;0;0;0</td>\n",
       "      <td>AEAAAAPTVAPGPAQPGHVSPTPATTSPGEK</td>\n",
       "      <td>982.472900</td>\n",
       "      <td>3</td>\n",
       "      <td>_AEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPGE...</td>\n",
       "      <td>NUMBL_Q9Y6R0_[263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...</td>\n",
       "      <td>Q9Y6R0</td>\n",
       "      <td>NUMBL</td>\n",
       "      <td>[263]</td>\n",
       "      <td>9;21;23;26;27;28</td>\n",
       "      <td>0;1;0;0;0;0</td>\n",
       "      <td>KAEAAAAPTVAPGPAQPGHVSPTPATTSPGEK</td>\n",
       "      <td>1025.171143</td>\n",
       "      <td>3</td>\n",
       "      <td>_KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...</td>\n",
       "      <td>NUMBL_Q9Y6R0_[263]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>20200529_QX8_MaTa_SA_phosphatase_screen_phosph...</td>\n",
       "      <td>siRNA11</td>\n",
       "      <td>_AEAAAAPTVAPGPAQPGHVSPTPATTS[Phospho (STY)]PGE...</td>\n",
       "      <td>Q9Y6R0</td>\n",
       "      <td>NUMBL</td>\n",
       "      <td>[263]</td>\n",
       "      <td>8;20;22;25;26;27</td>\n",
       "      <td>0;0.99;0;0;0;0</td>\n",
       "      <td>AEAAAAPTVAPGPAQPGHVSPTPATTSPGEK</td>\n",
       "      <td>982.472900</td>\n",
       "      <td>3</td>\n",
       "      <td>_AEAAAAPTVAPGPAQPGHVSPTPATTS[Phospho (STY)]PGE...</td>\n",
       "      <td>NUMBL_Q9Y6R0_[263]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>947 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               R.Label conditions  \\\n",
       "0    20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "1    20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "2    20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "3    20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "4    20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "..                                                 ...        ...   \n",
       "942  20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "943  20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "944  20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "945  20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "946  20200529_QX8_MaTa_SA_phosphatase_screen_phosph...    siRNA11   \n",
       "\n",
       "                                                 FG.Id     REFPROT    gene  \\\n",
       "0                     _EQAEAEVAS[Phospho (STY)]LNRR_.3  A0A087WWU8    TPM3   \n",
       "1    _GELAELPNGLGET[Phospho (STY)]RGSEDET[Phospho (...  A0A087WYP0   HNF1A   \n",
       "2    _[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...  A0A087WZ13  RAVER1   \n",
       "3    _[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...  A0A087WZ13  RAVER1   \n",
       "4        _M[Oxidation (M)]S[Phospho (STY)]PPPSGFGER_.2  A0A087WZ13  RAVER1   \n",
       "..                                                 ...         ...     ...   \n",
       "942  _KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...      Q9Y6R0   NUMBL   \n",
       "943  _AEAAAAPTVAPGPAQPGHVSPT[Phospho (STY)]PATTSPGE...      Q9Y6R0   NUMBL   \n",
       "944  _AEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPGE...      Q9Y6R0   NUMBL   \n",
       "945  _KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...      Q9Y6R0   NUMBL   \n",
       "946  _AEAAAAPTVAPGPAQPGHVSPTPATTS[Phospho (STY)]PGE...      Q9Y6R0   NUMBL   \n",
       "\n",
       "           site           ptmlocs          locprob  \\\n",
       "0          [51]                 9                1   \n",
       "1    [nan, nan]       13;16;20;28  0.5;0.5;0.5;0.5   \n",
       "2          [14]            5;7;13            0;0;1   \n",
       "3          [14]            5;7;13            0;0;1   \n",
       "4         [617]               2;6              1;0   \n",
       "..          ...               ...              ...   \n",
       "942       [263]  9;21;23;26;27;28      0;1;0;0;0;0   \n",
       "943       [263]  8;20;22;25;26;27   0;0.99;0;0;0;0   \n",
       "944       [263]  8;20;22;25;26;27   0;0.99;0;0;0;0   \n",
       "945       [263]  9;21;23;26;27;28      0;1;0;0;0;0   \n",
       "946       [263]  8;20;22;25;26;27   0;0.99;0;0;0;0   \n",
       "\n",
       "                  PEP.StrippedSequence    FG.PrecMz  FG.Charge  \\\n",
       "0                        EQAEAEVASLNRR   518.242004          3   \n",
       "1    GELAELPNGLGETRGSEDETDDDGEDFTPPILK   919.892029          4   \n",
       "2                      AADVSVTHRPPLSPK   566.285461          3   \n",
       "3                      AADVSVTHRPPLSPK   848.924561          2   \n",
       "4                          MSPPPSGFGER   629.252136          2   \n",
       "..                                 ...          ...        ...   \n",
       "942   KAEAAAAPTVAPGPAQPGHVSPTPATTSPGEK   769.130188          4   \n",
       "943    AEAAAAPTVAPGPAQPGHVSPTPATTSPGEK   982.472900          3   \n",
       "944    AEAAAAPTVAPGPAQPGHVSPTPATTSPGEK   982.472900          3   \n",
       "945   KAEAAAAPTVAPGPAQPGHVSPTPATTSPGEK  1025.171143          3   \n",
       "946    AEAAAAPTVAPGPAQPGHVSPTPATTSPGEK   982.472900          3   \n",
       "\n",
       "                                             FG.Id.ptm  \\\n",
       "0                _EQAEAEVAS[Phospho (STY)]LNRR_.3_[51]   \n",
       "1    _GELAELPNGLGET[Phospho (STY)]RGSEDET[Phospho (...   \n",
       "2    _[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...   \n",
       "3    _[Acetyl (Protein N-term)]AADVSVTHRPPLS[Phosph...   \n",
       "4    _M[Oxidation (M)]S[Phospho (STY)]PPPSGFGER_.2_...   \n",
       "..                                                 ...   \n",
       "942  _KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...   \n",
       "943  _AEAAAAPTVAPGPAQPGHVSPT[Phospho (STY)]PATTSPGE...   \n",
       "944  _AEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPGE...   \n",
       "945  _KAEAAAAPTVAPGPAQPGHVS[Phospho (STY)]PTPATTSPG...   \n",
       "946  _AEAAAAPTVAPGPAQPGHVSPTPATTS[Phospho (STY)]PGE...   \n",
       "\n",
       "                          ptm_id  \n",
       "0           TPM3_A0A087WWU8_[51]  \n",
       "1    HNF1A_A0A087WYP0_[nan, nan]  \n",
       "2         RAVER1_A0A087WZ13_[14]  \n",
       "3         RAVER1_A0A087WZ13_[14]  \n",
       "4        RAVER1_A0A087WZ13_[617]  \n",
       "..                           ...  \n",
       "942           NUMBL_Q9Y6R0_[263]  \n",
       "943           NUMBL_Q9Y6R0_[263]  \n",
       "944           NUMBL_Q9Y6R0_[263]  \n",
       "945           NUMBL_Q9Y6R0_[263]  \n",
       "946           NUMBL_Q9Y6R0_[263]  \n",
       "\n",
       "[947 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "import alphaquant.ptmsite_mapping as aqptm\n",
    "input_df = pd.read_csv(\"test_data/ptmsite_mapping/shortened_aq.tsv.zip\", sep = \"\\t\", nrows=1000)\n",
    "\n",
    "mapped_df = aqptm.assign_dataset(input_df,results_folder=None, samplemap=\"test_data/ptmsite_mapping/samples.map\")[0]\n",
    "display(mapped_df)\n",
    "mapped_df['site'] = [str(x) for x in mapped_df['site']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "#compare to hand selected sites\n",
    "\n",
    "def check_if_matches(refprot, pepseq, ptm_positions_peptide, protseq, number_occurences):\n",
    "    start_idx_protein = protseq.index(pepseq)\n",
    "    ptm_positions_prot = str([x+start_idx_protein for x in ptm_positions_peptide])\n",
    "    occurence_of_prot_position_combinations = sum([(x[0] == refprot)&(str(x[1]) == ptm_positions_prot) for x in zip(mapped_df[\"REFPROT\"], mapped_df[\"site\"])])\n",
    "    assert occurence_of_prot_position_combinations == number_occurences\n",
    "\n",
    "#peptide \"FIHQQPQSSSPVYGSSAK\"\n",
    "refprot = \"P49023\"\n",
    "protseq = \"MDDLDALLADLESTTSHISKRPVFLSEETPYSYPTGNHTYQEIAVPPPVPPPPSSEALNGTILDPLDQWQPSSSRFIHQQPQSSSPVYGSSAKTSSVSNPQDSVGSPCSRVGEEEHVYSFPNKQKSAEPSPTVMSTSLGSNLSELDRLLLELNAVQHNPPGFPADEANSSPPLPGALSPLYGVPETNSPLGGKAGPLTKEKPKRNGGRGLEDVRPSVESLLDELESSVPSPVPAITVNQGEMSSPQRVTSTQQQTRISASSATRELDELMASLSDFKIQGLEQRADGERCWAAGWPRDGGRSSPGGQDEGGFMAQGKTGSSSPPGGPPKPGSQLDSMLGSLQSDLNKLGVATVAKGVCGACKKPIAGQVVTAMGKTWHPEHFVCTHCQEEIGSRNFFERDGQPYCEKDYHNLFSPRCYYCNGPILDKVVTALDRTWHPEHFFCAQCGAFFGPEGFHEKDGKAYCRKDYFDMFAPKCGGCARAILENYISALNTLWHPECFVCRECFTPFVNGSFFEHDGQPYCEVHYHERRGSLCSGCQKPITGRCITAMAKKFHPEHFVCAFCLKQLNKGTFKEQNDKPYCQNCFLKLFC\"\n",
    "pepseq = \"FIHQQPQSSSPVYGSSAK\"\n",
    "\n",
    "ptm_position_peptide = [10]\n",
    "number_occurences = 4\n",
    "check_if_matches(refprot, pepseq, ptm_position_peptide, protseq, number_occurences)\n",
    "\n",
    "ptm_position_peptide = [13]\n",
    "number_occurences = 6\n",
    "check_if_matches(refprot, pepseq, ptm_position_peptide, protseq, number_occurences)\n",
    "\n",
    "#peptide \"FSEMMNNMGGDEDVDLPEVDGADDDSQDSDDEK\"\n",
    "refprot = \"Q15185\"\n",
    "protseq = \"MQPASAKWYDRRDYVFIEFCVEDSKDVNVNFEKSKLTFSCLGGSDNFKHLNEIDLFHCIDPNDSKHKRTDRSILCCLRKGESGQSWPRLTKERAKLNWLSVDFNNWKDWEDDSDEDMSNFDRFSEMMNNMGGDEDVDLPEVDGADDDSQDSDDEKMPDLE\"\n",
    "pepseq = \"FSEMMNNMGGDEDVDLPEVDGADDDSQDSDDEK\"\n",
    "\n",
    "ptm_position_peptide =[29]\n",
    "number_occurences = 4\n",
    "check_if_matches(refprot, pepseq, ptm_position_peptide, protseq,number_occurences)\n",
    "\n",
    "ptm_position_peptide =[26]\n",
    "number_occurences = 1\n",
    "check_if_matches(refprot, pepseq, ptm_position_peptide, protseq,number_occurences)\n",
    "\n",
    "ptm_position_peptide =[26,29]\n",
    "number_occurences = 11\n",
    "check_if_matches(refprot, pepseq, ptm_position_peptide, protseq,number_occurences)\n",
    "\n",
    "ptm_position_peptide =[2, 26,29]\n",
    "number_occurences = 2\n",
    "check_if_matches(refprot, pepseq, ptm_position_peptide, protseq,number_occurences)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
