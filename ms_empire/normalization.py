# AUTOGENERATED! DO NOT EDIT! File to edit: 02_normalization.ipynb (unless otherwise specified).

__all__ = ['normalize_withincond', 'get_bestmatch_pair', 'get_fcdistrib', 'determine_anchor_and_shift_sample',
           'shift_samples', 'get_total_shift', 'merge_distribs', 'mode_normalization', 'get_betweencond_shift',
           'get_normalized_dfs']

# Cell
from .visualizations import *
from .benchmarking import *

# Cell
import numpy as np
import matplotlib.pyplot as plt

def normalize_withincond(samples):

    "finds optimal scaling factors for samples measured in the same condition and corrects the samples by these scaling factors. Takes a 2d numpy array as input  "

    num_samples = samples.shape[0]
    mergedsamples = samples #the virtual "merged" samples will be stored in this array
    sampleidx2shift = dict(zip(range(num_samples), np.zeros(num_samples))) #the scaling factors applied to the samples are stored here
    sampleidx2counts = dict(zip(range(num_samples), np.ones(num_samples)))#keeps track of how many distributions are merged
    sampleidx2anchoridx = {} #keeps track of the shifted samples
    exclusion_set = set() #already clustered samples are stored here

    for rep in range(num_samples-1):

        anchor_idx, shift_idx, min_distance = get_bestmatch_pair(mergedsamples, exclusion_set, sampleidx2counts) #determine the closest pair of samples (one "shift" sample to be shifted and one "anchor sample which stays the same") and the distance between this pair
        #update the sets
        sampleidx2anchoridx.update({shift_idx : anchor_idx})
        sampleidx2shift.update({shift_idx : min_distance })
        exclusion_set.add(shift_idx)

        anchor_sample = samples[anchor_idx]
        shift_sample = samples[shift_idx]
        shifted_sample = shift_sample - min_distance
        merged_sample = merge_distribs(anchor_sample, shifted_sample, sampleidx2counts[anchor_idx], sampleidx2counts[shift_idx])
        sampleidx2counts[anchor_idx]+=1

    for i in range(num_samples):
        shift = get_total_shift(sampleidx2anchoridx, sampleidx2shift, i)
        samples[i] = samples[i]+shift

    return samples


# Cell
def get_bestmatch_pair(samples, exclusion_set, sample2counts):
    "finds the pair of samples whose median values are closest to each other"
    i_min=None
    j_min=None
    min_distance = float('inf')

    for i in range(samples.shape[0]):
        if(i in exclusion_set):#if a sample has already been merged, it is written in the exclusion set
            continue
        for j in range(i+1, samples.shape[0]):#do every comparison once
            if(j in exclusion_set):
                continue
            distance = np.nanmedian(get_fcdistrib(samples[i], samples[j])) #the median of the shifted distribution is taken as the distance measure
            if abs(distance) < min_distance:
                i_min = i
                j_min = j
                min_distance = distance

    return determine_anchor_and_shift_sample(sample2counts, i_min, j_min, min_distance)

# Cell
def get_fcdistrib(logvals_rep1, logvals_rep2):
    "generates difference distribution between two samples"
    dist = np.subtract(logvals_rep1, logvals_rep2)
    return dist


# Cell
def determine_anchor_and_shift_sample(sample2counts, i_min, j_min, min_distance):
    "given two samples, determine the sample with fewer merges as the shift"
    counts_i = sample2counts[i_min]
    counts_j = sample2counts[j_min]
    anchor_idx = i_min if counts_i>=counts_j else j_min #ask Max for more elegant solution
    shift_idx = j_min if anchor_idx == i_min else i_min
    flip = 1 if anchor_idx == i_min else -1
    return anchor_idx, shift_idx, flip*min_distance



# Cell
def shift_samples(samples, sampleidx2anchoridx, sample2shift):
    for sample_idx in range(samples.shape[0]):
        samples[sample_idx] = samples[sample_idx]+get_total_shift(sampleidx2anchoridx, sample2shift, sample_idx)


# Cell
def get_total_shift(sampleidx2anchoridx, sample2shift,sample_idx):

    total_shift = 0.0

    while(True):
        total_shift +=sample2shift[sample_idx]
        if sample_idx not in sampleidx2anchoridx: #every shifted sample has an anchor
            break
        sample_idx = sampleidx2anchoridx[sample_idx]

    return total_shift


# Cell
def merge_distribs(anchor_distrib, shifted_distrib,counts_anchor_distrib, counts_shifted_distrib):
    "Calculate the average peptide intensities to merge two peptide distributions"
    return (anchor_distrib *counts_anchor_distrib + shifted_distrib*counts_shifted_distrib)/(counts_anchor_distrib+counts_shifted_distrib)

# Cell
import numpy as np
from scipy.signal import find_peaks
import pandas as pd

def mode_normalization(x):

    x = np.sort(x)

    cumul_counts = np.linspace(0, len(x), len(x)) #cut away the most extreme fold changes
    cumul_counts_rel = cumul_counts/cumul_counts[-1]
    thresh = 0.05
    subset_vec = (cumul_counts_rel>thresh/2) & (cumul_counts_rel<1-thresh/2)
    x = x[subset_vec]

    x_min = min(x)
    x_max = max(x)
    num_bins = int((x_max-x_min)*50)
    bins = np.linspace(x_min, x_max, num_bins)
    hist = np.histogram(x, bins)
    x = hist[0]
    fcs =  0.5*(hist[1][1:]+hist[1][:-1]) #get middle of each fc bin
    cumul_x = np.cumsum(x)

    peaks2  = find_peaks(x, prominence=1)
    lbase = peaks2[1]['left_bases']
    rbase = peaks2[1]['right_bases']
    cumul_heights = cumul_x[rbase] - cumul_x[lbase]
    max_cumul_idx = np.argmax(cumul_heights)#returns the peak with the highest probabilty mass
    max_idx = peaks2[0][max_cumul_idx]
    shift_fc = hist[1][max_idx]

    return shift_fc

# Cell
import numpy as np
from scipy import stats

def get_betweencond_shift(df_c1_normed, df_c2_normed):

    both_idx = df_c1_normed.index.intersection(df_c2_normed.index)
    df1 = df_c1_normed.loc[both_idx]
    df2 = df_c2_normed.loc[both_idx]
    df1 = df1.median(axis = 1, skipna = True).to_frame()
    df2 = df2.median(axis = 1, skipna = True).to_frame()
    col1 = df1.columns[0]
    col2 = df2.columns[0]

    diff_fcs = df1[col1].to_numpy() - df2[col2].to_numpy()
    median = np.nanmedian(diff_fcs)
    mode = mode_normalization(diff_fcs)
    if(abs(median-mode) <0.05):
        print(f"using median for shift")
        return -median
    else:
        print(f"using mode for shift")
        return -mode


# Cell
import pandas as pd
def get_normalized_dfs(labelmap_df, unnormed_df,condpair, minrep, prenormed_file = None):

    c1_samples = labelmap_df[labelmap_df["condition"]== condpair[0]]
    c2_samples = labelmap_df[labelmap_df["condition"]== condpair[1]]
    df_c1 = unnormed_df.loc[:, c1_samples["sample"]].dropna(thresh=minrep, axis=0)
    df_c2 = unnormed_df.loc[:, c2_samples["sample"]].dropna(thresh=minrep, axis=0)
    df_c1_normed = None
    df_c2_normed = None

    if prenormed_file is not None:
        print("using pre-normalized data - skipping normalization")
        df_prenormed = pd.read_csv(prenormed_file, sep="\t",index_col = "peptide")
        df_c1_normed = df_prenormed[c1_samples["sample"]].dropna(thresh=minrep, axis=0)
        df_c2_normed = df_prenormed[c2_samples["sample"]].dropna(thresh=minrep, axis=0)
    else:
        df_c1_normed = pd.DataFrame(normalize_withincond(df_c1.to_numpy().T).T, index = df_c1.index, columns = c1_samples["sample"])
        df_c2_normed = pd.DataFrame(normalize_withincond(df_c2.to_numpy().T).T, index = df_c2.index, columns = c2_samples["sample"])

    display(c1_samples)

    #plot_betweencond_fcs(df_c1, df_c2, False)
    print(f"normalized within conditions")
    shift_between_cond = get_betweencond_shift(df_c1_normed, df_c2_normed)
    if(prenormed_file is not None):
        shift_between_cond = -0.18
    print(f"shift cond 2 by {shift_between_cond}")
    df_c2_normed = df_c2_normed-shift_between_cond
    #compare_normalization("./test_data/normed_intensities.tsv", df_c1_normed, df_c2_normed)
    plot_betweencond_fcs(df_c1_normed, df_c2_normed, False)
    plot_betweencond_fcs(df_c1_normed, df_c2_normed, True)
    return df_c1_normed, df_c2_normed