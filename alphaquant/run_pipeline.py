# AUTOGENERATED! DO NOT EDIT! File to edit: 01_diff_analysis_manager.ipynb (unless otherwise specified).

import os
import re
import pathlib
import pandas as pd
from itertools import combinations

import alphaquant.diffquant.diffutils as aqutils

import alphaquant.ptm.ptmsite_mapping as aqptm
import multiprocess
import alphaquant.config.variables as aqvariables
import alphabase.quantification.quant_reader.config_dict_loader as config_dict_loader
config_dict_loader.INTABLE_CONFIG = os.path.join(pathlib.Path(__file__).parent.absolute(), "./config/quant_reader_config.yaml")

import alphabase.quantification.quant_reader.quant_reader_manager as abquantreader
import alphaquant.diffquant.condpair_analysis as aqcondpair
import alphaquant.multicond.median_condition_creation as aqmediancreation
import alphaquant.multicond.median_condition_analysis as aqmediancond
import alphaquant.tables.misctables as aq_tablewriter_misc
import alphaquant.config.config as aqconfig
import logging
aqconfig.setup_logging()
LOGGER = logging.getLogger(__name__)



class ConfigOfRunPipeline:
    """Stores all the parameters given to the "run_pipeline" function"""
    def __init__(self, locals):
        for k, v in locals.items():
            setattr(self, k, v)


#abquantreader.set_quanttable_config_location(os.path.join(pathlib.Path(__file__).parent.absolute(), "./config/quant_reader_config.yaml"))

def run_pipeline(*,input_file = None, samplemap_file=None, samplemap_df = None, ml_input_file = None,modification_type = None, input_type_to_use = None,results_dir = "./results", multicond_median_analysis = False, 
                 condpairs_list = None, file_has_alphaquant_format = False, minrep_both = 2, minrep_either = None,minrep_c1 = None, minrep_c2 = None, min_num_ions = 1, minpep = 1, organism = None,
                 cluster_threshold_pval = 0.01, cluster_threshold_fcfc = 0, fcdiff_cutoff_clustermerge = 0.5, use_ml = True, take_median_ion = True, 
                 perform_ptm_mapping = False, perform_phospho_inference = False, outlier_correction = True, normalize = True, use_iontree_if_possible = True, write_out_results_tree = True, get_ion2clust = False, median_offset = False,
                 pre_normed_intensity_file = None, dia_fragment_selection = False, use_multiprocessing = False,runtime_plots = False, volcano_fdr =0.05, 
                 volcano_fcthresh = 0.5, annotation_columns = None, protein_subset_for_normalization_file = None, protnorm_peptides = True, peptides_to_exclude_file = None):

    """Run the differential analyses.
    """
    LOGGER.info("Starting AlphaQuant")
    check_input_consistency(input_file, samplemap_file, samplemap_df)
    aqvariables.determine_variables(input_file)

    if samplemap_df is None:
        samplemap_df = aqutils.load_samplemap(samplemap_file)

    if perform_ptm_mapping:
        if modification_type is None:
            raise Exception("modification_type is None, but perform_ptm_mapping is True. Please set perform_ptm_mapping to False or specify modification_type.")
        input_file = write_ptm_mapped_input(input_file=input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type, organism = organism)

    if "aq_reformat.tsv" not in input_file and not file_has_alphaquant_format:
        annotation_file = aq_tablewriter_misc.AnnotationFileCreator(input_file, input_type_to_use, annotation_columns).annotation_filename
        input_file = abquantreader.reformat_and_save_input_file(input_file, input_type_to_use = input_type_to_use, use_alphaquant_format=True)
        if peptides_to_exclude_file is not None:
            remove_peptides_to_exclude_from_input_file(input_file, peptides_to_exclude_file)

    if multicond_median_analysis:
        condpairs_list = aqmediancreation.get_all_conds_relative_to_median(samplemap_df)
        median_manager = aqmediancreation.MedianConditionManager(input_file, samplemap_file) #writes median condition to input file and samplemap file and overwrites the formatted input and samplemap file
        input_file = median_manager.input_filename_adapted
        samplemap_df = median_manager.samplemap_df_adapted
        del median_manager #delete the object as it needs not be in the runconfig
    
    #use runconfig object to store the parameters
    runconfig = ConfigOfRunPipeline(locals()) #all the parameters given into the function are transfered to the runconfig object!

    #store method parameters for reproducibility
    aqutils.remove_old_method_parameters_file_if_exists(results_dir)
    aqutils.store_method_parameters(locals(), results_dir)

    if runconfig.use_iontree_if_possible and use_ml and not ml_input_file:
        generate_and_save_ml_infos_if_possible(runconfig)

    if condpairs_list == None:
        conds = samplemap_df["condition"].unique()
        condpairs_list = combinations(conds, 2)
        
    num_cores = get_num_cores_to_use(use_multiprocessing)

    if num_cores == 1:
        run_analysis_singleprocess(condpair_combinations=condpairs_list, runconfig=runconfig)

    else:
        run_analysis_multiprocess(condpair_combinations=condpairs_list, runconfig=runconfig, num_cores=num_cores)
    
    if multicond_median_analysis:
        aqmediancond.analyze_and_write_median_condition_results(results_dir)



def generate_and_save_ml_infos_if_possible(runconfig):
    results_dir = runconfig.results_dir
    samplemap_df = runconfig.samplemap_df
    all_samples = aqutils.get_all_samples_from_samplemap_df(samplemap_df)
    samples_in_input = list(pd.read_csv(runconfig.input_file, sep = "\t", nrows = 1).columns)
    if len(set(all_samples).intersection(samples_in_input)) <2:
        raise Exception("The input file and the samplemap file show (almost) no overlap. Please check that the samplemap file is specified correctly.")
    dfinfos = aqutils.AcquisitionTableInfo(results_dir=results_dir)
    if dfinfos.file_exists:
        dfhandler = aqutils.AcquisitionTableHandler(table_infos=dfinfos,samples=all_samples)
        dfhandler.save_dataframe_as_new_acquisition_dataframe()
        dfhandler.update_ml_file_location_in_method_parameters_yaml()
    else:
        runconfig.use_ml = False

def get_num_cores_to_use(use_multiprocessing):
    num_cores = multiprocess.cpu_count() if use_multiprocessing else 1
    return min(num_cores, 10)

def run_analysis_singleprocess(condpair_combinations, runconfig):

    for condpair in condpair_combinations:
        aqcondpair.analyze_condpair(runconfig=runconfig, condpair=condpair)

def run_analysis_multiprocess(condpair_combinations, runconfig, num_cores):

    with multiprocess.Pool(num_cores) as pool:

        pool.map(lambda condpair :

        aqcondpair.analyze_condpair(runconfig= runconfig, condpair = condpair)

        ,condpair_combinations)



def write_ptm_mapped_input(input_file, results_dir, samplemap_df, modification_type, organism = "human"):
    try:
        aqptm.assign_dataset_inmemory(input_file = input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type, organism=organism)
    except:
        aqptm.assign_dataset_chunkwise(input_file = input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type, organism=organism)
    mapped_df = pd.read_csv(f"{results_dir}/ptm_ids.tsv", sep = "\t")
    ptm_mapped_file = aqptm.merge_ptmsite_mappings_write_table(input_file, mapped_df, modification_type)
    return ptm_mapped_file

def remove_peptides_to_exclude_from_input_file(input_file, peptides_to_exclude_file):
    df_input = pd.read_csv(input_file, sep = "\t")
    peptides_to_exclude = set(pd.read_csv(peptides_to_exclude_file, sep = "\t")["peptide"].tolist())
    pattern = r"SEQ_([A-Za-z0-9]+)_"
    try:
        df_input["peptide"] = [re.search(pattern, peptide).group(1) for peptide in df_input[aqvariables.QUANT_ID]]
    except:
        raise Exception("parsing of peptide sequence from QUANT_ID failed. The QUANT_ID column should contain the peptide sequence in the format SEQ_<peptide>_")
    
    not_in_peptides_to_exclude = ~df_input["peptide"].isin(peptides_to_exclude)
    df_input = df_input[not_in_peptides_to_exclude]
    df_input = df_input.drop(columns = ["peptide"])
    df_input.to_csv(input_file, sep = "\t", index = False)
    num_removed = len(not_in_peptides_to_exclude) - len(df_input.index)
    LOGGER.info(f"Excluded {num_removed} shared-species entries from input file")



def check_input_consistency(input_file, samplemap_file, samplemap_df):
    if input_file is None:
        raise Exception("no input file!")
    if samplemap_file is None and samplemap_df is None:
        raise Exception("Samplemap is missing!")
    return True


import alphaquant.diffquant.diffutils as aqutils
import alphabase.quantification.quant_reader.config_dict_loader as abconfigloader
def determine_if_ion_tree_is_used(runconfig):
    if runconfig.use_iontree_if_possible is not None:
        return runconfig.use_iontree_if_possible
    _, config_dict, _ =  abconfigloader.get_input_type_and_config_dict(runconfig.input_file)
    return config_dict.get("use_iontree")
