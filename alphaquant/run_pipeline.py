# AUTOGENERATED! DO NOT EDIT! File to edit: 01_diff_analysis_manager.ipynb (unless otherwise specified).

__all__ = ['ConfigOfRunPipeline', 'run_pipeline', 'min_num_ions', 'use_iontree_if_possible', 'annotation_file',
           'reformat_and_save_ml_dataframe', 'get_num_cores_to_use', 'run_analysis_singleprocess',
           'run_analysis_multiprocess', 'write_ptm_mapped_input', 'check_input_consistency', 'get_unnormed_df_condpair',
           'get_per_condition_dataframes', 'get_minrep_for_cond', 'determine_if_ion_tree_is_used', 'analyze_condpair',
           'QuantifiedResult', 'update_quantified_proteins_w_tree_results', 'add_fdr', 'get_results_df',
           'write_out_normed_df', 'read_tables']


class ConfigOfRunPipeline:
    """Stores all the parameters given to the "run_pipeline" function"""
    def __init__(self, locals):
        for k, v in locals.items():
            setattr(self, k, v)


import pandas as pd
from itertools import combinations

import alphaquant.diffquant.diffutils as aqutils

import alphaquant.ptm.ptmsite_mapping as aqptm
import multiprocess
import alphaquant.config.variables as aqvariables
import alphabase.quantification.quant_reader.quant_reader_manager as abquantreader
import alphaquant.diffquant.condpair_analysis as aqcondpair
import alphaquant.multicond.median_condition_creation as aqmediancreation
import alphaquant.multicond.median_condition_analysis as aqmediancond


def run_pipeline(*,input_file = None, samplemap_file=None, samplemap_df = None, ml_input_file = None,modification_type = None, input_type_to_use = None,results_dir = "./results", multicond_median_analysis = False, condpairs_list = None, file_has_alphaquant_format = False,
                 minrep = 2, min_num_ions = 1, minpep = 1, organism = None,
                 cluster_threshold_pval = 0.01, cluster_threshold_fcfc = 0, fcdiff_cutoff_clustermerge = 0.5, use_ml = True, take_median_ion = True, 
                 perform_ptm_mapping = False, perform_phospho_inference = False, outlier_correction = True, normalize = True, use_iontree_if_possible = True, write_out_results_tree = True, get_ion2clust = False, median_offset = False,
                 pre_normed_intensity_file = None, dia_fragment_selection = False, use_multiprocessing = False,runtime_plots = False, volcano_fdr =0.05, 
                 volcano_fcthresh = 0.5, annotation_file = None, protein_subset_for_normalization_file = None, protnorm_peptides = True):

    """Run the differential analyses.
    """

    check_input_consistency(input_file, samplemap_file, samplemap_df)
    aqvariables.determine_variables(input_file)

    if samplemap_df is None:
        samplemap_df = aqutils.load_samplemap(samplemap_file)

    if perform_ptm_mapping:
        if modification_type is None:
            raise Exception("modification_type is None, but perform_ptm_mapping is True. Please set perform_ptm_mapping to False or specify modification_type.")
        input_file = write_ptm_mapped_input(input_file=input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type, organism = organism)

    if "aq_reformat.tsv" not in input_file and not file_has_alphaquant_format:
        input_file = abquantreader.reformat_and_save_input_file(input_file, input_type_to_use = input_type_to_use, use_alphaquant_format=True)

    if multicond_median_analysis:
        condpairs_list = aqmediancreation.get_all_conds_relative_to_median(samplemap_df)
        median_manager = aqmediancreation.MedianConditionManager(input_file, samplemap_file) #writes median condition to input file and samplemap file and overwrites the formatted input and samplemap file
        input_file = median_manager.input_filename_adapted
        samplemap_df = median_manager.samplemap_df_adapted
        del median_manager #delete the object as it needs not be in the runconfig
    
    #use runconfig object to store the parameters
    runconfig = ConfigOfRunPipeline(locals()) #all the parameters given into the function are transfered to the runconfig object!

    #store method parameters for reproducibility
    aqutils.remove_old_method_parameters_file_if_exists(results_dir)
    aqutils.store_method_parameters(locals(), results_dir)

    if runconfig.use_iontree_if_possible and use_ml and not ml_input_file:
        generate_and_save_ml_infos_if_possible(runconfig)

    if condpairs_list == None:
        conds = samplemap_df["condition"].unique()
        condpairs_list = combinations(conds, 2)
        
    num_cores = get_num_cores_to_use(use_multiprocessing)

    if num_cores == 1:
        run_analysis_singleprocess(condpair_combinations=condpairs_list, runconfig=runconfig)

    else:
        run_analysis_multiprocess(condpair_combinations=condpairs_list, runconfig=runconfig, num_cores=num_cores)
    
    if multicond_median_analysis:
        aqmediancond.analyze_and_write_median_condition_results(results_dir)



def generate_and_save_ml_infos_if_possible(runconfig):
    results_dir = runconfig.results_dir
    samplemap_df = runconfig.samplemap_df
    all_samples = aqutils.get_all_samples_from_samplemap_df(samplemap_df)
    dfinfos = aqutils.AcquisitionTableInfo(results_dir=results_dir)
    if dfinfos.file_exists:
        dfhandler = aqutils.AcquisitionTableHandler(table_infos=dfinfos,samples=all_samples)
        dfhandler.save_dataframe_as_new_acquisition_dataframe()
        dfhandler.update_ml_file_location_in_method_parameters_yaml()
    else:
        runconfig.use_ml = False

def get_num_cores_to_use(use_multiprocessing):
    num_cores = multiprocess.cpu_count() if use_multiprocessing else 1
    return min(num_cores, 10)

def run_analysis_singleprocess(condpair_combinations, runconfig):

    for condpair in condpair_combinations:
        aqcondpair.analyze_condpair(runconfig=runconfig, condpair=condpair)

def run_analysis_multiprocess(condpair_combinations, runconfig, num_cores):

    with multiprocess.Pool(num_cores) as pool:

        pool.map(lambda condpair :

        aqcondpair.analyze_condpair(runconfig= runconfig, condpair = condpair)

        ,condpair_combinations)



def write_ptm_mapped_input(input_file, results_dir, samplemap_df, modification_type, organism = "human"):
    try:
        aqptm.assign_dataset_inmemory(input_file = input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type, organism=organism)
    except:
        aqptm.assign_dataset_chunkwise(input_file = input_file, results_dir=results_dir, samplemap_df=samplemap_df, modification_type=modification_type, organism=organism)
    mapped_df = pd.read_csv(f"{results_dir}/ptm_ids.tsv", sep = "\t")
    ptm_mapped_file = aqptm.merge_ptmsite_mappings_write_table(input_file, mapped_df, modification_type)
    return ptm_mapped_file



def check_input_consistency(input_file, samplemap_file, samplemap_df):
    if input_file is None:
        raise Exception("no input file!")
    if samplemap_file is None and samplemap_df is None:
        raise Exception("inputs inconsistent! Either file or dataframe needs to be specified!")
    return True


import alphaquant.diffquant.diffutils as aqutils
import alphabase.quantification.quant_reader.config_dict_loader as abconfigloader
def determine_if_ion_tree_is_used(runconfig):
    if runconfig.use_iontree_if_possible is not None:
        return runconfig.use_iontree_if_possible
    _, config_dict, _ =  abconfigloader.get_input_type_and_config_dict(runconfig.input_file)
    return config_dict.get("use_iontree")
