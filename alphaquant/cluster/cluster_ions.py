# AUTOGENERATED! DO NOT EDIT! File to edit: 09_cluster_ions.ipynb (unless otherwise specified).

__all__ = ['find_fold_change_clusters', 'exchange_cluster_idxs', 'decide_cluster_order',
           'get_score_mapping_consistency_score', 'get_score_mapping_num_clustelems', 'reformat_to_childnode2clust',
           'order_by_score', 'get_fcs_ions', 'evaluate_distance', 'create_hierarchical_ion_grouping', 'get_ionlist',
           'get_leafs', 'exclude_node', 'cluster_along_specified_levels', 'get_mainclust_leaves',
           'annotate_mainclust_leaves', 'assign_cluster_number', 'aggregate_node_properties',
           'get_feature_numpy_array_from_nodes', 'filter_fewpeps_per_protein', 'set_bounds_for_p_if_too_extreme',
           'get_median_peptides', 'select_predscore_with_minimum_absval', 'get_diffresults_from_clust_root_node',
           'get_scored_clusterselected_ions', 'assign_fcs_to_base_ions', 'update_nodes_w_ml_score',
           're_order_depending_on_predscore', 're_order_clusters_by_predscore', 'TypeFilter',
           'globally_initialized_typefilter', 'NodeProperties', 'regex_frgions_only', 'REGEX_FRGIONS_ISOTOPES',
           'export_roots_to_json']

# Cell
import scipy.spatial.distance as distance
import scipy.cluster.hierarchy as hierarchy
import alphaquant.cluster.cluster_utils as aqcluster_utils
import alphaquant.diffquant.diffutils as aqutils

REGEX_FRGIONS_ISOTOPES = [[("(SEQ.*MOD.*CHARGE.*FRG)(ION.*)", "frgion"), ("(SEQ.*MOD.*CHARGE.*MS1)(ISO.*)", "ms1_isotopes")], [("(SEQ.*MOD.*CHARGE.*)(FRG.*|MS1.*)", "mod_seq_charge")], [("(SEQ.*MOD.*)(CHARGE.*)", "mod_seq")], [("(SEQ.*)(MOD.*)", "seq")]]
LEVEL_NAMES = ['ion_type', 'mod_seq_charge', 'mod_seq', 'seq']
FCDIFF_CUTOFF_CLUSTERMERGE = 0.5



import numpy as np
class TypeFilter():
    def __init__(self, filttype= 'default'):
        if filttype=='default':
            self.type = ['frgion', 'ms1_isotopes', 'mod_seq_charge', 'mod_seq', 'seq', 'gene']
            self.mapping_dict = {'SEQ':'seq', 'MOD':'mod_seq', 'CHARGE':'mod_seq_charge', 'MS1ISOTOPES':'ms1_isotopes','FRGION':'frgion'}

globally_initialized_typefilter = TypeFilter()



def get_scored_clusterselected_ions(gene_name, diffions, normed_c1, normed_c2, ion2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold, take_median_ion,
                                    fcdiff_cutoff_clustermerge):
    #typefilter = TypeFilter('successive')

    global FCDIFF_CUTOFF_CLUSTERMERGE
    FCDIFF_CUTOFF_CLUSTERMERGE = fcdiff_cutoff_clustermerge

    name2diffion = {x.name : x for x in diffions}
    root_node = create_hierarchical_ion_grouping(REGEX_FRGIONS_ISOTOPES, LEVEL_NAMES,gene_name, diffions)
    add_reduced_names_to_root(root_node)
    #print(anytree.RenderTree(root_node))
    root_node_clust = cluster_along_specified_levels(globally_initialized_typefilter, root_node, name2diffion, normed_c1, normed_c2, ion2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold, take_median_ion)

    level_sorted_nodes = [[node for node in children] for children in anytree.ZigZagGroupIter(root_node_clust)]
    level_sorted_nodes.reverse() #the base nodes are first

    root_node_lvl = level_sorted_nodes[-1]
    if len(root_node_lvl)!=1:
        Exception("there should be only one root node!")

    root_node_annot =root_node_lvl[0]
    return root_node_annot


import anytree
import re
def create_hierarchical_ion_grouping(regex_patterns, level_names, gene_name, diffions):
    #regex patterns sorted from bottom to top in the following way list(list(tuple(pattern, name))): first instance of list represents the level of the tree, second instance represents the different nodes available on this level (for example FRgIon, MS1 are on the same level)

    nodes = [anytree.Node(x.name, type = "base", level = "base",cluster = -1, is_included = True) for x in diffions]

    for level_idx, level in enumerate(regex_patterns):
        name2node = {}
        for pattern2name in level:
            for node in nodes:
                if (re.match(pattern2name[0], node.name)):
                    level_name = level_names[level_idx]
                    m = re.match(pattern2name[0], node.name)
                    matching_name = m.group(1)
                    name2node[matching_name] = name2node.get(matching_name, anytree.Node(matching_name,  type = pattern2name[1], level = level_name,cluster = -1, is_included = True))
                    parent_node = name2node.get(matching_name)
                    node.parent = parent_node

        if len(name2node.keys())>0:
            nodes = list(name2node.values())

    root_node = anytree.Node(gene_name, type = "gene", level = "gene",cluster = 0, is_included = True)

    for node in nodes:
        node.parent = root_node

    return root_node

def add_reduced_names_to_root(node):
    for child in node.children:
        add_reduced_names_to_root(child)
    if node.parent:
        node.name_reduced = node.name.replace(node.parent.name, "")
    else:
        node.name_reduced = node.name
    

import pandas as pd
def cluster_along_specified_levels(typefilter, root_node, ionname2diffion, normed_c1, normed_c2, ion2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold, take_median_ion):#~60% of overall runtime
    #typefilter object specifies filtering and clustering of the nodes
    aqcluster_utils.assign_fcs_to_base_ions(root_node, ionname2diffion, normed_c1, normed_c2)

    for idx in range(len(typefilter.type)):
        type_nodes = anytree.search.findall(root_node, filter_=lambda node: node.type == typefilter.type[idx])

        if len(type_nodes)==0:
            continue
        for type_node in type_nodes:
            child_nodes = type_node.children
            diffions = aqcluster_utils.get_mainclust_leaves(child_nodes, ionname2diffion)
            if len(diffions)==0:
                exclude_node(type_node)
                continue
            
            if len(diffions)==1:
                childnode2clust = get_childnode2clust_for_single_ion(type_node)
            else:
                childnode2clust = find_fold_change_clusters(type_node, diffions, normed_c1, normed_c2, ion2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold, take_median_ion) #the clustering is performed on the child nodes
                childnode2clust = merge_similar_clusters(childnode2clust, type_node, fcdiff_cutoff_clustermerge = FCDIFF_CUTOFF_CLUSTERMERGE)
                childnode2clust = decide_cluster_order(type_node,childnode2clust)
            
            aqcluster_utils.assign_clusterstats_to_type_node(type_node, childnode2clust)
            aqcluster_utils.annotate_mainclust_leaves(childnode2clust)
            aqcluster_utils.assign_cluster_number(type_node, childnode2clust)
            aqcluster_utils.aggregate_node_properties(type_node,only_use_mainclust=True, use_fewpeps_per_protein=True)

    return root_node

def get_childnode2clust_for_single_ion(type_node):
    type_node.num_clusters = 1
    type_node.num_mainclusts = 1
    type_node.frac_mainclust = 1
    return {type_node.children[0]: 0}


def find_fold_change_clusters(type_node, diffions, normed_c1, normed_c2, ion2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold, take_median_ion):
    """Compares the fold changes of the ions corresponding to the nodes that are compared and returns the set of ions with consistent fold changes.

    Args:
        diffions (list[list[ionnames]]): contains the sets of ions to be tested, for example [[fragion1_precursor1, fragion2_precursor1, fragion3_precursor1],[fragion1_precursor2],[fragion1_precursor3, fragion2_precursor3]]. The ions are assumed to be similar in type (e.g. fragment, precursor)!
        normed_c1 (ConditionBackground): [description]
        normed_c2 (ConditionBackground): [description]
        ion2diffDist (dict(ion : SubtractedBackground)): [description]
        p2z ([type]): [description]
        deedpair2doublediffdist ([type]): [description]
        fc_threshold (float, optional): [description]. Defaults to 0.3.
        pval_threshold_basis (float, optional): [description]. Defaults to 0.05.
    """

    diffions_idxs = [[x] for x in range(len(diffions))]
    diffions_fcs = aqcluster_utils.get_fcs_ions(diffions)
    #mt_corrected_pval_thresh = pval_threshold_basis/len(diffions)
    condensed_distance_matrix = distance.pdist(diffions_idxs, lambda idx1, idx2: evaluate_distance(idx1[0], idx2[0], diffions, diffions_fcs, normed_c1, normed_c2, ion2diffDist,p2z, 
                                                                                                   deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold, take_median_ion))
    after_clust = hierarchy.complete(condensed_distance_matrix)
    clustered = hierarchy.fcluster(after_clust, 0.1, criterion='distance')
    clustered = aqcluster_utils.exchange_cluster_idxs(clustered)

    childnode2clust = [(type_node.children[ion_idx],clust_idx) for ion_idx, clust_idx in zip(list(range(len(clustered))),clustered)]
    childnode2clust = sorted(childnode2clust, key = lambda x : x[0].name) #sort list for reproducibility

    return childnode2clust


def merge_similar_clusters(childnode2clust, type_node, fcdiff_cutoff_clustermerge = 0.5):
    clust2childnodes = aqutils.invert_tuple_list_w_nonunique_values(childnode2clust)

    if len(clust2childnodes.keys())==1:
        return childnode2clust

    clust2fc = {}
    for clust, childnodes in clust2childnodes.items():
        clust2fc[clust] = np.median([x.fc for x in childnodes])

    clusters = list(clust2fc.keys())
    clust_idxs = [[x] for x in range(len(clusters))]

    condensed_distance_matrix = distance.pdist(clust_idxs, lambda idx1, idx2: compare_fcdistance(clusters, idx1, idx2, clust2fc))
    after_clust = hierarchy.complete(condensed_distance_matrix)
    clustered = hierarchy.fcluster(after_clust, fcdiff_cutoff_clustermerge, criterion='distance')

    childnode2clust = update_childnode2clust(childnode2clust, clusters, clustered)

    return childnode2clust


def compare_fcdistance(clusters, idx1, idx2, clust2fc):
    clust1 = clusters[idx1[0]]
    clust2 = clusters[idx2[0]]

    fc1 = clust2fc.get(clust1)
    fc2 = clust2fc.get(clust2)

    return abs(fc1-fc2)



def update_childnode2clust(childnode2clust, old_clusters, new_clusters):
    old2new = dict(zip(old_clusters, new_clusters))
    childnode2clust_new = []
    for childnode, old_clust in childnode2clust:
        new_clust = old2new[old_clust]
        childnode2clust_new.append((childnode, new_clust))
    return childnode2clust_new
    


# Cell
def decide_cluster_order(node, childnode2clust_init):
    """ranks the clusters from 0 to n (with 0 being the best) depending on the properties/similarities of the child nodes contained in each cluster
    """
    childnode2clust = order_by_score(childnode2clust_init,node, score_mapping_function=get_score_mapping_consistency_score)

    return childnode2clust

def order_by_score(childnode2clust_init, node, score_mapping_function, sort_descending_by_score = True):
    clust2score, clust2childnodes = score_mapping_function(childnode2clust_init)

    id2score2childnodes = []
    for clust in clust2score.keys():
        score = clust2score.get(clust)
        childnodes = clust2childnodes.get(clust)
        id = childnodes[0].name
        id2score2childnodes.append((id, score, childnodes))

    id2score2childnodes = sorted(id2score2childnodes, key= lambda x : x[0])#sort by id (to ensure reproducibility)
    id2score2childnodes = sorted(id2score2childnodes, key= lambda x : x[1], reverse= sort_descending_by_score)#then sort by score
    node.clustscore = id2score2childnodes[0][1] #annotate the parent of the childnodes with the score of the main cluster
    childnode2clust = reformat_to_childnode2clust(id2score2childnodes)

    return childnode2clust


def get_score_mapping_consistency_score(childnode2clust):
    clust2score = {}
    clust2childnodes = {}
    for childnode,clust in childnode2clust:
        clust2score[clust] = clust2score.get(clust, 0) + childnode.fraction_consistent*len(childnode.leaves)
        clust2childnodes[clust] = clust2childnodes.get(clust, []) + [childnode]
    return clust2score, clust2childnodes

def get_score_mapping_num_clustelems(childnode2clust):
    clust2score = {}
    clust2childnodes = {}
    for childnode,clust in childnode2clust:
        clust2score[clust] = clust2score.get(clust, 0) +1
        clust2childnodes[clust] = clust2childnodes.get(clust, []) + [childnode]
    return clust2score, clust2childnodes

def reformat_to_childnode2clust(id2score2childnodes):
    childnode2clust = {}
    for clust_idx_new in range(len(id2score2childnodes)): #the new cluster has been determined by the sorting
        for childnode in id2score2childnodes[clust_idx_new][2]:
            childnode2clust[childnode] = clust_idx_new
    return childnode2clust


# Cell
import statistics
import alphaquant.diffquant.doublediff_analysis as aqdd
import numpy as np
def evaluate_distance(idx1, idx2, diffions, fcs, normed_c1, normed_c2, ion2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis, fcfc_threshold,  take_median_ion):
    ions1 = [x.name for x in diffions[idx1]]
    ions2 = [x.name for x in diffions[idx2]]
    fc1 = fcs[idx1]
    fc2 = fcs[idx2]

    if abs((fc1-fc2)) < fcfc_threshold:
        return 0

    if take_median_ion:
        fcs_ions1 = [x.fc for x in diffions[idx1]]
        fcs_ions2 = [x.fc for x in diffions[idx2]]
        idx_ions1 = np.argsort(fcs_ions1)[len(fcs_ions1)//2]
        idx_ions2 = np.argsort(fcs_ions2)[len(fcs_ions2)//2]
        ions1 = [ions1[idx_ions1]]
        ions2 = [ions2[idx_ions2]]

    fcfc, pval = aqdd.calc_doublediff_score(ions1, ions2, normed_c1, normed_c2,ion2diffDist,p2z, deedpair2doublediffdist)
    if (pval<pval_threshold_basis) & (abs(fcfc) > fcfc_threshold):
        return 1
    else:
        return 0


# Cell
import anytree
def exclude_node(node):
    node.is_included = False
    for descendant in node.descendants:
        descendant.is_included = False


# Cell
import numpy as np
def update_nodes_w_ml_score(protnodes):
    typefilter = globally_initialized_typefilter
    for prot in protnodes:
        re_order_depending_on_predscore(prot, typefilter)


def re_order_depending_on_predscore(protnode, typefilter):
    for idx in range(len(typefilter.type)):
        type_nodes = anytree.search.findall(protnode, filter_=lambda node: node.type == typefilter.type[idx])
        if len(type_nodes)==0:
            continue
        for type_node in type_nodes: #go through the nodes, re-order the children. Propagate the values from the newly ordered children to the type node
            child_nodes = type_node.children
            had_predscore = hasattr(child_nodes[0], 'predscore')
            if had_predscore:
                re_order_clusters_by_predscore(child_nodes)
                aqcluster_utils.aggregate_node_properties(type_node,only_use_mainclust=True, use_fewpeps_per_protein=True)



def re_order_clusters_by_predscore(nodes):
    cluster2scores = {}
    for node in nodes:
        cluster2scores[node.cluster] = cluster2scores.get(node.cluster, [])
        cluster2scores[node.cluster].append(abs(node.predscore))
    clusters = list(cluster2scores.keys())
    clusters.sort(key = lambda x : 1/len(cluster2scores.get(x))) 
    clusters.sort(key = lambda x : np.nanmin(cluster2scores.get(x))) 
    clust2newclust = { clusters[x] :x for x in range(len(clusters))}
    for node in nodes:
        node.cluster =clust2newclust.get(node.cluster)
