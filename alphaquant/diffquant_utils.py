# AUTOGENERATED! DO NOT EDIT! File to edit: 08_diffquant_utils.ipynb (unless otherwise specified).

__all__ = ['get_condpairname', 'get_middle_elem', 'get_nonna_array', 'get_non_nas_from_pd_df', 'invert_dictionary',
           'get_relevant_columns', 'retrieve_configuration', 'get_config_columns', 'get_type2relevant_cols',
           'filter_input', 'merge_protein_and_ion_cols', 'reformat_longtable_according_to_config',
           'read_mq_peptides_table', 'prepare_table', 'add_ptmsite_infos_spectronaut',
           'add_ptm_precursor_names_spectronaut', 'import_data']

# Cell
def get_condpairname(condpair):
    return f"{condpair[0]}_VS_{condpair[1]}"

# Cell
def get_middle_elem(sorted_list):
    nvals = len(sorted_list)
    if nvals==1:
        return sorted_list[0]
    middle_idx = nvals//2
    if nvals%2==1:
        return sorted_list[middle_idx]
    return 0.5* (sorted_list[middle_idx] + sorted_list[middle_idx-1])

# Cell
import numpy as np
def get_nonna_array(array_w_nas):
    res = []
    isnan_arr = np.isnan(array_w_nas)

    for idx in range(len(array_w_nas)):
        sub_res = []
        sub_array = array_w_nas[idx]
        na_array = isnan_arr[idx]
        for idx2 in range(len(sub_array)):
            if not na_array[idx2]:
               sub_res.append(sub_array[idx2])
        res.append(np.array(sub_res))
    return np.array(res)

# Cell
import numpy as np
def get_non_nas_from_pd_df(df):
    # vals = df.values
    # result_dict = dict()
    # pep_names = df.index.values
    # for pep_name, sub_vals in zip(pep_names, vals):
    #     result_dict[pep_name] = sub_vals[~np.isnan(sub_vals)]
    # return result_dict
    return {
        pep_name: sub_vals[~np.isnan(sub_vals)] for pep_name, sub_vals in
        zip( df.index.values, df.values)
    }

# Cell
def invert_dictionary(my_map):
    inv_map = {}
    for k, v in my_map.iteritems():
        inv_map[v] = inv_map.get(v, []) + [k]
    return inv_map


# Cell
import yaml

def get_relevant_columns(grouping_cols, sample_ID, quant_ID, filter_dict):
    filtcols = []
    for filtconf in filter_dict.values():
        filtcols.append(filtconf.get('param'))
    relevant_cols = grouping_cols + [sample_ID] + [quant_ID] + filtcols
    relevant_cols = list(set(relevant_cols)) # to remove possible redudancies
    return relevant_cols


def retrieve_configuration(config_yaml, input_type):
    """collect the relevant parameters for a given type of input file (eg. DIA-NN type)"""
    stream = open(config_yaml, 'r')
    config_all = yaml.safe_load(stream)
    config_dict = config_all.get(input_type)
    return get_config_columns(config_dict)


def get_config_columns(config_dict):
    protein_cols = config_dict.get("grouping_cols").get("protein_cols")
    ion_cols = config_dict.get("grouping_cols").get("ion_cols")
    sample_ID = config_dict.get("sample_ID")
    quant_ID = config_dict.get("quant_ID")
    filter_dict = config_dict.get("filters")
    relevant_cols = get_relevant_columns(grouping_cols, sample_ID, quant_ID, filter_dict)
    return relevant_cols, protein_cols, ion_cols, sample_ID, quant_ID, filter_dict


def get_type2relevant_cols(config_yaml):
    stream = open(config_yaml, 'r')
    config_all = yaml.safe_load(stream)
    type2relcols = {}
    for type in config_all.keys():
        config_typedict = config_all.get(type)
        relevant_cols,_ = get_config_columns(config_typedict)
        type2relcols[type] = relevant_cols
    return type2relcols


# Cell

def filter_input(filter_dict, input_df):
    for filtname,filterconf in filter_dict.items():
        param = filterconf.get('param')
        comparator = filterconf.get('comparator')
        value = filterconf.get('value')

        if comparator not in [">",">=", "<", "<=", "==", "!="]:
            raise TypeError(f"cannot identify the filter comparator of {filtname} given in the longtable config yaml!")

        if comparator=="==":
            input = input[input[param] ==value]
            continue

        input = input.astype({f"{param}" : "float"})
        if comparator==">":
            input = input[input[param].astype(type(value)) >value]

        if comparator==">=":
            input = input[input[param].astype(type(value)) >=value]

        if comparator=="<":
            input = input[input[param].astype(type(value)) <value]

        if comparator=="<=":
            input = input[input[param].astype(type(value)) <=value]

        if comparator=="!=":
            input = input[input[param].astype(type(value)) !=value]

    return input

# Cell
def merge_protein_and_ion_cols(input_df, protein_cols, ion_cols):
    input_df['protein'] = input_df.loc[:, protein_cols].astype('string').sum(axis=1)
    input_df['ion'] = input_df.loc[:, ion_cols].astype('string').sum(axis=1)
    return input_df

# Cell

def reformat_longtable_according_to_config(input_file, input_type, results_folder = None, ptmsite_mapping = None, config_file = "longtable_config.yaml", sep = "\t",decimal = "."):
    """Reshape a long format proteomics results table (e.g. Spectronaut or DIA-NN) to a wide format table.
    :param file input_file: long format proteomic results table
    :param string input_type: the configuration key stored in the config file (e.g. "diann_precursor")
    """
    relevant_cols, protein_cols, ion_cols, sample_ID, quant_ID, filters = retrieve_configuration(config_file, input_type)

    input_df = pd.read_csv(input_file, sep = sep, decimal=decimal, usecols= relevant_cols).drop_duplicates()
    input_df = filter_input(filters, input_df)
    input_df = merge_protein_and_ion_cols(input_df, protein_cols, ion_cols)

    if ptmsite_mapping !=None:
        input_df = add_ptmsite_infos_spectronaut(input_df, results_folder)

    input_df = input_df.astype({f'{quant_value}': 'float'})
    input_reshaped = pd.pivot_table(input_df, index = ['protein', 'ion'], columns = sample_ID, values = quant_ID, fill_value=0)
    if input_reshaped.iloc[:,0].median() <100: #when values are small, rescale by a constant factor to prevent rounding errors in the subsequent aq analyses
        input_reshaped = input_reshaped *10000

    input_explicit = input_reshaped.reset_index()
    ion_level = "fragion" if "fragion" in input_file else "precursor"
    input_explicit.to_csv(f"{input_file}.aq_reformat.{ion_level}.tsv", index = False, sep = "\t")

    return input_explicit

# Cell
def read_mq_peptides_table(peptides_tsv, samplemap, pepheader = "Sequence", protheader = "Leading razor protein"):
    peps = pd.read_csv(peptides_tsv,sep="\t")
    peps = peps[peps["Reverse"] != "+"]
    peps = peps[peps["Potential contaminant"] != "+"]
    if pepheader != None:
        peps = peps.rename(columns = {pepheader : "ion"})
    if protheader != None:
        peps = peps.rename(columns = {protheader: "protein"})
    peps = peps.set_index("ion")
    headers = ['protein'] + samplemap["sample"].to_list()

    for sample in samplemap["sample"]:
        peps[sample] = np.log2(peps[sample].replace(0, np.nan))
    return peps[headers], samplemap

# Cell
def prepare_table(data_df, samplemap):

    data_df = data_df.set_index("ion")
    headers = ['protein'] + samplemap["sample"].to_list()
    for sample in samplemap["sample"]:
        data_df[sample] = np.log2(data_df[sample].replace(0, np.nan))
    return data_df[headers], samplemap

# Cell
import alphaquant.ptmsite_mapping as aqptm
def add_ptmsite_infos_spectronaut(input_df, results_folder):
    ptm_ids_df = aqptm.assign_dataset(input_df, results_folder= results_folder)
    intersect_columns = input_df.columns.intersection(ptm_ids.columns)
    if(len(intersect_columns)==2):
        print(f"assigning ptms based on columns {intersect_columns}")
        input_df = input_df.merge(ptm_ids_df, on=list(intersect_columns), how= 'left')
    else:
        raise Exception(f"Number of intersecting columns {intersect_columns} not as expected")
    input_df = add_ptm_precursor_names_spectronaut(input_df)
    return input_df

# Cell
def add_ptm_precursor_names_spectronaut(ptm_annotated_input):
    delimiter = pd.Series(["_" in range(len(ptm_annotated_input.index))])
    ptm_annotated_input["ion"] = ptm_annotated_input["PEP.StrippedSequence"] + delimiter + ptm_annotated_input["FG.PrecMz"] + delimiter + ptm_annotated_input["FG.Charge"] + delimiter + ptm_annotated_input["REFPROT"] + delimiter +ptm_annotated_input["site"]
    return ptm_annotated_input

# Cell
import pandas as pd
import os
import pkg_resources
import pathlib

def import_data(input_file, samplemap_file, output_folder = None, ptmsite_mapping = False,verbose=True, dashboard=False):
    """
    Function to import peptide level data. Depending on available columns in the provided file,
    the function identifies the type of input used (e.g. Spectronaut, MaxQuant, DIA-NN)
    """
    config_file = os.path.join(pathlib.Path(__file__).parent.absolute(), "..", "longtable_config.yaml") #the yaml config is located one directory below the python library files
    samplemap = pd.read_csv(samplemap_file, sep="\t")
    type2relevant_columns = get_type2relevant_cols(config_file)

    if dashboard:
        file = StringIO(str(file, "utf-8"))

    file_ext = os.path.splitext(file)[-1]
    if file_ext=='.csv':
        sep=','
    if file_ext=='.tsv':
        sep='\t'
    if file_ext=='.txt':
        sep='\t'
    if file_ext=='.xls':
        sep='\t'

    if "aq_reformat" in input_file:
        data = pd.read_csv(input_file, sep = "\t")
        data = prepare_table(data, samplemap)
        return data, samplemap

    uploaded_data_columns = set(pd.read_csv(input_file, sep=sep, nrows=1).columns)
    if (set(["Leading razor protein","Sequence", "Reverse", "Potential contaminant"]).issubset(uploaded_data_columns)) & (list(filter(lambda x : x.startswith("Intensity"), uploaded_data_columns))>4):
        if verbose:
            print("Import MaxQuant peptides table")
        data = read_mq_peptides_table(input_file, samplemap)
        return data, samplemap

    if set(type2relevant_columns.get("spectronaut_fragion")).issubset(uploaded_data_columns):
        if verbose:
            print("Spectronaut long format table detected. Importing and re-formating for fragment-level quantification.")
        data = reformat_longtable_according_to_config(input_file, input_type = "spectronaut_fragion", results_folder=results_folder, sep = sep, ptmsite_mapping=ptmsite_mapping,config_file=config_file)
        data = prepare_table(data, samplemap)
        return data, samplemap

    if set(type2relevant_columns.get("spectronaut_precursor")).issubset(uploaded_data_columns):
        if verbose:
            print("Spectronaut long format table detected. Importing and re-formating for precursor-level quantification.")
        data = reformat_longtable_according_to_config(input_file, input_type = "spectronaut_precursor", results_folder=results_folder, sep = sep, ptmsite_mapping=ptmsite_mapping,config_file=config_file)
        data = prepare_table(data, samplemap)
        return data, samplemap

    if set(type2relevant_columns.get("diann_precursor")).issubset(uploaded_data_columns):
        if verbose:
            print("DIA-NN long format table detected. Importing and re-formating for precursor-level quantification.")
        data = reformat_longtable_according_to_config(input_file, input_type = "diann_precursor", results_folder=results_folder, sep = sep, ptmsite_mapping=ptmsite_mapping,config_file=config_file)
        data = prepare_table(data, samplemap)
        return data, samplemap
    #if non of the cases match, return error
    raise TypeError(f'Input data format for {file} not known.')
