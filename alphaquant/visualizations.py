# AUTOGENERATED! DO NOT EDIT! File to edit: 05_visualizations.ipynb (unless otherwise specified).

__all__ = ['plot_pvals', 'plot_bgdist', 'tranform_fc2count_to_fc_space', 'plot_withincond_fcs', 'plot_betweencond_fcs',
           'scatter_df_columns', 'plot_cumhist_dfcols', 'compare_peptid_protein_overlaps', 'plot_fold_change',
           'get_volcanoplot_ckg', 'volcano_plot', 'get_melted_protein_ion_intensity_table', 'get_betweencond_fcs_table',
           'beeswarm_ion_plot', 'foldchange_ion_plot', 'get_iontree_img', 'get_normalization_overview_heatmap',
           'get_protein_regulation_heatmap', 'get_heatmapplot_ckg', 'compare_direction', 'compare_correlation',
           'get_condensed_distance_matrix', 'clustersort_numerical_arrays', 'compare_direction', 'compare_correlation',
           'clustersort_numerical_arrays', 'get_clustered_dataframe', 'get_sample_overview_dataframe',
           'get_diffresult_dataframe', 'get_diffresult_dict_ckg_format', 'subset_normed_peptides_df_to_condition',
           'get_normed_peptides_dataframe', 'initialize_sample2cond', 'read_condpair_tree']

# Cell
import alphaquant.diffquant_utils as utils

# Cell
import matplotlib.pyplot as plt
import numpy as np

def plot_pvals(result_df):
    pvals = result_df["peptide_pval"].to_list()
    plt.hist(pvals,99,cumulative=True,density=True, histtype='step')
    x = np.linspace(0,1,100)
    plt.plot(x, x)
    plt.show()

# Cell
from scipy.stats import norm
import matplotlib.pyplot as plt

def plot_bgdist(bgdist):
    fc2counts_rescaled = tranform_fc2count_to_fc_space(bgdist.fc2counts, bgdist.cumulative[-1],1/100.0)

    plt.bar(list(fc2counts_rescaled.keys()), fc2counts_rescaled.values(),width=0.01,color='g')
    axes2 = plt.twinx()
    x = np.linspace(-4, 4, 1000)
    axes2.plot(x, norm.pdf(x, 0, bgdist.SD)/1.15)
    axes2.set_ylim(0.0, 0.4)
    plt.show()

def tranform_fc2count_to_fc_space(fc2counts, num_fcs, rescale_factor):
    fc2counts_fcscales = {}
    for fc, count in fc2counts.items():
        fc2counts_fcscales[fc*rescale_factor] = count/num_fcs

    return fc2counts_fcscales

# Cell
#interactive

import matplotlib.pyplot as plt
import itertools

def plot_withincond_fcs(normed_intensity_df, cut_extremes = True, indiv_plots = False):
    """takes a normalized intensity dataframe and plots the fold change distribution between all samples. Column = sample, row = ion"""

    samplecombs = list(itertools.combinations(normed_intensity_df.columns, 2))

    for spair in samplecombs:#compare all pairs of samples
        s1 = spair[0]
        s2 = spair[1]
        diff_fcs = normed_intensity_df[s1].to_numpy() - normed_intensity_df[s2].to_numpy() #calculate fold changes by subtracting log2 intensities of both samples

        if cut_extremes:
            cutoff = max(abs(np.nanquantile(diff_fcs,0.025)), abs(np.nanquantile(diff_fcs, 0.975))) #determine 2.5% - 97.5% interval, i.e. remove extremes
            range = (-cutoff, cutoff)
        else:
            range = None
        plt.hist(diff_fcs,80,density=True, histtype='step',range=range) #set the cutoffs to focus the visualization
        plt.xlabel("log2 peptide fcs")
        if indiv_plots:
            plt.title(f"{s1}_vs_{s2}")
            plt.show()
    if not indiv_plots:
        plt.show()

# Cell
#interactive
import matplotlib.pyplot as plt
from scipy import stats

def plot_betweencond_fcs(df_c1_normed, df_c2_normed, merge_samples = True, indiv_plots= False):
    """takes normalized intensity dataframes of each condition and plots the distribution of direct peptide fold changes between conditions"""

    if merge_samples: #samples can be merged to median intensity
        df_c1_normed = df_c1_normed.median(axis = 1, skipna = True).to_frame()
        df_c2_normed = df_c2_normed.median(axis = 1, skipna = True).to_frame()

    both_idx = df_c1_normed.index.intersection(df_c2_normed.index)
    df1 = df_c1_normed.loc[both_idx]
    df2 = df_c2_normed.loc[both_idx]
    plt.xlabel("log2(fc)")
    for col1 in df1.columns:
        for col2 in df2.columns:
            diff_fcs = df1[col1].to_numpy() - df2[col2].to_numpy() #calculate fold changes by subtracting log2 intensities of both conditions

            plt.axvline(0, color = 'red', linestyle = "dashed") #the data is normalized around 0, draw in helper line
            cutoff = max(abs(np.nanquantile(diff_fcs,0.025)), abs(np.nanquantile(diff_fcs, 0.975))) #determine 2.5% - 97.5% interval, i.e. remove extremes

            plt.hist(diff_fcs,80,density=True, histtype='step', range=(-cutoff,cutoff)) #set the cutoffs to focus the visualization
            if indiv_plots:
                plt.title(f"{col1}_vs_{col2}")
                plt.show()
    if not indiv_plots:
        plt.show()

# Cell
import matplotlib.pyplot as plt
def scatter_df_columns(merged_df, log_axes = False):
    col = (0.2, 0.4, 0.6, 0.1)
    ref_columns = list(filter(lambda x : "_ref" in x, merged_df.columns.to_list())) #filter the reference columns from the merged df

    for ref in ref_columns:
        compare = ref.replace("_ref", "")
        ax_p = merged_df.plot.scatter(x=ref,y=compare, color = col)
        corr = merged_df[ref].corr(merged_df[compare])
        plt.title(f"{ref} vs. {compare} corr {corr}")
        x = np.linspace(0,merged_df[ref].max(),100)
        plt.plot(x, x)
        if log_axes:
            plt.xscale('log')
            plt.yscale('log')
        plt.show()

# Cell
import matplotlib.pyplot as plt
def plot_cumhist_dfcols(merged_df):
    col = (0.2, 0.4, 0.6, 0.4)
    ref_columns = list(filter(lambda x : "_ref" in x, merged_df.columns.to_list())) #filter the reference columns from the merged df

    for ref in ref_columns:
        compare = ref.replace("_ref", "")
        plt.hist(merged_df[ref], 100, density=True, histtype='step', label='reference')
        plt.hist(merged_df[compare], 100, density=True, histtype='step',label='compare')
        corr = merged_df[ref].corr(merged_df[compare])
        plt.title(f"{ref} vs. {compare} corr {corr}")
        plt.show()

# Cell
from matplotlib_venn import venn2
from matplotlib import pyplot as plt
def compare_peptid_protein_overlaps(protein_ref, protein_comp,peptide_ref, peptide_comp, peptide_name = "ion"):
    protIDs_ref = set(protein_ref["protein"].to_list())
    protIDs_comp = set(protein_comp["protein"].to_list())
    venn2([protIDs_ref, protIDs_comp], ('protIDs_ref', 'protIDs_comp'))
    plt.show()
    pepIDs_ref = set(peptide_ref[peptide_name].to_list())
    pepIDs_comp = set(peptide_comp[peptide_name].to_list())
    venn2([pepIDs_ref, pepIDs_comp], ('pepIDs_ref', 'pepIDs_comp'))
    plt.show()

# Cell
import matplotlib.pyplot as plt
import seaborn as sns

def plot_fold_change(df, key1, key2):
    to_plot = df.copy()
    to_plot[f'Ratio ({key1}/{key2})'] = np.log2(to_plot[key1] / to_plot[key2])
    to_plot[f'Inten_{key1}'] = np.log10(to_plot[key1])

    species = 'Human'
    val = to_plot.loc[to_plot['species']==species, f'Ratio ({key1}/{key2})'].values
    val = val[~np.isnan(val)&~np.isinf(val)&~np.isneginf(val)]
    print(f'Species={species}, n={len(val)}, median={np.median(val)}, dev={np.std(val)}')
    species='Ecoli'
    val = to_plot.loc[to_plot['species']==species, f'Ratio ({key1}/{key2})'].values
    val = val[~np.isnan(val)&~np.isinf(val)&~np.isneginf(val)]
    print(f'species={species}, n={len(val)}, median={np.median(val)}, dev={np.std(val)}')

    plt.figure(figsize=(7,7))
    ax = sns.scatterplot(x=f'Ratio ({key1}/{key2})', y=f'Inten_{key1}', hue="species", data=to_plot, alpha=0.5)
    plt.title('Fold Change')
    plt.xlim([-4.5, 6.5])
    #plt.ylim([6,11.5])
    plt.show()


# Cell

import dash_core_components as dcc
import plotly.graph_objs as go
#interactive
#ckg_copypaste, defaults added for args argument
def get_volcanoplot_ckg(results, args = {'x_title':'log2FC', 'y_title':'-log10FDR','colorscale':'Blues', 'showscale':True, 'marker_size':7, 'fc' :0.5}):
    """
    This function plots volcano plots for each internal dictionary in a nested dictionary.
    :param dict[dict] results: nested dictionary with pairwise group comparisons as keys and internal dictionaries containing 'x' (log2FC values), \
                                'y' (-log10 p-values), 'text', 'color', 'pvalue' and 'annotations' (number of hits to be highlighted).
    :param dict args: see below.
    :Arguments:
        * **fc** (float) -- fold change threshold.
        * **range_x** (list) -- list with minimum and maximum values for x axis.
        * **range_y** (list) -- list with minimum and maximum values for y axis.
        * **x_title** (str) -- plot x axis title.
        * **y_title** (str) -- plot y axis title.
        * **colorscale** (str) -- string for predefined plotly colorscales or dict containing one or more of the keys listed in \
                                    https://plot.ly/python/reference/#layout-colorscale.
        * **showscale** (bool) -- determines whether or not a colorbar is displayed for a trace.
        * **marker_size** (int) -- sets the marker size (in px).
    :return: list of volcano plot figures within the <div id="_dash-app-content">.
    Example::
        result = get_volcanoplot(results, args={'fc':2.0, 'range_x':[0, 1], 'range_y':[-1, 1], 'x_title':'x_axis', 'y_title':'y_title', 'colorscale':'Blues', \
                                'showscale':True, 'marker_size':7})
    """
    figures = []
    for identifier,title in results:
        result = results[(identifier,title)]
        figure = {"data":[],"layout":None}
        if "range_x" not in args:
            range_x = [-max(abs(result['x']))-0.1, max(abs(result['x']))+0.1]#if symmetric_x else []
        else:
            range_x = args["range_x"]
        if "range_y" not in args:
            range_y = [0,max(abs(result['y']))+1.]
        else:
            range_y = args["range_y"]
        traces = [go.Scatter(x=result['x'],
                        y=result['y'],
                        mode='markers',
                        text=result['text'],
                        hoverinfo='text',
                        marker={'color':result['color'],
                                'colorscale': args["colorscale"],
                                'showscale': args['showscale'],
                                'size': args['marker_size'],
                                'line': {'color':result['color'], 'width':2}
                                }
                        )]
        shapes = []
        if ('is_samr' in result and not result['is_samr']) or 'is_samr' not in result:
            shapes = [{'type': 'line',
                      'x0': np.log2(args['fc']),
                      'y0': 0,
                      'x1': np.log2(args['fc']),
                      'y1': range_y[1],
                      'line': {
                          'color': 'grey',
                          'width': 2,
                          'dash':'dashdot'
                          },
                      },
                    {'type': 'line',
                     'x0': -np.log2(args['fc']),
                     'y0': 0,
                     'x1': -np.log2(args['fc']),
                     'y1': range_y[1],
                     'line': {
                         'color': 'grey',
                         'width': 2,
                         'dash': 'dashdot'
                         },
                     },
                    {'type': 'line',
                     'x0': -max(abs(result['x']))-0.1,
                     'y0': result['pvalue'],
                     'x1': max(abs(result['x']))+0.1,
                     'y1': result['pvalue'],
                     'line': {
                         'color': 'grey',
                         'width': 1,
                         'dash': 'dashdot'
                         },
                     }]
            #traces.append(go.Scattergl(x=result['upfc'][0], y=result['upfc'][1]))
            #traces.append(go.Scattergl(x=result['downfc'][0], y=result['downfc'][1]))

        figure["data"] = traces
        figure["layout"] = go.Layout(title=title,
                                        xaxis={'title': args['x_title'], 'range': range_x},
                                        yaxis={'title': args['y_title'], 'range': range_y},
                                        hovermode='closest',
                                        shapes=shapes,
                                        width=950,
                                        height=1050,
                                        annotations = result['annotations']+[dict(xref='paper', yref='paper', showarrow=False, text='')],
                                        template='plotly_white',
                                        showlegend=False)

        figures.append(dcc.Graph(id= identifier, figure = figure))
    return figures


# Cell
#interactive
import matplotlib.pyplot as plt

import numpy as np

def volcano_plot(result_df, fc_header = "log2fc", fdr_header = "fdr", significance_cutoff = 0.05, log2fc_cutoff = 0.5,ybound = None, xbound =None):
    result_df[fdr_header] = result_df[fdr_header].replace(0, np.min(result_df[fdr_header].replace(0, 1.0)))
    fdrs = result_df[fdr_header].to_numpy()
    fcs = result_df[fc_header].to_numpy()
    sighits_down = sum((fdrs<significance_cutoff) & (fcs <= -log2fc_cutoff))
    sighits_up = sum((fdrs<significance_cutoff) & (fcs >= log2fc_cutoff))
    plt.title(f"{sighits_up} up, {sighits_down} down of {len(fcs)}")
    plt.scatter(result_df[fc_header],-np.log10(result_df[fdr_header]),s=10, c='grey', alpha = 0.1)
    plt.xlabel('log2 FC',fontsize = 14)
    plt.ylabel('-log10 FDR',fontsize = 14)

    if ybound==None:
        plt.ylim(0,max(-np.log10(result_df[fdr_header]))+0.5)
    else:
        plt.ylim(ybound)
    if significance_cutoff>0:
        plt.axhline(y=-np.log10(significance_cutoff), color='g', linestyle='-')
    if log2fc_cutoff >0:
        plt.axvline(x=log2fc_cutoff, color='g', linestyle='-')
        plt.axvline(x=-log2fc_cutoff, color='g', linestyle='-')
    maxfc = max(abs(result_df[fc_header]))+0.5
    if xbound==None:
        plt.xlim(-maxfc,maxfc)
    else:
        plt.xlim(xbound)
    plt.show()


# Cell
import anytree
def get_melted_protein_ion_intensity_table(protein, diffresults_df, normed_df, sample2cond, condpair_root_node = None,ion_header = 'ion', protein_header = 'protein'):
    diffresults_line = diffresults_df.loc[protein]
    value_vars = set.intersection(set(normed_df.columns), set(sample2cond.keys()))
    protein_df = normed_df.xs(protein, level = 0)
    df_melted = pd.melt(protein_df.reset_index(), value_vars= value_vars, id_vars=[ion_header], value_name="intensity", var_name="sample")
    df_melted["condition"] = [sample2cond.get(x) for x in df_melted["sample"]]

    #if ion clustering has been performed, add cluster information
    if condpair_root_node != None:

        protein_node = anytree.findall_by_attr(condpair_root_node, protein, maxlevel=2)[0]
        ions_sorted = [x.name for x in protein_node.leaves]
        ion2is_included = {x.name : x.is_included for x in protein_node.leaves} #written as dict because identical ion has multiple columns
        ions_in_df = set(df_melted["ion"]) - set(ions_sorted)
        if len(ions_in_df)>0:
            Exception("Clustered ions and observed ions differ!")

        df_melted = df_melted.set_index("ion")
        df_melted = df_melted.loc[ions_sorted]
        df_melted["is_included"] = [ion2is_included.get(x) for x in df_melted.index]
        df_melted = df_melted.reset_index()

    return df_melted, diffresults_line


# Cell

def get_betweencond_fcs_table(melted_df, c1, c2, ion_header = "ion"):
    has_clust_info = "is_included" in melted_df.columns
    melted_df = melted_df.set_index(["condition"])
    sorted_ions = melted_df["ion"]
    c1_df = melted_df.loc[c1]
    c2_df = melted_df.loc[c2]
    ions = set(c1_df[ion_header]).intersection(set(c2_df[ion_header]))
    sorted_ions = [x for x in sorted_ions if x in ions]
    c1_df = c1_df.set_index([ion_header]).sort_index()
    c2_df = c2_df.set_index([ion_header]).sort_index()
    result_ions = []
    result_fcs = []
    result_included = []
    for ion in sorted_ions:
        is_included = c1_df.loc[ion]["is_included"][0] if has_clust_info else True

        ions1 = c1_df.loc[[ion]]["intensity"]
        ions2 = c2_df.loc[[ion]]["intensity"]
        fcs = [x-y for x,y in itertools.product(ions1, ions2)]
        result_ions.extend([ion for x in range(len(fcs))])
        result_fcs.extend(fcs)
        result_included.extend([is_included for x in range(len(fcs))])

    res_df = pd.DataFrame({"ion": result_ions, "log2fc": result_fcs, "is_included" : result_included})

    return res_df

# Cell
#interactive
import seaborn as sns
import matplotlib.pyplot as plt

def beeswarm_ion_plot(df_melted, diffresults_protein, saveloc = None):
    """takes pre-formatted long-format dataframe which contains all ion intensities for a given protein.
      Columns are "ion", "intensity", "condition". Also takes results of the protein differential analysis as a series
      to annotate the plot"""

    #get annotations from diffresults
    fdr = float(diffresults_protein.at["fdr"])
    protein = diffresults_protein.name

    #define greyscale color palette for the two conditions
    pal2 = [(0.94, 0.94, 0.94),(1.0, 1.0, 1.0)]

    #searborn standard functions
    ax = sns.boxplot(x="ion", y="intensity", hue="condition", data=df_melted, palette=pal2)
    ax = sns.stripplot(x="ion", y="intensity", hue="condition", data=df_melted, palette="Set2", dodge=True)#size = 10/len(protein_df.index)

    #annotate and format
    handles, labels = ax.get_legend_handles_labels()

    l = plt.legend(handles[2:4], labels[2:4])

    plt.xticks(rotation=90)
    if "gene" in diffresults_protein.index:
        gene = diffresults_line.at["gene"]
        plt.title(f"{gene} ({protein}) FDR: {fdr:.1e}")
    else:
        plt.title(f"{protein} FDR: {fdr:.1e}")
    if saveloc is not None:
        plt.savefig(saveloc)

    plt.show()

# Cell
#interactive
import seaborn as sns
import matplotlib.pyplot as plt

def foldchange_ion_plot(df_melted, diffresults_protein, saveloc = None):
    """takes pre-formatted long-format dataframe which contains all between condition fold changes. All ions of a given protein
    are visualized, the columns are "ion" and "log2fc".  Also takes results of the protein differential analysis as a series
      to annotate the plot"""
    num_ions = len(set(df_melted["ion"]))

    if num_ions>30:
        plt.figure(figsize=(num_ions*0.7, num_ions*0.2))

    #get annotations from diffresults
    fdr = float(diffresults_protein.at["fdr"])
    protein = diffresults_protein.name

    #define greyscale color palette
    pal2 = [(0.94, 0.94, 0.94),(1.0, 1.0, 1.0)]

    #plot with seaborn standard functions
    ax = sns.boxplot(x="ion", y="log2fc", hue= "is_included",data=df_melted) #color = "white"
    ax = sns.stripplot(x="ion", y="log2fc",hue= "is_included", data=df_melted)#, color = "grey"

    #annotate and format
    handles, labels = ax.get_legend_handles_labels()
    ax.axhline(y = 0, color='black', linewidth=2, alpha=.7, linestyle = "dashed")
    l = plt.legend(handles[2:4], labels[2:4])
    plt.xticks(rotation=90)
    if "gene" in diffresults_protein.index:
        gene = diffresults_line.at["gene"]
        plt.title(f"{gene} ({protein}) FDR: {fdr:.1e}")
    else:
        plt.title(f"{protein} FDR: {fdr:.1e}")
    if saveloc is not None:
        plt.savefig(saveloc)


    plt.show()

# Cell
from anytree.exporter import DotExporter
import anytree

def get_iontree_img(root, protein,saveloc = None):
    protein_node = anytree.findall_by_attr(root, protein, maxlevel=2)[0]
    exporter = DotExporter(protein_node, nodenamefunc=lambda n: f"{n.name}\ncluster{n.cluster}\n{n.is_included}")
    exporter.to_picture(saveloc)

# Cell
#interactive
import itertools
import pandas as pd
import numpy as np
import holoviews as hv
hv.extension('bokeh')


def get_normalization_overview_heatmap(normed_peptides_df):
    """Compares the normed intensities of the samples pairwise and clusters by sample similarity.
    The sample similarity matrix is then visualized as a heatmap"""

    samples = list(normed_peptides_df.columns)
    #initialize matrix for sample similarities
    result_2dnp = np.zeros((len(samples), len(samples)))

    #go over each sample pair
    for idxpair in itertools.combinations(range(len(samples)), 2):
        s1 = samples[idxpair[0]]
        s2 = samples[idxpair[1]]

        #calculate fold changes for each ion by subtracting log2 intensities of both samples
        difference_distrib = normed_peptides_df[s1].to_numpy() - normed_peptides_df[s2].to_numpy()

        #take variance of fold change distribution as distance (high variance -> dissimilar samples)
        distance = np.nanvar(difference_distrib)

        #assign distances to the respective matrix elements (symmetric)
        result_2dnp[idxpair[0]][idxpair[1]] = distance
        result_2dnp[idxpair[1]][idxpair[0]] = distance

    #annotate matrix
    res_df = pd.DataFrame(result_2dnp, index=samples, columns=samples)

    #cluster
    clust_df = get_clustered_dataframe(res_df)
    heatmap = hv.HeatMap(clust_df, label='Sample similarities')
    #heatmap.opts(opts.HeatMap(tools=['hover'], colorbar=True, width=325, toolbar='above', clim=(-2, 2)))

    return heatmap

# Cell
#interactive
import os
import holoviews as hv
import pandas as pd
hv.extension('bokeh')

def get_protein_regulation_heatmap(overview_df, results_folder = os.path.join(".", "results")):
    """Takes the overview dataframe, which annotates the proteins regulated for each condition. Index = condpair, column = protein.
    Clusters and visualizes as heatmap."""
    clustered_df = get_clustered_dataframe(overview_df).reset_index()
    if results_folder != None:
        clustered_df.to_csv(os.path.join(results_folder, "regulation_overview.tsv"), sep = "\t", index = None)
    plot_df = pd.melt(clustered_df, id_vars='index')
    heatmap = hv.HeatMap(plot_df, label='Regulation overview')
    #heatmap.opts(opts.HeatMap(tools=['hover'], colorbar=True, width=325, toolbar='above', clim=(-2, 2)))
    return heatmap

# Cell
import dash_core_components as dcc
import plotly.graph_objs as go
#interactive
#ckg_copypaste
def get_heatmapplot_ckg(data, identifier= "Heatmap", args = {'format' :'default', 'title' : 'heatmap'}):
    """
    This function plots a simple Heatmap.
    :param data: is a Pandas DataFrame with the shape of the heatmap where index corresponds to rows \
                and column names corresponds to columns, values in the heatmap corresponds to the row values.
    :param str identifier: is the id used to identify the div where the figure will be generated.
    :param dict args: see below.
    :Arguments:
        * **format** (str) -- defines the format of the input dataframe.
        * **source** (str) -- name of the column containing the source.
        * **target** (str) -- name of the column containing the target.
        * **values** (str) -- name of the column containing the values to be plotted.
        * **title** (str) -- title of the figure.
    :return: heatmap figure within the <div id="_dash-app-content">.
    Example::
        result = get_heatmapplot(data, identifier='heatmap', args={'format':'edgelist', 'source':'node1', 'target':'node2', 'values':'score', 'title':'Heatmap Plot'})
    """
    df = data.copy()
    if args['format'] == "edgelist":
        df = df.set_index(args['source'])
        df = df.pivot_table(values=args['values'], index=df.index, columns=args['target'], aggfunc='first')
        df = df.fillna(0)
    figure = {}
    figure["data"] = []
    figure["layout"] = {"title":args['title'],
                        "height": 500,
                        "width": 700,
                        "annotations" : [dict(xref='paper', yref='paper', showarrow=False, text='')],
                        "template":'plotly_white'}
    figure['data'].append(go.Heatmap(z=df.values.tolist(),
                                    x = list(df.columns),
                                    y = list(df.index)))

    return dcc.Graph(id = identifier, figure = figure)


# Cell
import numpy.ma as ma
import scipy.cluster.hierarchy as hierarchy

def compare_direction(array1, array2):
    identical_elements  = array1 == array2
    num_same_direction = np.sum(identical_elements)
    return num_same_direction

def compare_correlation(array1, array2):
    corr = ma.corrcoef(ma.masked_invalid(array1), ma.masked_invalid(array2))[0][1]
    return corr

def get_condensed_distance_matrix(arrays, compare_function):

    res = np.ones(int(len(arrays) * (len(arrays)-1)/2))
    count = 0
    for i in range(len(arrays)):
        for j in range(i+1, len(arrays)):
            array1 = arrays[i]
            array2 = arrays[j]
            distance = 1/compare_function(array1, array2)
            res[count] = distance
            count+=1

    return res

def clustersort_numerical_arrays(arrays, names , cluster_method ='average',compare_function = compare_direction):
    condensed_distance_matrix = get_condensed_distance_matrix(arrays, compare_function)
    linkage_matrix = hierarchy.linkage(condensed_distance_matrix, method = cluster_method)
    sorted_array_idxs = hierarchy.leaves_list(linkage_matrix)

    sorted_array = [arrays[x] for x in sorted_array_idxs]
    sorted_names = [names[x] for x in sorted_array_idxs]
    return sorted_array, sorted_names, linkage_matrix








# Cell
import numpy as np
def compare_direction(array1, array2):
    identical_elements  = array1 == array2
    num_same_direction = np.sum(identical_elements)
    return num_same_direction


# Cell
import numpy.ma as ma
def compare_correlation(array1, array2):
    corr = ma.corrcoef(ma.masked_invalid(array1), ma.masked_invalid(array2))[0][1]
    return corr

# Cell

import scipy.cluster.hierarchy as hierarchy
import scipy.spatial.distance as dist
def clustersort_numerical_arrays(arrays, names , cluster_method ='average',compare_function = compare_direction):
    #condensed_distance_matrix = get_condensed_distance_matrix(arrays, compare_function)
    condensed_distance_matrix = dist.pdist(arrays, lambda u, v: 1/(compare_function(u,v)+1))
    linkage_matrix = hierarchy.linkage(condensed_distance_matrix, method = cluster_method)
    sorted_array_idxs = hierarchy.leaves_list(linkage_matrix)

    sorted_array = np.array([arrays[x] for x in sorted_array_idxs])
    sorted_names = np.array([names[x] for x in sorted_array_idxs])
    return sorted_array, sorted_names, linkage_matrix


# Cell

import pandas as pd
import numpy as np
import os
def get_clustered_dataframe(overview_df, cluster_method ='average',compare_function = compare_direction, clust_rows = True, clust_columns = True):

    df_numbered = overview_df.select_dtypes(include=np.number)
    contains_floats = ['float' in str(x) for x in df_numbered.dtypes]
    type = 'float' if True in contains_floats else 'int'
    df_numbered = df_numbered.astype(type) #ensure that the df has no mixed types

    rows = df_numbered.to_numpy()
    rownames = list(df_numbered.index)
    colnames = list(df_numbered.columns)

    if clust_rows:
        if(len(rownames)>10000):
            print(f"large number of rows, skipping cluster step of rows to avoid long runtime.")
        else:
            print(f"clustering on {len(rownames)} rows")
            rows, rownames, _ = clustersort_numerical_arrays(rows, rownames, cluster_method, compare_function)
    if clust_columns:
        if(len(colnames)>10000):
            print(f"large number of columns, skipping cluster step of columns to avoid long runtime")
        else:
            print(f"clustering on {len(colnames)} columns")
            columns, colnames,_ = clustersort_numerical_arrays(rows.T, colnames, cluster_method, compare_function)
            rows = columns.T
    print("finished clustering")
    df_clustered = pd.DataFrame(rows, index= rownames)
    df_clustered.columns = colnames
    return df_clustered


# Cell
import re
import os
def get_sample_overview_dataframe(results_folder = os.path.join(".", "results"), regulated_object = "protein",condpairs_to_compare = []):
    """
    goes through the results folder and extracts up- and downregulated genes for each (specified) condition comparison
    """

    if len(condpairs_to_compare) == 0:
        condpairs_to_compare = [f.replace(".results.tsv", "").split("_VS_") for f in os.listdir(results_folder) if re.match(r'.*results.tsv', f)]

    dfs = []
    count = 0
    for row in condpairs_to_compare:
        c1 = row[0]
        c2 = row[1]
        results = get_diffresult_dataframe(c1, c2, results_folder)
        if(type(results) == type(None)):
            continue
        site_df = results
        positive_sites = list(set(site_df[(site_df["fdr"]<0.05) & (site_df["log2fc"]>0.5)][regulated_object]))
        negative_sites = list(set(site_df[(site_df["fdr"]<0.05) & (site_df["log2fc"]<-0.5)][regulated_object]))
        df_loc = pd.DataFrame([[1 for x in range(len(positive_sites))]+[-1 for x in range(len(negative_sites))]],columns=positive_sites+negative_sites)
        df_loc["condpair"] = utils.get_condpairname([c1, c2])
        #df_loc["num_regulated"] = len(positive_sites) + len(negative_sites)
        dfs.append(df_loc)
        #print(count)
        count+=1

    result_df = pd.concat(dfs)
    result_df = result_df.replace(np.nan, 0).set_index("condpair")

    return result_df


# Cell
import pandas as pd
import os
import numpy as np

def get_diffresult_dataframe(cond1, cond2, results_folder = os.path.join(".", "results")):
    """
    reads the results dataframe for a given condpair
    """
    condpair = utils.get_condpairname([cond1, cond2])
    diffresults = os.path.join(results_folder, f"{condpair}.results.tsv")

    try:
        diffprots = pd.read_csv(diffresults, sep = "\t")
    except:
        print(f"no quantfiles found for {condpair}!")
        return None
    diffprots = diffprots[(diffprots["condpair"] == condpair)]

    diffprots["-log10fdr"] = -np.log10(diffprots["fdr"])
    #diffprots = diffprots.set_index("protein")

    return diffprots

# Cell
import alphaquant.diffquant_utils as aqutils
import numpy as np

def get_diffresult_dict_ckg_format(cond1, cond2, results_folder = os.path.join(".", "results")):
    """
    ckg wrapper, reads the results dataframe for a given condpair and reformats it to the ckg volcano plot input format
    """
    result_df = get_diffresult_dataframe(cond1, cond2, results_folder)
    log2fcs = result_df["log2fc"].to_numpy()
    logged_fdrs = result_df["-log10fdr"].to_numpy()
    min_fdr = np.min(logged_fdrs)
    result_ckg_dict = {}
    result_ckg_dict[("volcano", aqutils.get_condpairname([cond1, cond2]))] = {"x": log2fcs, "y" : np.array([1.2,3.3,1,3,4,5,6]), "pvalue" : min_fdr, "text" : "testext", "color" : "grey",'is_samr':False, 'annotations' : []}
    return result_ckg_dict

# Cell
import pandas as pd
def subset_normed_peptides_df_to_condition(cond, sample2cond_df, normed_df):
    columns_to_keep = set(sample2cond_df[sample2cond_df["condition"]==cond]["sample"]).intersection(set(normed_df.columns))
    columns_to_drop = set(normed_df.columns) - columns_to_keep
    subset_df = normed_df.drop(columns = columns_to_drop)
    return subset_df



# Cell
import pandas as pd
import os
import numpy as np

def get_normed_peptides_dataframe(cond1, cond2, results_folder = os.path.join(".", "results")):
    condpair = utils.get_condpairname([cond1, cond2])
    normed_peptides_tsv = os.path.join(results_folder, f"{condpair}.normed.tsv")
    try:
        normed_peptides = pd.read_csv(normed_peptides_tsv, sep = "\t")
    except:
        print(f"no normed peptides found for {condpair}!")
        return None

    numeric_cols = list(normed_peptides.select_dtypes(include=np.number).columns)
    #available_vals = list(set(samplemap_df["sample"].values).intersection(set(normed_peptides.columns)))
    normed_peptides[numeric_cols] = np.log2(normed_peptides[numeric_cols].replace(0, np.nan))
    normed_peptides = normed_peptides.set_index(["protein", "ion"])
    return normed_peptides


# Cell
import pandas as pd

def initialize_sample2cond(samplemap):
    samplemap_df = pd.read_csv(samplemap, sep = "\t")
    sample2cond = dict(zip(samplemap_df["sample"], samplemap_df["condition"]))
    return samplemap_df, sample2cond

# Cell
from anytree.importer import JsonImporter
import os
import alphaquant.diffquant_utils as aqutils
def read_condpair_tree(cond1, cond2, results_folder = os.path.join(".", "results")):
    """reads the merged and clustered iontree for a given condpair"""
    condpairname = utils.get_condpairname([cond1, cond2])
    tree_file =os.path.join(results_folder, f"{condpairname}.iontrees.json")
    importer = JsonImporter()
    filehandle = open(tree_file, 'r')
    jsontree = importer.read(filehandle)
    filehandle.close()
    return jsontree


