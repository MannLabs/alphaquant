{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp background_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionBackgrounds():\n",
    "\n",
    "    def __init__(self, normed_condition_df):\n",
    "        self.backgrounds = []\n",
    "        self.normed_condition_df = normed_condition_df\n",
    "        self.ion2background = {}\n",
    "        self.ion2nonNanvals = {}\n",
    "        self.init_ion2nonNanvals(self.normed_condition_df)\n",
    "        self.select_intensity_ranges()\n",
    "\n",
    "    def init_ion2nonNanvals(self, normed_condition_df):\n",
    "        for peptide, vals in normed_condition_df.iterrows():\n",
    "            self.ion2nonNanvals[peptide] = vals[vals.notna()].values\n",
    "\n",
    "\n",
    "    def select_intensity_ranges(self):\n",
    "        total_available_comparisons =0\n",
    "        num_contexts = 100\n",
    "        cumulative_counts = np.zeros(self.normed_condition_df.shape[0])\n",
    "\n",
    "        for idx ,count in enumerate(self.normed_condition_df.count(axis=1)):\n",
    "            total_available_comparisons+=count-1\n",
    "            cumulative_counts[idx] = int(total_available_comparisons/2)\n",
    "        \n",
    "\n",
    "        #assign the context sizes\n",
    "        context_size = np.max([1000, int(total_available_comparisons/(1+num_contexts/2))])\n",
    "        halfcontext_size = int(context_size/2)\n",
    "        context_boundaries = np.zeros(3).astype(int)\n",
    "\n",
    "        middle_idx = int(np.searchsorted(cumulative_counts, halfcontext_size))\n",
    "        end_idx = int(np.searchsorted(cumulative_counts, context_size))\n",
    "\n",
    "\n",
    "        context_boundaries[0] = 0\n",
    "        context_boundaries[1] = middle_idx\n",
    "        context_boundaries[2] = end_idx\n",
    "        while context_boundaries[1] < len(cumulative_counts)-1:\n",
    "            self.backgrounds.append(BackGroundDistribution(context_boundaries[0], context_boundaries[2], self.ion2nonNanvals))\n",
    "            context_boundaries[0] = context_boundaries[1]\n",
    "            context_boundaries[1] = context_boundaries[2]\n",
    "            end_idx = np.searchsorted(cumulative_counts, context_size + cumulative_counts[context_boundaries[0]])\n",
    "            if end_idx > len(cumulative_counts)-(context_boundaries[1]-context_boundaries[0])/1.5:\n",
    "                end_idx = len(cumulative_counts)-1\n",
    "            context_boundaries[2] = end_idx\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "class BackGroundDistribution:\n",
    "\n",
    "    fc_resolution_factor = 100\n",
    "    fc_conversion_factor = 1/fc_resolution_factor\n",
    "\n",
    "    def __init__(self, start_idx, end_idx, idx2noNanvals):\n",
    "        self.fc2counts = {} #binned Fold change Distribution\n",
    "        self.cumulative = np.array([])\n",
    "        self.zscores = np.array([])\n",
    "        self.min_fc =0\n",
    "        self.max_fc = 0\n",
    "        self.min_z=0\n",
    "        self.max_z=0\n",
    "        self.start_idx = int(start_idx)\n",
    "        self.end_idx = int(end_idx)\n",
    "        self.var = None\n",
    "        self.SD = None\n",
    "\n",
    "        anchor_fcs = self.generate_anchorfcs_from_intensity_range(idx2noNanvals)\n",
    "        shuffle(anchor_fcs)\n",
    "        self.generate_fc2counts_from_anchor_fcs(anchor_fcs)\n",
    "        self.cumulative = self.transform_fc2counts_into_cumulative()\n",
    "        self.calc_SD(0, self.cumulative)\n",
    "        self.zscores = self.transform_cumulative_into_z_values()\n",
    "\n",
    "    def generate_anchorfcs_from_intensity_range(self,idx2noNanvals):\n",
    "\n",
    "        anchor_fcs = []\n",
    "        for idx in range(self.start_idx, self.end_idx):\n",
    "            vals = idx2noNanvals[idx]\n",
    "            if vals.size < 2:\n",
    "                continue\n",
    "            anchor_idx =  np.random.randint(0, len(vals))\n",
    "            anchor_val = vals[anchor_idx]\n",
    "            vals = np.delete(vals, anchor_idx)\n",
    "            anchor_fcs.append(vals-anchor_val)\n",
    "        return anchor_fcs\n",
    "\n",
    "\n",
    "    def generate_fc2counts_from_anchor_fcs(self,anchor_fcs):\n",
    "        \n",
    "        anchor_fcs = np.array(anchor_fcs)\n",
    "        for idx in range(1, anchor_fcs.shape[0]):\n",
    "            fc_binned = np.rint(self.fc_resolution_factor*(anchor_fcs[idx-1] - anchor_fcs[idx])).astype(np.long)\n",
    "            for fc in fc_binned:\n",
    "                self.fc2counts[fc] = self.fc2counts.setdefault(fc, 0) + 1\n",
    "\n",
    "        self.min_fc = min(self.fc2counts.keys())\n",
    "        self.max_fc = max(self.fc2counts.keys())\n",
    "\n",
    "    \n",
    "    def transform_fc2counts_into_cumulative(self):\n",
    "        \n",
    "        cumulative = np.zeros(self.max_fc - self.min_fc +1).astype(np.long)\n",
    "\n",
    "        for entry in self.fc2counts.items():\n",
    "            cumulative[int(entry[0]-self.min_fc)] +=entry[1]\n",
    "        for idx in range(1,cumulative.shape[0]):\n",
    "            cumulative[idx] +=cumulative[idx-1]\n",
    "        \n",
    "        return cumulative\n",
    "\n",
    "    \n",
    "    def transform_cumulative_into_z_values(self):\n",
    "        total = self.cumulative[-1]\n",
    "        min_pval = 1/(total+1)\n",
    "        self.max_z = abs(norm.ppf(max(1e-9, min_pval)))\n",
    "        zscores = np.empty(len(self.cumulative))\n",
    "        zero_pos = -self.min_fc\n",
    "\n",
    "        normfact_posvals = 1/(total-self.cumulative[zero_pos]+1)\n",
    "        normfact_negvals = 1/(self.cumulative[zero_pos-1]+1)\n",
    "        print(f\"cumulative length {len(self.cumulative) -1}\")\n",
    "        for i in range(len(self.cumulative)):\n",
    "            num_more_extreme = 0\n",
    "            if i == zero_pos:\n",
    "                zscores[i] = 0\n",
    "                continue\n",
    "            if i!=zero_pos and i<len(self.cumulative)-1:\n",
    "                num_more_extreme = self.cumulative[i] if i<zero_pos else  self.cumulative[-1] - self.cumulative[i+1]\n",
    "            \n",
    "            normfact = normfact_negvals if i<zero_pos else normfact_posvals\n",
    "            p_val = 0.5*max(1e-9, (num_more_extreme+1)*normfact)\n",
    "            sign = -1 if i<zero_pos else 1\n",
    "            zscores[i] = sign*norm.ppf(p_val) ##ppf is the inverese cumulative distribution function\n",
    "\n",
    "        return zscores\n",
    "\n",
    "\n",
    "    def calc_zscore_from_fc(self, fc):\n",
    "        if abs(fc)<1e-9:\n",
    "            return 0\n",
    "        k = np.rint(fc * self.fc_resolution_factor)\n",
    "        rank = k-self.min_fc\n",
    "        if rank <0:\n",
    "            return -self.max_z\n",
    "        if rank >=len(self.cumulative):\n",
    "            return self.max_z\n",
    "        \n",
    "        return self.zscores[rank]\n",
    "\n",
    "\n",
    "    def calc_SD(self, mean, cumulative):\n",
    "        sq_err = 0.0\n",
    "        previous =0\n",
    "        print(cumulative)\n",
    "        for i in range(len(cumulative)):\n",
    "            fc = (i+self.min_fc)*self.fc_conversion_factor\n",
    "            sq_err += (cumulative[i] - previous)*(fc-mean)**2\n",
    "            previous = cumulative[i]\n",
    "        total = cumulative[-1]\n",
    "        var = sq_err/total\n",
    "        self.var = var\n",
    "        self.SD = math.sqrt(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate differential regulation peptide\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class DifferentialIon():\n",
    "    \n",
    "    def __init__(self,noNanvals_from, mean_from, bgdist_from, noNanvals_to, mean_to,  bgdist_to):\n",
    "        self.usable = False\n",
    "        p_val, fc, z_val = calc_diffreg_peptide(noNanvals_from, mean_from,bgdist_from, noNanvals_to, mean_to, bgdist_to)\n",
    "        if (p_val!=None):\n",
    "            self.p_val=p_val\n",
    "            self.fc=fc\n",
    "            self.z_val = z_val\n",
    "            self.usable = True\n",
    "\n",
    "def calc_diffreg_peptide(noNanvals_from, mean_from,bgdist_from, noNanvals_to, mean_to,  bgdist_to): #TO Do normalize the input vectors\n",
    "    nrep_from = len(noNanvals_from)\n",
    "    nrep_to = len(noNanvals_to)\n",
    "\n",
    "    if ((nrep_from==0) or (nrep_to ==0)):\n",
    "        return None, None, None\n",
    "\n",
    "    diffDist = SubtractedBackgrounds(bgdist_from, bgdist_to)\n",
    "\n",
    "    perEvidenceVariance = diffDist.var + (nrep_to-1) * bgdist_from.var + (nrep_from-1 ) * bgdist_to.var\n",
    "    totalVariance = perEvidenceVariance*nrep_to * nrep_from\n",
    "    fc_sum =0\n",
    "    z_sum=0\n",
    "\n",
    "    for from_intens in noNanvals_from:\n",
    "        for to_intens in noNanvals_to:\n",
    "            fc = from_intens - to_intens\n",
    "            fc_sum+=fc\n",
    "            z_sum += diffDist.calc_zscore_from_fc(fc)\n",
    "\n",
    "    fc = fc_sum/(nrep_from * nrep_to)\n",
    "    outlier_scaling_factor = calc_outlier_scaling_factor(noNanvals_from, mean_from, noNanvals_to, mean_to, bgdist_from, bgdist_to, diffDist)\n",
    "    scaled_SD = outlier_scaling_factor * math.sqrt(totalVariance/diffDist.var)\n",
    "    p_val = 2.0 * (1.0 -  norm(loc=0, scale= normed_sum_sd).cdf(abs(z_sum)))\n",
    "    z_val = z_sum/normed_sum_sd\n",
    "    return p_val, fc, z_val\n",
    "\n",
    "def calc_outlier_scaling_factor(noNanvals_from, mean_from, noNanvals_to, mean_to, bgdist_from, bgdist_to, diffDist):\n",
    "    between_rep_SD_from = math.sqrt(sum(np.square(noNanvals_from-mean_from))) if len(noNanvals_from)>1 else bgdist_from.SD\n",
    "    between_rep_SD_to = math.sqrt(sum(np.square(noNanvals_to-mean_to))) if len(noNanvals_to)>1 else bgdist_to.SD\n",
    "\n",
    "    highest_SD_from = max(between_rep_SD_from, bgdist_from.SD)\n",
    "    highest_SD_to = max(between_rep_SD_to, bgdist_to.SD)\n",
    "    highest_SD_combined = math.sqrt(highest_SD_from**2 + highest_SD_to**2)\n",
    "\n",
    "    scaling_factor = max(1.0, highest_SD_combined/diffDist.SD)\n",
    "    return scaling_factor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1    1    1 ... 1991 1991 1992]\n",
      "cumulative length 1365\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1642\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1238\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1305\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1323\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1245\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1445\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1360\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1534\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1544\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1425\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1468\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1373\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1331\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1270\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1380\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1576\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1393\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1393\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1329\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1302\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1299\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1354\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1304\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1199\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1415\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1360\n",
      "[   2    2    2 ... 1995 1995 1996]\n",
      "cumulative length 1341\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1360\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1462\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1310\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1338\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1493\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1549\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1580\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1268\n",
      "[   1    1    2 ... 1995 1995 1996]\n",
      "cumulative length 1150\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1323\n",
      "[   1    1    1 ... 1995 1995 1996]\n",
      "cumulative length 1243\n"
     ]
    }
   ],
   "source": [
    "num_vals = 10000\n",
    "rand1 = np.random.normal(loc=0, size=num_vals)\n",
    "rand2 = np.random.normal(loc=0, size=num_vals)\n",
    "rand3 = np.random.normal(loc=0, size=num_vals)\n",
    "rand4 = np.random.normal(loc=0, size=num_vals)\n",
    "rand5 = np.random.normal(loc=0, size=num_vals)\n",
    "\n",
    "randarray = pd.DataFrame({1:rand1, 2:rand2, 3:rand3, 4:rand4, 5:rand5})\n",
    "#display(randarray)\n",
    "condbg = ConditionBackgrounds(randarray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       289967418542 4614156196565583417     140490695507376 ...\n 4613136636625005970 4613136636625005970 4613136926592424512]\ncumulative length 3007\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4e55efe6dd32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdiffion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDifferentialIon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoNanvals_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdist_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoNanvals_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdist_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_diffreg_pep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-4e55efe6dd32>\u001b[0m in \u001b[0;36mtest_diffreg_pep\u001b[0;34m(condbg)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbgdist_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackgrounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbgdist_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcondbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackgrounds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdiffion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDifferentialIon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoNanvals_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdist_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoNanvals_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdist_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_diffreg_pep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondbg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-57b7ba519a43>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, noNanvals_from, mean_from, bgdist_from, noNanvals_to, mean_to, bgdist_to)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoNanvals_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdist_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoNanvals_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_to\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbgdist_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_diffreg_peptide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoNanvals_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbgdist_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoNanvals_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdist_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp_val\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-57b7ba519a43>\u001b[0m in \u001b[0;36mcalc_diffreg_peptide\u001b[0;34m(noNanvals_from, mean_from, bgdist_from, noNanvals_to, mean_to, bgdist_to)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_intens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mto_intens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mfc_sum\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mz_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiffDist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_zscore_from_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_sum\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrep_from\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnrep_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-e0ed9da71e1c>\u001b[0m in \u001b[0;36mcalc_zscore_from_fc\u001b[0;34m(self, fc)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "#test\n",
    "def test_diffreg_pep(condbg):\n",
    "    noNanvals_from = np.array([1,1,1,1])\n",
    "    noNanvals_to = np.array([2,2,2,2])\n",
    "    mean_from =1\n",
    "    mean_to = 2\n",
    "    bgdist_from = condbg.backgrounds[0]\n",
    "    bgdist_to = condbg.backgrounds[1]\n",
    "    diffion = DifferentialIon(noNanvals_from,mean_from, bgdist_from, noNanvals_to,mean_to, bgdist_to)\n",
    "\n",
    "test_diffreg_pep(condbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#subtract two Empirical Backgrounds\n",
    "from scipy.stats import norm\n",
    "class SubtractedBackgrounds(BackGroundDistribution):\n",
    "\n",
    "    def __init__(self, from_dist, to_dist):\n",
    "        self.max_fc = None\n",
    "        self.min_fc = None\n",
    "        self.cumulative = None\n",
    "        self.subtract_distribs(from_dist, to_dist)\n",
    "        self.calc_SD(0, self.cumulative)\n",
    "        self.zscores = self.transform_cumulative_into_z_values()\n",
    "        \n",
    "    def subtract_distribs(self,from_dist, to_dist):\n",
    "        min_joined = from_dist.min_fc - to_dist.max_fc\n",
    "        max_joined = from_dist.max_fc - to_dist.min_fc\n",
    "\n",
    "        n_from = get_normed_freqs(from_dist.cumulative)\n",
    "        n_to = get_normed_freqs(to_dist.cumulative)\n",
    "\n",
    "        min_from = from_dist.min_fc\n",
    "        min_to = to_dist.min_fc\n",
    "\n",
    "        joined = np.empty(max_joined-min_joined+1, dtype=\"long\")\n",
    "        \n",
    "        for from_idx in range(len(n_from)):\n",
    "            fc_from = min_from + from_idx\n",
    "            freq_from = n_from[from_idx]\n",
    "            for to_idx in range(len(n_to)):\n",
    "                fc_to = min_to + to_idx\n",
    "                freq_to = n_to[to_idx]\n",
    "                fcdiff = fc_from - fc_to\n",
    "                joined_idx = fcdiff - min_joined\n",
    "                joined[joined_idx] += (freq_from*freq_to)\n",
    "        self.max_fc = max_joined\n",
    "        self.min_fc = min_joined\n",
    "        self.cumulative = joined\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "def test_subtract_distribs():\n",
    "    from_dist = [1,1,2,1,1]\n",
    "    to_dist = [1,1,2,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "from scipy.stats import norm\n",
    "\n",
    "class DifferentialProtein():\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.pval=None\n",
    "        self.fc=None\n",
    "        self.name = name\n",
    "\n",
    "    def evaluate_protein_expression(ion_diffresults):\n",
    "        ion_diffresults = list(filter(lambda _f : _f.usable, ion_diffresults))\n",
    "        if len(ion_diffresults) ==0:\n",
    "            return\n",
    "        fcs = list(map(lambda _dr : _dr.fc,ion_diffresults))\n",
    "        median_fc = statistics.median(fcs)\n",
    "        ion_diffresults = select_robust_if_many_ions(fcs, median_fc,ion_diffresults)\n",
    "        z_sum = sum(map(lambda _dr: _dr.zval, table))\n",
    "        p_val = 2.0 * (1.0 - norm(0, math.sqrt(len(ion_diffresults))).cdf(abs(z_sum)))\n",
    "\n",
    "        return median_fc, p_val\n",
    "\n",
    "\n",
    "    def select_robust_if_many_ions(fcs, median_fc,ion_diffresults):\n",
    "        ion_diffresults = sort(lambda _dr : abs(_dr.fc - median_fc),ion_diffresults)\n",
    "        ninety_perc_cutoff = math.ceil(0.9*len(ion_diffresults)) #the ceil function ensures that ions are only excluded if there are more than 10 available\n",
    "        if ninety_perc_cutoff >0:\n",
    "            ion_diffresults = ion_diffresults[:ninety_perc_cutoff]\n",
    "        return ion_diffresults\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform cumulative into frequency\n",
    "\n",
    "def get_freq_from_cumul(cumulative):\n",
    "    res = np.empty(len(cumulative), dtype=\"long\")\n",
    "    res[0] = cumulative[0]\n",
    "    for i in range(1,len(cumulative)):\n",
    "        res[i] = cumulative[i]-cumulative[i-1]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "def test_get_freq_from_cumul():\n",
    "            arr = [1,2,3,4,5,6]\n",
    "            freqs = get_freq_from_cumul(arr)\n",
    "            assert (freqs == [1,1,1,1,1,1]).all()\n",
    "test_get_freq_from_cumul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get normalized freqs from cumulative\n",
    "\n",
    "def get_normed_freqs(cumulative):\n",
    "    normfact = 2**30 /cumulative[len(cumulative)-1]\n",
    "    freqs =get_freq_from_cumul(cumulative)\n",
    "    for i in range(len(freqs)):\n",
    "        freqs[i] *= normfact\n",
    "    return freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "class Test():\n",
    "    def __init__(self):\n",
    "        arr = [1,2,3,4,5,6]\n",
    "        self.freqs = get_freq_from_cumul(arr)\n",
    "        normfreq = get_normed_freqs(arr)\n",
    "        display(freqs)\n",
    "        display(freqs.dtype)\n",
    "        display(normfreq.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>r1</th>\n      <th>r2</th>\n      <th>r3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>falcon</td>\n      <td>12.0</td>\n      <td>50.0</td>\n      <td>389.0</td>\n    </tr>\n    <tr>\n      <td>parrot</td>\n      <td>20.0</td>\n      <td>64.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <td>lion</td>\n      <td>NaN</td>\n      <td>55.0</td>\n      <td>80.2</td>\n    </tr>\n    <tr>\n      <td>monkey</td>\n      <td>17.0</td>\n      <td>51.0</td>\n      <td>385.0</td>\n    </tr>\n    <tr>\n      <td>leopard</td>\n      <td>15.0</td>\n      <td>68.0</td>\n      <td>370.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           r1    r2     r3\nfalcon   12.0  50.0  389.0\nparrot   20.0  64.0   24.0\nlion      NaN  55.0   80.2\nmonkey   17.0  51.0  385.0\nleopard  15.0  68.0  370.0"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([(12, 50, 389.0),                (20, 64.0, 24.0),\n",
    "               (np.nan, 55, 80.2),\n",
    "                (17, 51, 385.0),\n",
    "                   (15, 68, 370.0)],\n",
    "                  index=['falcon', 'parrot', 'lion', 'monkey', 'leopard'],\n",
    "                columns=('r1', 'r2', 'r3'))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falcon\n[ 12.  50. 389.]\nparrot\n[20. 64. 24.]\nlion\n[55.  80.2]\nmonkey\n[ 17.  51. 385.]\nleopard\n[ 15.  68. 370.]\n"
     ]
    }
   ],
   "source": [
    "for label, content in df.iterrows():\n",
    "    print(label)\n",
    "    print(content[content.notna()].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "arr = np.zeros(5)\n",
    "for idx in range(1,arr.shape[0]):\n",
    "    arr[idx]+=arr[idx-1]+1\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "40d51365aa244ea8dfcdc6ebc574fb3bd1f17153aa3af35e8e8f263381dfdfa4"
    }
   },
   "name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
