{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# default_exp classify_ions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "def collect_node_parameters(all_nodes, w_annot = True):\n",
    "    ion2param2val = {}\n",
    "    all_headers = set()\n",
    "    for node in all_nodes:\n",
    "\n",
    "        param2val = { \"frac_mainclust\" : node.frac_mainclust, \"num_mainclusts\" : node.num_mainclusts,\n",
    "        \"cv_fcs\" : calc_variance_for_node(node), \"num_children\" : len(node.children), \"fraction_consistent\": node.fraction_consistent, \"num_leaves\" : len(node.leaves), \"replicate_cv\" : node.cv,\n",
    "        \"intensity\" : node.min_intensity}\n",
    "        if w_annot:\n",
    "            param2val.update({\"positive_example\" : node.positive_example, \"ion\" : node.name})\n",
    "        if node.type == 'mod_seq_charge':\n",
    "            if len(node.children) ==2:\n",
    "                fcfc_diff = abs(node.children[0].fc - node.children[1].fc)\n",
    "                param2val.update({\"ms1_ms2_fcfc_diff\" : fcfc_diff})\n",
    "\n",
    "            for child in node.children:\n",
    "                name_frac_mainclust = f\"child_type_{child.type}_frac_mainclust\"\n",
    "                name_num_mainclusts = f\"child_type_{child.type}_num_mainclusts\"\n",
    "                name_variance = f\"child_type_{child.type}_cv_fcs\"\n",
    "                name_replicate_cv = f\"child_type_{child.type}_replicate_cv\"\n",
    "                param2val.update({name_frac_mainclust: child.frac_mainclust, name_num_mainclusts : child.num_mainclusts, name_variance : calc_variance_for_node(child), name_replicate_cv : child.cv})\n",
    "                clusterstats_dict = calc_cluster_stats(child)\n",
    "                param2val.update(clusterstats_dict)\n",
    "        all_headers.update(param2val.keys())\n",
    "        ion2param2val[node.name] = param2val\n",
    "\n",
    "    return get_dataframe(all_nodes,ion2param2val, all_headers)\n",
    "\n",
    "def get_dataframe(all_nodes,ion2param2val, all_headers):\n",
    "    all_headers = list(all_headers)\n",
    "    rows = [[ion2param2val.get(node.name).get(header, np.nan) for header in all_headers] for node in all_nodes]\n",
    "    df = pd.DataFrame(rows, columns = all_headers)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calc_cluster_stats(node):\n",
    "    num_elems_secondclust = 0\n",
    "    fcs_clust0 = []\n",
    "    fcs_clust1 = []\n",
    "    intensities = []\n",
    "    for child in node.children:\n",
    "        if child.cluster ==0:\n",
    "            fcs_clust0.append(child.fc)\n",
    "        if child.cluster ==1:\n",
    "            num_elems_secondclust+=1\n",
    "            fcs_clust1.append(child.fc)\n",
    "        intensities.append(child.min_intensity)\n",
    "\n",
    "    if len(fcs_clust1)>0:\n",
    "        betweenclust_fcfc = abs(np.mean(fcs_clust0) - np.mean(fcs_clust1))\n",
    "    else:\n",
    "        betweenclust_fcfc = 8\n",
    "    \n",
    "    stats_dict = {f\"child_type_{node.type}_num_elems_secondclust\" : num_elems_secondclust, f\"child_type_{node.type}_num_clusters_total\" : node.num_clusters, f\"child_type_{node.type}_betweenclust_fcfc\" : betweenclust_fcfc,\n",
    "    f\"child_type_{node.type}_num_elems_secondclust\" : np.mean(intensities)}\n",
    "    return stats_dict\n",
    "\n",
    "def calc_variance_for_node(node):\n",
    "    \n",
    "    fcs_children = [x.fc for x in node.children]\n",
    "    min_fc = min(fcs_children)\n",
    "    fcs_children = [x.fc - min_fc for x in node.children]\n",
    "    #print(f\"fcs children are {fcs_children}, variance is {np.var(fcs_children)}\")\n",
    "\n",
    "    return scipy.stats.variation(fcs_children)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import anytree\n",
    "\n",
    "def get_positive_negative_samples(condpairtree,type):\n",
    "    all_nodes = []\n",
    "    for protein_node in condpairtree.children:\n",
    "        if protein_node.num_mainclusts <3:\n",
    "            continue\n",
    "        if protein_node.fraction_consistent < 0.7:\n",
    "            continue\n",
    "        type_nodes = anytree.search.findall(protein_node, filter_=lambda node: node.type == type)\n",
    "        for type_node in type_nodes:\n",
    "            fcdiff = abs(type_node.fc - protein_node.fc)\n",
    "\n",
    "            if fcdiff<0.3:\n",
    "                type_node.positive_example = True\n",
    "                all_nodes.append(type_node)\n",
    "                continue\n",
    "            if fcdiff>2:\n",
    "                type_node.positive_example = False\n",
    "                all_nodes.append(type_node)\n",
    "    return all_nodes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "from sklearn.utils import resample\n",
    "import alphaquant.classify_ions as aqclass\n",
    "\n",
    "def get_tp_fp_nodes(condpairtree, nodetype, substantially_off_thresholds, close_to_target_threshold, precursor2fc = None):\n",
    "    res_nodes =[]\n",
    "    condpairtree.type = 'condpair'\n",
    "    nodes = anytree.search.findall(condpairtree, filter_=lambda node:  (node.type == nodetype))\n",
    "    if precursor2fc is not None:\n",
    "        node2fc = get_node2fc(precursor2fc, nodes)\n",
    "\n",
    "    for node in nodes:\n",
    "        if precursor2fc is not None:\n",
    "            fc = node2fc.get(node)\n",
    "        else:\n",
    "            fc = node.fc\n",
    "        if (abs(fc) > substantially_off_thresholds[0]) & (abs(fc) < substantially_off_thresholds[1]):\n",
    "            node.positive_example = False\n",
    "            res_nodes.append(node)\n",
    "        if abs(fc) < close_to_target_threshold:\n",
    "            node.positive_example = True\n",
    "            res_nodes.append(node)\n",
    "    return res_nodes\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import re\n",
    "def get_node2fc(precursor2fc, nodes):\n",
    "    node2fc = {}\n",
    "    pattern = \"(SEQ_.*_MOD_)(.*)(_CHARGE_)(.*)(_)\"\n",
    "    if nodes[0].name in precursor2fc.keys():\n",
    "        rename_precursor= False\n",
    "    else:\n",
    "        rename_precursor = True\n",
    "    for node in nodes:\n",
    "        if rename_precursor:\n",
    "            matched = re.search(pattern,node.name)\n",
    "            precursor = f\"{matched.group(2)}.{matched.group(4)}\"\n",
    "        else:\n",
    "            precursor = node.name\n",
    "        fc = precursor2fc.get(precursor)\n",
    "        node2fc[node] = fc\n",
    "\n",
    "    return node2fc\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import alphaquant.visualizations as aqplot\n",
    "def generate_ml_input(c1, c2, neg_thresholds =[1.5, 3], pos_threshold =  0.2, features_to_exclude = [], precursor2fc = None, results_folder=\"results_renamed\"):\n",
    "    tree = aqplot.read_condpair_tree(c1, c2, results_folder)\n",
    "    pos_negs = get_tp_fp_nodes(tree, 'mod_seq_charge', neg_thresholds, pos_threshold, precursor2fc)\n",
    "    df_precursor_features = aqclass.collect_node_parameters(pos_negs)\n",
    "    df_precursor_features = df_precursor_features.drop(columns = features_to_exclude)\n",
    "    \n",
    "    df_precursor_features = balance_classes(df_precursor_features)\n",
    "    #df_precursor_features = df_precursor_features.dropna()\n",
    "    ionnames = df_precursor_features[\"ion\"]\n",
    "    df_precursor_features = df_precursor_features.drop(columns = \"ion\")\n",
    "    df_precursor_features = df_precursor_features.astype('float')\n",
    "    df_precursor_features = df_precursor_features.replace(np.nan, -1)\n",
    "    \n",
    "    X_outliers = df_precursor_features.drop(columns=[\"positive_example\"]).to_numpy()\n",
    "    print(\"shapes:\")\n",
    "    print(X_outliers.shape)\n",
    "    y_outliers = df_precursor_features[\"positive_example\"]\n",
    "    print(y_outliers.shape)\n",
    "    featurenames = list(df_precursor_features.drop(columns=[\"positive_example\"]).columns)\n",
    "    return X_outliers, y_outliers, featurenames, ionnames\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import anytree\n",
    "def ml_filter_and_plot_fcs(ml_classifier, threshold_for_negative_classification, c1, c2, results_folder=\"results_renamed\"):\n",
    "    results_df = aqplot.get_diffresult_dataframe(c1, c2, results_folder=results_folder)\n",
    "    tree = aqplot.read_condpair_tree(c1, c2, results_folder)\n",
    "    tree.type = \"condpair\"\n",
    "    nodes = anytree.findall(tree, filter_= lambda x : x.type == 'mod_seq_charge')\n",
    "    ion2isincluded = get_ion2classification(ml_classifier, nodes, threshold_for_negative_classification)\n",
    "    results_df = results_df[[ion2isincluded.get(x) for x in results_df[\"protein\"]]]\n",
    "\n",
    "    aqplot.volcano_plot(results_df)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "def get_ion2classification(ml_classifier, nodes, threshold_for_positive_classification):\n",
    "    df_precursor_features = aqclass.collect_node_parameters(nodes, w_annot=False)\n",
    "    df_precursor_features = df_precursor_features.astype('float')\n",
    "    df_precursor_features = df_precursor_features.replace(np.nan, -1)\n",
    "    X = df_precursor_features.to_numpy()\n",
    "    ionnames = [x.name for x in nodes]\n",
    "    probabilities_positive_example = [x[1] for x in ml_classifier.predict_proba(X)]\n",
    "    ion2included = {ion:(prob>threshold_for_positive_classification ) for ion, prob in zip(ionnames, probabilities_positive_example)}\n",
    "    return ion2included\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "\n",
    "def balance_classes(df_precursor_features):\n",
    "    df_pos_examples = df_precursor_features[df_precursor_features[\"positive_example\"] ==1]\n",
    "    df_neg_examples = df_precursor_features[df_precursor_features[\"positive_example\"] ==0]\n",
    "    min_length = min(len(df_pos_examples.index), len(df_neg_examples.index))\n",
    "    df_pos_examples = resample(df_pos_examples, replace = False, n_samples = int(min_length), random_state = 123)\n",
    "    df_neg_examples = resample(df_neg_examples, replace = False, n_samples = min_length, random_state = 123)\n",
    "    df_downsampled = pd.concat([df_pos_examples, df_neg_examples], ignore_index=True)\n",
    "    print(sum(df_downsampled[\"positive_example\"]))\n",
    "    print(len(df_downsampled.index))\n",
    "    return df_downsampled\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import resample\n",
    "def load_feature_df(c1, c2, neg_thresholds =[1.5, 3], pos_threshold =  0.2, features_to_exclude = []):\n",
    "    tree = aqplot.read_condpair_tree(c1, c2, results_folder=\"results\")\n",
    "    pos_negs = get_tp_fp_nodes(tree, 'mod_seq_charge', neg_thresholds, pos_threshold)\n",
    "    df_precursor_features = aqclass.collect_node_parameters(pos_negs)\n",
    "    df_precursor_features = df_precursor_features.drop(columns = features_to_exclude)\n",
    "    return df_precursor_features\n",
    "\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "def annotate_feature_df_w_spectronaut(spectronaut_df, parameter_df, groupby_merge_type = 'mean'):\n",
    "    spectronaut_df[\"ion\"] = pd.Series([\"SEQ_\" for x in range(len(spectronaut_df.index))]) + spectronaut_df[\"PEP.StrippedSequence\"] + pd.Series([\"_MOD_\" for x in range(len(spectronaut_df.index))]) + spectronaut_df['EG.ModifiedSequence'] +  pd.Series([\"_CHARGE_\" for x in range(len(spectronaut_df.index))])+ spectronaut_df['FG.Charge'].astype('str') +pd.Series([\"_\" for x in range(len(spectronaut_df.index))])\n",
    "    precursor_headers = [\"ion\"] + [x for x in spectronaut_df.columns if ((\"EG.\" in x) | (\"FG.\" in x))]\n",
    "    spectronaut_df = spectronaut_df[precursor_headers].drop_duplicates()\n",
    "    spectronaut_df = spectronaut_df.replace({False: 0, True: 1})\n",
    "    precursor_headers_final = [\"ion\"] + list(spectronaut_df.select_dtypes(include=np.number).columns)\n",
    "    spectronaut_df = spectronaut_df[precursor_headers_final]\n",
    "    merged_df = parameter_df.merge(spectronaut_df, how = 'left', on = 'ion')\n",
    "    if groupby_merge_type == 'mean':\n",
    "        merged_df = merged_df.groupby('ion').mean().reset_index()\n",
    "    if groupby_merge_type == 'min':\n",
    "        merged_df = merged_df.groupby('ion').min().reset_index()\n",
    "    if groupby_merge_type == 'max':\n",
    "        merged_df = merged_df.groupby('ion').max().reset_index()\n",
    "    return merged_df\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "def reformat_to_ml_input(annotated_df):\n",
    "    annotated_df = annotated_df.drop(columns = \"ion\")\n",
    "    annotated_df = annotated_df.astype('float')\n",
    "    annotated_df = annotated_df.replace(np.nan, -1)\n",
    "    #df_precursor_features = df_precursor_features.dropna()\n",
    "    annotated_df = balance_classes(annotated_df)\n",
    "    X_outliers = annotated_df.drop(columns=[\"positive_example\"]).to_numpy()\n",
    "    y_outliers = annotated_df[\"positive_example\"]\n",
    "    featurenames = list(annotated_df.drop(columns=[\"positive_example\"]).columns)\n",
    "    return X_outliers, y_outliers, featurenames\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#export\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_feature_importances(coef, names, top_n = np.inf, print_out_name = False):\n",
    "    imp,names = filter_sort_top_n(coef, names, top_n)\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    if print_out_name:\n",
    "        for idx in range(len(imp)):\n",
    "            print(f\"{imp[idx]}\\t{names[idx]}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def filter_sort_top_n(imp, names, top_n):\n",
    "    tuplelist = list(zip(imp, names))\n",
    "    tuplelist.sort(key = lambda x : abs(x[0]),reverse=True)\n",
    "    tuplelist = tuplelist[:top_n]\n",
    "    imp = [x[0] for x in tuplelist]\n",
    "    names = [x[1] for x in tuplelist]\n",
    "    return imp, names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_precision_recall(classfier, X_train, y_train, X_test, y_test):\n",
    "      y_score = classfier.decision_function(X_train)\n",
    "      average_precision = average_precision_score(y_train, y_score)\n",
    "\n",
    "      print('Average precision-recall score: {0:0.2f}'.format(\n",
    "            average_precision))\n",
    "\n",
    "\n",
    "      disp = plot_precision_recall_curve(classfier, X_test, y_test)\n",
    "      disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                        'AP={0:0.2f}'.format(average_precision))\n",
    "      plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "def get_precursor2fc(cond1, cond2, results_folder):\n",
    "    result_df = aqviz.get_diffresult_dataframe(cond1, cond2, results_folder)\n",
    "    result_dict = dict(zip(result_df[\"protein\"], result_df[\"log2fc\"]))\n",
    "    return result_dict\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "\n",
    "def get_nodes_of_type(cond1, cond2, results_folder, node_type = 'mod_seq_charge'):\n",
    "\n",
    "    tree_sn = aqplot.read_condpair_tree(cond1, cond2, results_folder=results_folder)\n",
    "    tree_sn.type = \"asd\"\n",
    "    return anytree.findall(tree_sn, filter_= lambda x : (x.type == node_type))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import alphaquant.classify_ions as aqclass\n",
    "import alphaquant.visualizations as aqplot\n",
    "import anytree\n",
    "\n",
    "def generate_protein_shifted_peptide_set(cond1, cond2, results_folder, precursor_cutoff = 2):\n",
    "    cpair_tree = aqplot.read_condpair_tree(cond1, cond2, results_folder=results_folder)\n",
    "    cpair_tree.type = \"asd\"\n",
    "    protnodes = anytree.findall(cpair_tree, filter_= lambda x : (x.type == \"gene\"),maxlevel=2)\n",
    "    normalized_peptides = []\n",
    "    for prot in protnodes:\n",
    "        precursors = anytree.findall(prot, filter_= lambda x : (x.type == \"mod_seq_charge\"))\n",
    "        if len(precursors)<precursor_cutoff:\n",
    "            continue\n",
    "        fc_prot = prot.fc\n",
    "        for precursor in precursors: #shift every peptide by the protein fold change, this should make peptides from different proteins comparable and enable analyses/ml on this dataset\n",
    "            precursor.fc = precursor.fc - fc_prot\n",
    "            normalized_peptides.append(precursor)\n",
    "        \n",
    "    return normalized_peptides"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "\n",
    "def get_intersect_sn_diann_precursors(cond1, cond2, sn_folder, diann_folder):\n",
    "    precursor_nodes_diann = get_nodes_of_type(cond1, cond2, diann_folder, node_type = 'mod_seq_charge')\n",
    "    precursor_nodes_sn = get_nodes_of_type(cond1, cond2, sn_folder, node_type = 'mod_seq_charge')\n",
    "    precursors_diann = {x.name.replace(\"_MOD_\", \"_MOD__\").replace(\"_CHARGE\", \"__CHARGE\") for x in precursor_nodes_diann}\n",
    "    precursors_sn = {x.name for x in precursor_nodes_sn}\n",
    "    \n",
    "    intersect = precursors_diann.intersection(precursors_sn)\n",
    "    \n",
    "    return intersect"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "\n",
    "def generate_ml_input_regression(df_precursor_features, nodes):\n",
    "    ion2fc = {x.name: x.fc for x in nodes}\n",
    "    df_precursor_features = df_precursor_features.dropna()\n",
    "    df_precursor_features = df_precursor_features[[(x in ion2fc.keys()) for x in df_precursor_features[\"ion\"]]]\n",
    "    ionnames = list(df_precursor_features[\"ion\"])\n",
    "    df_precursor_features = df_precursor_features.drop(columns=[\"ion\"])\n",
    "    df_precursor_features = df_precursor_features.drop(columns=[\"positive_example\"])\n",
    "    X = df_precursor_features.to_numpy()\n",
    "    y = [ion2fc.get(ion) for ion in ionnames]\n",
    "    featurenames = list(df_precursor_features.columns)\n",
    "    return X, y, featurenames, ionnames"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "\n",
    "def reduce_spectronaut_output_to_precursor_level(spectronaut_file):\n",
    "    tableit = pd.read_csv(spectronaut_file, sep = \"\\t\", chunksize=100000)\n",
    "    tables = []\n",
    "    for table_df in tableit:\n",
    "\n",
    "        subset_table = table_df[[\"R.Label\", \"FG.Id\"]].drop_duplicates()\n",
    "        table_df = table_df.loc[subset_table.index] #use index to subset\n",
    "        tables.append(table_df)\n",
    "\n",
    "    res_df = pd.concat(tables, ignore_index = True)\n",
    "    res_df = res_df.dropna(axis=1, how='all')\n",
    "    return res_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import alphaquant.visualizations as aqplot\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import alphaquant.classify_ions as aqclass\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "\n",
    "def do_linear_regression(X, y, featurenames, ionnames, prediction_cutoff):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    X = scale_input(X)\n",
    "    # Split the data into training/testing sets\n",
    "    fc2ion = {x:y for x,y in zip(y, ionnames)}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # Create linear regression object\n",
    "    \n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred = regr.predict(X_test)\n",
    "\n",
    "    # The coefficients\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    # The mean squared error\n",
    "    print('Mean squared error: %.2f'\n",
    "        % mean_squared_error(y_test, y_pred))\n",
    "    # The coefficient of determination: 1 is perfect prediction\n",
    "    print('Coefficient of determination: %.2f'\n",
    "        % r2_score(y_test, y_pred))\n",
    "\n",
    "    # Plot outputs\n",
    "    #plt.plot(X_test[:,-1], y_pred,  color='black')\n",
    "    plt.scatter(y_test, y_pred, color='blue')\n",
    "    plt.show()\n",
    "    aqclass.plot_feature_importances(regr.coef_,featurenames, 10)\n",
    "    plt.show()\n",
    "    aqplot.plot_predicted_fc_histogram(y_test, y_pred, prediction_cutoff, show_filtered=False)\n",
    "    plt.show()\n",
    "    aqplot.plot_predicted_fc_histogram(y_test, y_pred, prediction_cutoff, show_filtered=True)\n",
    "    plt.show()\n",
    "    print_good_predicitions(y_test, y_pred, fc2ion)\n",
    "\n",
    "import sklearn.preprocessing\n",
    "def scale_input_minmax(X):\n",
    "    scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    X_transformed = scaler.transform(X)\n",
    "    return X_transformed\n",
    "\n",
    "def scale_input(X):\n",
    "    scaler = sklearn.preprocessing.StandardScaler().fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return X_scaled\n",
    "\n",
    "def print_good_predicitions(y_test, y_pred, fc2ionnames,top_n = 10):\n",
    "    tuples = list(zip(y_test, y_pred))\n",
    "    tuples.sort(key = lambda x: min(abs(np.array([x[0], x[1]]))), reverse=True)\n",
    "    print('printing names of some well predicted ions')\n",
    "    for idx in range(top_n):\n",
    "        print(f\"{tuples[idx]}\\t{fc2ionnames.get(tuples[idx][0])}\")\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "def do_random_forest_regression(X, y, featurenames, prediction_cutoff):\n",
    "      # Split the data into training/testing sets\n",
    "      X = scale_input(X)\n",
    "      X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "      \n",
    "      # Create linear regression object\n",
    "      regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "      # Train the model using the training sets\n",
    "      regr.fit(X_train, y_train)\n",
    "\n",
    "      # Make predictions using the testing set\n",
    "      y_pred = regr.predict(X_test)\n",
    "\n",
    "\n",
    "      # The mean squared error\n",
    "      print('Mean squared error: %.2f'\n",
    "            % mean_squared_error(y_test, y_pred))\n",
    "      # The coefficient of determination: 1 is perfect prediction\n",
    "      print('Coefficient of determination: %.2f'\n",
    "            % r2_score(y_test, y_pred))\n",
    "      \n",
    "      # Plot outputs\n",
    "      #plt.plot(X_test[:,-1], y_pred,  color='black')\n",
    "      plt.scatter(y_test, y_pred, color='blue')\n",
    "      plt.show()\n",
    "      aqclass.plot_feature_importances(regr.feature_importances_,featurenames, 10)\n",
    "      plt.show()\n",
    "      aqplot.plot_predicted_fc_histogram(y_test, y_pred, prediction_cutoff, show_filtered=False)\n",
    "      plt.show()\n",
    "      aqplot.plot_predicted_fc_histogram(y_test, y_pred, prediction_cutoff, show_filtered=True)\n",
    "      plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import alphaquant.visualizations as aqplot\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "def balance_small_and_strong_fcs(X_orig, y_orig, ionnames,cutoff):\n",
    "    smaller_pep_idxs = []\n",
    "    larger_peps_idxs = []\n",
    "    for idx in range(len(y_orig)):\n",
    "        fc = y_orig[idx]\n",
    "        if fc< cutoff:\n",
    "            smaller_pep_idxs.append(idx)\n",
    "        else:\n",
    "            larger_peps_idxs.append(idx)\n",
    "    if len(larger_peps_idxs)< len(smaller_pep_idxs):\n",
    "        print(\"balancing subsets\")\n",
    "        print(f\"{len(larger_peps_idxs)} of large vs {len(smaller_pep_idxs)} of small fcs\")\n",
    "        smaller_pep_idxs = random.sample(smaller_pep_idxs, len(larger_peps_idxs))\n",
    "    else:\n",
    "        print(\"skip balancing subsets\")\n",
    "        return X_orig, y_orig, ionnames\n",
    "    new_idxs = smaller_pep_idxs+larger_peps_idxs\n",
    "    X_new = X_orig[new_idxs,:]\n",
    "    y_new = y_orig[new_idxs]\n",
    "    return X_new, y_new, ionnames[new_idxs]\n",
    "\n",
    "\n",
    "def random_forest_iterative_cross_predict(X, y, ionnames,number_splits, regr, balancing_cutoff = np.inf):\n",
    "    y = np.array(y)\n",
    "    X = scale_input(X)\n",
    "    X_balanced, y_balanced, ionnames_balanced = balance_small_and_strong_fcs(X, y, ionnames,balancing_cutoff)\n",
    "    #X_not_balanced, y_not_balanced  = get_balance_excluded_subset(y_balanced, y, X)\n",
    "    \n",
    "    chunks_included, chunks_excluded = get_indices_for_cross_predict(y_balanced, number_splits)\n",
    "    y_test_all = []\n",
    "    y_pred_all = []\n",
    "    ionnames_all = []\n",
    "    all_excluded = {}\n",
    "    for i in range(len(chunks_included)):\n",
    "        idxs_in = chunks_included[i]\n",
    "        idxs_out = chunks_excluded[i]\n",
    "\n",
    "        if len(set(idxs_out).intersection(all_excluded))>0:\n",
    "            print(\"overfitting alarm!\")\n",
    "            all_excluded.update(set(idxs_out))\n",
    "\n",
    "        X_train = X_balanced[idxs_in,:]\n",
    "        y_train = y_balanced[idxs_in]\n",
    "        X_test = X_balanced[idxs_out, :]\n",
    "        y_test = y_balanced[idxs_out]\n",
    "        regr.fit(X_train, y_train)\n",
    "        # Make predictions using the testing set\n",
    "        y_pred = regr.predict(X_test)\n",
    "        print(idxs_out[:20])\n",
    "        y_test_all.extend(y_test)\n",
    "        y_pred_all.extend(y_pred)\n",
    "        ionnames_all.extend(ionnames_balanced[idxs_out])\n",
    "    #predict the ones that were excluded for small fcs (predictor chosen aribtrarly)\n",
    "    #y_pred_not_balanced = regr.predict(X_not_balanced)\n",
    "    #y_pred_all.extend(y_pred_not_balanced)\n",
    "    #y_test_all.extend(y_not_balanced)\n",
    "    return y_test_all, y_pred_all, ionnames_all\n",
    "    #aqplot.get_error_and_scatter_ml_regression(y_test_all, y_pred_all, scatter_filt)\n",
    "        \n",
    "        \n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "def get_indices_for_cross_predict(y, number_splits):\n",
    "    length_subset = math.floor(len(y)/number_splits)\n",
    "    y_idxs = list(range(len(y)))\n",
    "    random.shuffle(y_idxs)\n",
    "    chunks_excluded = []\n",
    "    chunks_included = []\n",
    "    for i in range(0, len(y), length_subset):\n",
    "        idxs_excluded = y_idxs[i:i + length_subset]\n",
    "        idxs_included = [idx for idx in y_idxs if idx not in idxs_excluded]\n",
    "        chunks_excluded.append(idxs_excluded)\n",
    "        chunks_included.append(idxs_included)\n",
    "    return chunks_included, chunks_excluded\n",
    "\n",
    "\n",
    "def get_balance_excluded_subset(y_balanced, y, X):\n",
    "    idxs_y_balance_excluded = [x for x in range(len(y)) if (y[x] not in y_balanced)]\n",
    "    y_not_balanced = np.array(y)[idxs_y_balance_excluded]\n",
    "    X_not_balanced = X[idxs_y_balance_excluded,:]\n",
    "    return X_not_balanced, y_not_balanced\n",
    "\n",
    "\n",
    "def calculate_log_loss_scores_for_prediction(y_test, y_pred):\n",
    "    loss_scores = abs(np.log2(y_test) - np.log2(y_pred))\n",
    "    return loss_scores"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}