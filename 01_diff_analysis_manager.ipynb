{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp diff_analysis_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import statsmodels.stats.multitest as mt\n",
    "from time import time\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "import alphaquant.diff_analysis_manager as aqmgr\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "import alphaquant.visualizations as aqviz\n",
    "\n",
    "import alphaquant.ptmsite_mapping as aqptm\n",
    "import multiprocess\n",
    "\n",
    "\n",
    "def run_pipeline(*,input_file = None, samplemap_file=None, input_df = None, samplemap_df = None, modification_type = None, input_type_to_use = None,results_dir = \"./results\", condpair_combinations = None, minrep = 2, \n",
    "min_num_ions = 1, minpep = 1, cluster_threshold_pval = 0.05, cluster_threshold_fcfc = 0, use_ml = True, take_median_ion = True,outlier_correction = True, normalize = True,\n",
    "use_iontree_if_possible = True, get_ion2clust = False, median_offset = False, pre_normed_intensity_file = None, dia_fragment_selection = False, use_multiprocessing = False,runtime_plots = False, volcano_fdr =0.05, volcano_fcthresh = 0.5, \n",
    "annotation_file = None, protein_subset_for_normalization_file = None):\n",
    "\n",
    "    \"\"\"Run the differential analyses.\n",
    "    \"\"\"\n",
    "    \n",
    "    check_input_consistency(input_file, samplemap_file, input_df, samplemap_df)\n",
    "\n",
    "    \n",
    "    if input_file is not None: #if input file is given, load the dataframes from there\n",
    "        \n",
    "        if modification_type is not None:\n",
    "            input_file = write_ptm_mapped_input(input_file=input_file, results_dir=results_dir, samplemap_file=samplemap_file, modification_type=modification_type)\n",
    "\n",
    "        samplemap_df = aqutils.load_samplemap(samplemap_file)\n",
    "\n",
    "        try:\n",
    "            input_df = aqutils.import_data(input_file, input_type_to_use=input_type_to_use)\n",
    "            input_df, samplemap_df = aqutils.prepare_loaded_tables(input_df, samplemap_df)\n",
    "        except:\n",
    "            input_df = None\n",
    "        \n",
    "    \n",
    "    \n",
    "    #store method parameters for reproducibility\n",
    "    aqutils.store_method_parameters(locals(), results_dir)\n",
    "    \n",
    "\n",
    "    if condpair_combinations == None:\n",
    "        conds = samplemap_df[\"condition\"].unique()\n",
    "        condpair_combinations = combinations(conds, 2)\n",
    "    \n",
    "    num_cores = multiprocess.cpu_count() if use_multiprocessing else 1\n",
    "    with multiprocess.Pool(num_cores) as pool:\n",
    "        #for condpair in condpair_combinations:\n",
    "        \n",
    "        pool.map(lambda condpair : analyze_condpair(samplemap_df=samplemap_df, input_df= input_df, input_file = input_file,results_dir=results_dir, condpair=condpair, minrep=minrep, min_num_ions=min_num_ions, minpep=minpep, \n",
    "        cluster_threshold_pval=cluster_threshold_pval, cluster_threshold_fcfc=cluster_threshold_fcfc, take_median_ion=take_median_ion, outlier_correction=outlier_correction, normalize=normalize, \n",
    "        use_iontree_if_possible=use_iontree_if_possible, get_ion2clust=get_ion2clust,median_offset=median_offset, pre_normed_intensity_file=pre_normed_intensity_file , dia_fragment_selection=dia_fragment_selection,\n",
    "        runtime_plots=runtime_plots, volcano_fdr=volcano_fdr, volcano_fcthresh=volcano_fcthresh, annotation_file=annotation_file, use_ml = use_ml, protein_subset_for_normalization_file=protein_subset_for_normalization_file), condpair_combinations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import alphaquant.ptmsite_mapping as aqptm\n",
    "\n",
    "def write_ptm_mapped_input(input_file, results_dir, samplemap_file, modification_type):\n",
    "    try:\n",
    "        aqptm.assign_dataset_inmemory(input_file = input_file, results_dir=results_dir, samplemap=samplemap_file, modification_type=modification_type)\n",
    "    except:\n",
    "        aqptm.assign_dataset_chunkwise(input_file = input_file, results_dir=results_dir, samplemap=samplemap_file, modification_type=modification_type)\n",
    "    mapped_df = pd.read_csv(f\"{results_dir}/ptm_ids.tsv\", sep = \"\\t\")\n",
    "    ptm_mapped_file = aqptm.merge_ptmsite_mappings_write_table(input_file, mapped_df, modification_type)\n",
    "    return ptm_mapped_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def check_input_consistency(input_file, samplemap_file, unnormed_df, samplemap_df):\n",
    "    if (input_file is not None) and (samplemap_file is not None):\n",
    "        return True\n",
    "    elif (unnormed_df is not None) and (samplemap_df is not None):\n",
    "        return True\n",
    "    else:\n",
    "        raise Exception(\"inputs inconsistent! Either both files or both dataframes need to be specified!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "def get_unnormed_df_condpair(unnormed_df :pd.DataFrame, samplemap_df:pd.DataFrame,input_file:str, condpair:str) -> pd.DataFrame:\n",
    "    \"\"\"In the case that the total unnormed df does not fit into memory, attempt reloading the unnormed df for each condition pair\n",
    "\n",
    "    Args:\n",
    "        unnormed_df (pd.DataFrame): unnormed_dataframe that has been loaded (None if load was not successful)\n",
    "        samplemap_df (pd.DataFrame): sample mapping\n",
    "        input_file (str): path to file containing the unnormed df data\n",
    "        condpair (str): pair of conditions to be compared\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: unnormed dataframe per condition, in case the whole did not fit into memory\n",
    "    \"\"\"\n",
    "    if unnormed_df is not None:\n",
    "        return unnormed_df\n",
    "        \n",
    "    else:\n",
    "        samples_c1, samples_c2 = aqutils.get_samples_used_from_samplemap_df(samplemap_df=samplemap_df, cond1 = condpair[0], cond2 = condpair[1])\n",
    "        used_samples = samples_c1+samples_c2\n",
    "        unnormed_df = aqutils.import_data(input_file,samples_subset=used_samples)\n",
    "        unnormed_df, _ = aqutils.prepare_loaded_tables(unnormed_df, samplemap_df)\n",
    "        return unnormed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_per_condition_dataframes(samples_c1, samples_c2, unnormed_df, minrep):\n",
    "\n",
    "    min_samples = min(len(samples_c1), len(samples_c2))\n",
    "\n",
    "    if min_samples<2:\n",
    "        raise Exception(f\"condpair has not enough samples: c1:{len(samples_c1)} c2: {len(samples_c2)}, skipping\")\n",
    "\n",
    "    minrep_c1 = get_minrep_for_cond(samples_c1, minrep)\n",
    "    minrep_c2 = get_minrep_for_cond(samples_c2, minrep)\n",
    "    df_c1 = unnormed_df.loc[:, samples_c1].dropna(thresh=minrep_c1, axis=0)\n",
    "    df_c2 = unnormed_df.loc[:, samples_c2].dropna(thresh=minrep_c2, axis=0)\n",
    "    if (len(df_c1.index)<5) | (len(df_c2.index)<5):\n",
    "        raise Exception(f\"condpair has not enough data for processing c1: {len(df_c1.index)} c2: {len(df_c2.index)}, skipping\")\n",
    "        \n",
    "    return df_c1, df_c2\n",
    "\n",
    "def get_minrep_for_cond(c_samples, minrep):\n",
    "    if minrep is None: #in the case of None, no nans will be allowed\n",
    "        return None\n",
    "    num_samples = len(c_samples)\n",
    "    if num_samples<minrep:\n",
    "        return num_samples\n",
    "    else:\n",
    "        return minrep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_condpair_input(samplemap_df, condpair, minrep, input_df, input_file):\n",
    "\n",
    "    print(condpair)\n",
    "    samples_c1, samples_c2 = aqutils.get_samples_used_from_samplemap_df(samplemap_df, condpair[0], condpair[1])\n",
    "    \n",
    "    input_df_local = get_unnormed_df_condpair(input_df,samplemap_df,input_file, condpair)\n",
    "    pep2prot = dict(zip(input_df_local.index, input_df_local['protein']))\n",
    "\n",
    "    df_c1, df_c2 = get_per_condition_dataframes(samples_c1, samples_c2, input_df_local, minrep)\n",
    "    \n",
    "    return df_c1, df_c2, samples_c1, samples_c2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import alphaquant.background_distributions as aqbg\n",
    "import alphaquant.diff_analysis as aqdiff\n",
    "import alphaquant.normalization as aqnorm\n",
    "import alphaquant.visualizations as aqviz\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "import alphaquant.cluster_ions as aqclust\n",
    "import alphaquant.classify_ions as aqclass\n",
    "import anytree\n",
    "\n",
    "def analyze_condpair(*,samplemap_df,input_df, input_file,results_dir,condpair, minrep, min_num_ions, minpep,cluster_threshold_pval, cluster_threshold_fcfc, take_median_ion,outlier_correction, normalize, use_iontree_if_possible, \n",
    "get_ion2clust,median_offset, pre_normed_intensity_file, dia_fragment_selection, runtime_plots, volcano_fdr, volcano_fcthresh, annotation_file, use_ml, protein_subset_for_normalization_file):\n",
    "    t_zero = time()\n",
    "    print(f\"start processeing condpair {condpair}\")\n",
    "    prot2diffions = {}\n",
    "    p2z = {}\n",
    "    ion2clust = {}\n",
    "    protnodes = []\n",
    "    quantified_peptides = []\n",
    "    quantified_proteins = []\n",
    "\n",
    "    \n",
    "    input_df_local = get_unnormed_df_condpair(input_df,samplemap_df,input_file, condpair)\n",
    "    pep2prot = dict(zip(input_df_local.index, input_df_local['protein']))\n",
    "    c1_samples, c2_samples = aqutils.get_samples_used_from_samplemap_df(samplemap_df, condpair[0], condpair[1])\n",
    "\n",
    "    df_c1, df_c2 = get_per_condition_dataframes(c1_samples, c2_samples, input_df_local, minrep)\n",
    "\n",
    "    df_c1_normed, df_c2_normed = aqnorm.normalize_if_specified(df_c1 = df_c1, df_c2 = df_c2, c1_samples = c1_samples, c2_samples = c2_samples, minrep = minrep, normalize_within_conds = normalize, normalize_between_conds = normalize, \n",
    "    runtime_plots = runtime_plots, protein_subset_for_normalization_file=protein_subset_for_normalization_file, pep2prot = pep2prot,prenormed_file = pre_normed_intensity_file)#, \"./test_data/normed_intensities.tsv\")\n",
    "\n",
    "    if results_dir != None:\n",
    "        write_out_normed_df(df_c1_normed,df_c2_normed, pep2prot, results_dir, condpair)\n",
    "    t_normalized = time()\n",
    "    normed_c1 = aqbg.ConditionBackgrounds(df_c1_normed, p2z)\n",
    "    normed_c2 = aqbg.ConditionBackgrounds(df_c2_normed, p2z)\n",
    "\n",
    "    t_bgdist_fin = time()\n",
    "    ions_to_check = normed_c1.ion2nonNanvals.keys() & normed_c2.ion2nonNanvals.keys()\n",
    "    use_ion_tree = list(ions_to_check)[0].startswith(\"SEQ_\") & use_iontree_if_possible\n",
    "    bgpair2diffDist = {}\n",
    "    deedpair2doublediffdist = {}\n",
    "    count_ions=0\n",
    "    for ion in ions_to_check:\n",
    "        t_ion = time()\n",
    "        vals1 = normed_c1.ion2nonNanvals.get(ion)\n",
    "        vals2 = normed_c2.ion2nonNanvals.get(ion)\n",
    "        diffDist = aqbg.get_subtracted_bg(bgpair2diffDist,normed_c1, normed_c2,ion, p2z)\n",
    "        t_subtract_end = time()\n",
    "        diffIon = aqdiff.DifferentialIon(vals1, vals2, diffDist, ion, outlier_correction)\n",
    "        t_diffion = time()\n",
    "        protein = pep2prot.get(ion)\n",
    "        prot_ions = prot2diffions.get(protein, list())\n",
    "        prot_ions.append(diffIon)\n",
    "        prot2diffions[protein] = prot_ions\n",
    "        quantified_peptide = QuantifiedResult(kwargs = {'ion' : ion, 'pval' : diffIon.p_val, 'log2fc' : diffIon.fc, 'protein' : protein, 'condpair' : aqutils.get_condpairname(condpair)})\n",
    "        quantified_peptides.append(quantified_peptide)\n",
    "\n",
    "\n",
    "        if count_ions%2000==0:\n",
    "            print(f\"checked {count_ions} of {len(ions_to_check)} ions\")\n",
    "\n",
    "        count_ions+=1\n",
    "\n",
    "        t_iterfin = time()\n",
    "        #print(f\"t_init {t_subtract_start-t_ion} t_diffdist {t_subtract_end -t_subtract_start} t_diffion {t_iterfin - t_ion}\")\n",
    "    count_prots = 0\n",
    "    for prot in prot2diffions.keys():\n",
    "        ions = prot2diffions.get(prot)\n",
    "        if len(ions)<min_num_ions:\n",
    "            continue\n",
    "        diffprot = aqdiff.DifferentialProtein(prot, ions, median_offset, dia_fragment_selection)\n",
    "        if use_ion_tree:\n",
    "            clustered_root_node = aqclust.get_scored_clusterselected_ions(prot, ions, normed_c1, normed_c2, bgpair2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis = cluster_threshold_pval, fcfc_threshold = cluster_threshold_fcfc, take_median_ion=take_median_ion)\n",
    "            #print(anytree.RenderTree(clustered_root_node))\n",
    "            #if not clustered_root_node.is_included:\n",
    "             #   continue\n",
    "            protnodes.append(clustered_root_node)\n",
    "            pval, fc, consistency_score, ions_included = aqclust.get_diffresults_from_clust_root_node(clustered_root_node)\n",
    "            num_peptides = len(anytree.findall(clustered_root_node, filter_ = lambda x : x.type == 'seq'))\n",
    "            if num_peptides < minpep:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            pval, fc, consistency_score, ions_included = diffprot.pval, diffprot.fc, np.nan,diffprot.ions\n",
    "\n",
    "        if get_ion2clust:\n",
    "            ionclust_protein = aqclust.find_fold_change_clusters_base_ions([[x] for x in ions],normed_c1,normed_c2, bgpair2diffDist,p2z, deedpair2doublediffdist, fc_threshold=cluster_threshold_fcfc, pval_threshold_basis=cluster_threshold_pval)\n",
    "            ion2clust.update({x.name:y for x,y in ionclust_protein.items()})\n",
    "        \n",
    "        if count_prots%100==0:\n",
    "            print(f\"checked {count_prots} of {len(prot2diffions.keys())} prots\")\n",
    "        count_prots+=1\n",
    "\n",
    "        pseudoint1_cond, pseudoint2_cond = aqdiff.calc_pseudo_intensities(ions, normed_c2, diffprot.fc)\n",
    "        quantified_protein = QuantifiedResult(kwargs={'condpair': aqutils.get_condpairname(condpair), 'protein' : prot, 'fdr' : 1.0, 'pval':pval,'log2fc': fc, 'consistency_score' : consistency_score, 'num_ions' : len(ions_included), 'pseudoint1' : pseudoint1_cond, 'pseudoint2' : pseudoint2_cond})\n",
    "        quantified_proteins.append(quantified_protein)\n",
    "\n",
    "    if use_ion_tree:\n",
    "        if use_ml:\n",
    "            ml_performance_dict = {}\n",
    "            aqclass.assign_predictability_scores(protnodes, results_dir, name = aqutils.get_condpairname(condpair), samples_used = c1_samples+ c2_samples,precursor_cutoff=3, \n",
    "            fc_cutoff=0.5, number_splits=5, plot_predictor_performance=runtime_plots, replace_nans=True, performance_metrics=ml_performance_dict)\n",
    "            if ml_performance_dict[\"r2_score\"] >0.05: #only use the ml score, if it is meaningful\n",
    "                aqclust.update_nodes_w_ml_score(protnodes)\n",
    "                update_quantified_proteins_w_tree_results(quantified_proteins, protnodes)\n",
    "            aqclust.export_roots_to_json(protnodes,condpair,results_dir)\n",
    "    \n",
    "    add_fdr(quantified_proteins)\n",
    "    add_fdr(quantified_peptides)\n",
    "    \n",
    "    res_df = get_results_df(quantified_proteins)\n",
    "    pep_df = get_results_df(quantified_peptides)\n",
    "\n",
    "    if runtime_plots:\n",
    "        aqviz.volcano_plot(res_df, significance_cutoff = volcano_fdr, log2fc_cutoff = volcano_fcthresh)\n",
    "        aqviz.volcano_plot(pep_df,significance_cutoff = volcano_fdr, log2fc_cutoff = volcano_fcthresh)\n",
    "\n",
    "    if results_dir!=None:\n",
    "        if annotation_file != None: #additional annotations can be added before saving\n",
    "            annot_df = pd.read_csv(annotation_file, sep = \"\\t\")\n",
    "            intersect_columns = annot_df.columns.intersection(pep_df.columns)\n",
    "            if(len(intersect_columns)>0):\n",
    "                print(list(intersect_columns))\n",
    "                res_df = res_df.merge(annot_df, on=list(intersect_columns), how= 'left')\n",
    "                pep_df = pep_df.merge(annot_df, on= list(intersect_columns), how = 'left')\n",
    "        \n",
    "\n",
    "            \n",
    "        if get_ion2clust:\n",
    "            ion2clust_df = pd.DataFrame(ion2clust.items(), columns=['ion', 'cluster'])\n",
    "            ion2clust_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.ion2clust.tsv\", sep = \"\\t\", index=None)\n",
    "\n",
    "        res_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.results.tsv\", sep = \"\\t\", index=None)\n",
    "        pep_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.results.ions.tsv\", sep = \"\\t\", index=None)\n",
    "    \n",
    "\n",
    "\n",
    "    return res_df, pep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ion': 'ion', 'pval': 23, 'log2fc': 123.2, 'protein': 'protein', 'condpair': 'aqutils.get_condpairname(condpair)'}\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "#helper class to store diffresults\n",
    "class QuantifiedResult:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.propdict = None\n",
    "        if kwargs:\n",
    "            self.propdict = kwargs['kwargs']\n",
    "    def add_property(self, key, value):\n",
    "        self.propdict[key]  = value\n",
    "    def add_properties(self, dict):\n",
    "        self.propdict.update(dict)\n",
    "\n",
    "\n",
    "def update_quantified_proteins_w_tree_results(quantified_proteins, protnodes):\n",
    "    prot2fc = {x.name : x.fc for x in protnodes}\n",
    "    prot2pval = {x.name : x.p_val  for x in protnodes}\n",
    "    prot2predscore = {x.name : x.predscore for x in protnodes}\n",
    "    for quantified_protein in quantified_proteins:\n",
    "        protname = quantified_protein.propdict['protein']\n",
    "        quantified_protein.propdict['log2fc'] = prot2fc.get(protname)\n",
    "        quantified_protein.propdict['pval'] = prot2pval.get(protname)\n",
    "        quantified_protein.propdict['predscore'] = prot2predscore.get(protname)\n",
    "\n",
    "\n",
    "def add_fdr(quantified_results):\n",
    "    pvals = [x.propdict[\"pval\"] for x in quantified_results]\n",
    "    fdrs = mt.multipletests(pvals, method='fdr_bh', is_sorted=False, returnsorted=False)[1]\n",
    "    for idx in range(len(quantified_results)):\n",
    "        quantified_results[idx].propdict['fdr'] = fdrs[idx]\n",
    "\n",
    "def get_results_df(quantfied_results):\n",
    "    quantified_results_dicts = [x.propdict for x in quantfied_results]\n",
    "    res_df = pd.DataFrame(quantified_results_dicts)\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import os\n",
    "def write_out_normed_df(normed_df_1, normed_df_2, pep2prot, results_dir, condpair):\n",
    "    merged_df = normed_df_1.merge(normed_df_2, left_index = True, right_index = True)\n",
    "    merged_df = 2**merged_df\n",
    "    merged_df = merged_df.replace(np.nan, 0)\n",
    "    merged_df[\"protein\"] = list(map(lambda x : pep2prot.get(x),merged_df.index))\n",
    "    if not os.path.exists(f\"{results_dir}/\"):\n",
    "        os.makedirs(f\"{results_dir}/\")\n",
    "    merged_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.normed.tsv\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_normed_dfs(normed_df_1, normed_df_2, condpair):\n",
    "    merged_df = normed_df_1.merge(normed_df_2, left_index = True, right_index = True)\n",
    "    merged_df = 2**merged_df\n",
    "    merged_df = merged_df.replace(np.nan, 0)\n",
    "    merged_df[\"condpair\"] = condpair\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read in proteomics datafiles, log the intensities\n",
    "def read_tables(peptides_tsv, samplemap_tsv, pepheader = None, protheader = None):\n",
    "    samplemap = pd.read_csv(samplemap_tsv, sep=\"\\t\")\n",
    "    peps = pd.read_csv(peptides_tsv,sep=\"\\t\")\n",
    "\n",
    "    if pepheader != None:\n",
    "        peps = peps.rename(columns = {pepheader : \"ion\"})\n",
    "    if protheader != None:\n",
    "        peps = peps.rename(columns = {protheader: \"protein\"})\n",
    "    peps = peps.set_index(\"ion\")\n",
    "    headers = ['protein'] + samplemap[\"sample\"].to_list()\n",
    "\n",
    "    for sample in samplemap[\"sample\"]:\n",
    "        peps[sample] = np.log2(peps[sample].replace(0, np.nan))\n",
    "    return peps[headers], samplemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "\n",
    "def write_out_ion2nonan_ion2idx(cb, outfolder, condname):\n",
    "    \n",
    "    ion2nan_conv = [[a, x.tolist()] for a, x in cb.ion2nonNanvals.items()]\n",
    "    \n",
    "    ion2nan_df = pd.DataFrame(ion2nan_conv)\n",
    "    display(ion2nan_df)\n",
    "    print(ion2nan_df.iloc[41775, 1])\n",
    "    idx2ion_df = pd.DataFrame(list(cb.idx2ion.items()))\n",
    "\n",
    "    ion2nan_df.to_csv(f\"{outfolder}/ion2nonans_{condname}.tsv\", sep = \"\\t\", index = False)\n",
    "    idx2ion_df.to_csv(f\"{outfolder}/idx2ion_{condname}.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def compare_context_boundaries_against_ref(ref_file, cond_bg):\n",
    "    ref_bounds = pd.read_csv(ref_file, sep = \"\\t\", names = [\"l_ref\", \"u_ref\"])\n",
    "    ref_bounds[\"l\"] = pd.Series(np.array(cond_bg.context_ranges).T[0])\n",
    "    ref_bounds[\"u\"] = pd.Series(np.array(cond_bg.context_ranges).T[1])\n",
    "    ref_bounds[\"l-ref\"] = (ref_bounds[\"l_ref\"] / ref_bounds[\"l\"]).abs()\n",
    "    ref_bounds[\"u-ref\"] = (ref_bounds[\"u_ref\"] / ref_bounds[\"u\"]).abs()\n",
    "    display(ref_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "#protein_df, peptide_df = benchmark_proteomics(\"./test_data/peptides.txt\", \"./test_data/samples.map\", \"./test_data/prot2organism.tsv\")\n",
    "#protein_df.to_csv(\"./test_data/AP_protein_out.tsv\", sep = \"\\t\", index= False)\n",
    "#peptide_df.to_csv(\"./test_data/AP_peptide_out.tsv\", sep = \"\\t\", index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/Users/constantin/workspace/EmpiRe/nbdev/MS-EmpiRe_Python')\n",
    "# from alphaquant.background_distributions import *\n",
    "# from alphaquant.normalization import *\n",
    "# from alphaquant.diff_analysis import *\n",
    "# from alphaquant.visualizations import *\n",
    "# from alphaquant.benchmarking import *\n",
    "# from alphaquant.diffquant_utils import *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
