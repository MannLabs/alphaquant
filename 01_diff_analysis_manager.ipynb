{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# default_exp diff_analysis_manager"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "def run_pipeline_from_preconfigured_files(input_file, samplemap_file, results_dir = \".\", minrep = 2, condpair_combinations = None,outlier_correction = True, median_offset = False, pre_normed_intensity_file = None, dia_fragment_selection = False, runtime_plots = False, volcano_fdr =0.05, volcano_fcthresh = 0.5, annotation_file = None):\n",
    "    input_data = aqutils.import_data(input_file)\n",
    "    samplemap_df = aqutils.load_samplemap(samplemap_file)\n",
    "    input_processed, samplemap_df_processed = aqutils.prepare_loaded_tables(input_data, samplemap_df)\n",
    "    run_pipeline(input_processed, samplemap_df, results_dir, condpair_combinations,minrep, outlier_correction, median_offset, pre_normed_intensity_file, dia_fragment_selection, runtime_plots, volcano_fdr, volcano_fcthresh, annotation_file)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import statsmodels.stats.multitest as mt\n",
    "from time import time\n",
    "\n",
    "\n",
    "def run_pipeline(unnormed_df, labelmap_df, results_dir = \"./results\",  condpair_combinations = None, minrep = 2, min_num_ions = 1, minpep = 1, cluster_threshold_pval = 1e-3, cluster_threshold_fcfc = 0.5, take_median_ion = True,outlier_correction = True, normalize = True, use_iontree_if_possible = True,\n",
    "get_ion2clust = False, median_offset = False, pre_normed_intensity_file = None, dia_fragment_selection = False, runtime_plots = False, volcano_fdr =0.05, volcano_fcthresh = 0.5,annotation_file = None):\n",
    "    \"\"\"Run the differential analyses.\n",
    "    \"\"\"\n",
    "    \n",
    "    res_dfs = []\n",
    "    pep_dfs = []\n",
    "    pep2prot = dict(zip(unnormed_df.index, unnormed_df['protein']))\n",
    "\n",
    "    if condpair_combinations == None:\n",
    "        conds = labelmap_df[\"condition\"].unique()\n",
    "        condpair_combinations = combinations(conds, 2)\n",
    "        \n",
    "\n",
    "    for condpair in condpair_combinations:\n",
    "        print(condpair)\n",
    "        c1_samples = labelmap_df[labelmap_df[\"condition\"]== condpair[0]]\n",
    "        c2_samples = labelmap_df[labelmap_df[\"condition\"]== condpair[1]]\n",
    "        if (len(c1_samples.index)<2) | len(c2_samples.index)<2:\n",
    "            print(f\"condpair has not enough samples c1:{len(c1_samples)} c2: {len(c2_samples)}, skipping\")\n",
    "            continue\n",
    "        df_c1 = unnormed_df.loc[:, c1_samples[\"sample\"]].dropna(thresh=minrep, axis=0)\n",
    "        df_c2 = unnormed_df.loc[:, c2_samples[\"sample\"]].dropna(thresh=minrep, axis=0)\n",
    "        if (len(df_c1.index)<5) | (len(df_c2.index)<5):\n",
    "            print(f\"condpair has not enough data for processing c1: {len(df_c1.index)} c2: {len(df_c2.index)}, skipping\")\n",
    "            continue\n",
    "    \n",
    "        res, peps = analyze_condpair(df_c1, df_c2, c1_samples, c2_samples, pep2prot,results_dir,condpair, minrep, min_num_ions, minpep,cluster_threshold_pval, cluster_threshold_fcfc, take_median_ion,outlier_correction, normalize, use_iontree_if_possible, get_ion2clust,median_offset, pre_normed_intensity_file , dia_fragment_selection, \n",
    "        runtime_plots, volcano_fdr, volcano_fcthresh, annotation_file)\n",
    "        res_dfs.append(res)\n",
    "        pep_dfs.append(peps)\n",
    "    \n",
    "    res_df = pd.concat(res_dfs)\n",
    "    pep_df = pd.concat(pep_dfs)\n",
    "\n",
    "    return res_df, pep_df\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import alphaquant.background_distributions as aqbg\n",
    "import alphaquant.diff_analysis as aqdiff\n",
    "import alphaquant.normalization as aqnorm\n",
    "import alphaquant.visualizations as aqviz\n",
    "import alphaquant.diffquant_utils as aqutils\n",
    "import alphaquant.cluster_ions as aqclust\n",
    "import anytree\n",
    "\n",
    "\n",
    "def analyze_condpair(df_c1, df_c2, c1_samples, c2_samples, pep2prot, results_dir,condpair, minrep, min_num_ions, minpep,cluster_threshold_pval, cluster_threshold_fcfc, take_median_ion,outlier_correction, normalize, use_iontree_if_possible, get_ion2clust,median_offset, pre_normed_intensity_file, dia_fragment_selection, runtime_plots, volcano_fdr, volcano_fcthresh, annotation_file):\n",
    "    t_zero = time()\n",
    "    print(f\"start processeing condpair {condpair}\")\n",
    "    prot2diffions = {}\n",
    "    p2z = {}\n",
    "    ion2clust = {}\n",
    "    prots = []\n",
    "    iontrees = []\n",
    "    pvals = []\n",
    "    fdrs = []\n",
    "    fcs = []\n",
    "    consistency_scores = []\n",
    "    numions = []\n",
    "    peps = []\n",
    "    pep_pvals = []\n",
    "    pep_fdrs = []\n",
    "    pep_fcs = []\n",
    "    pep_prots = []\n",
    "    peps_included = []\n",
    "    pseudoint1 = []\n",
    "    pseudoint2 = []\n",
    "    condpairs = []\n",
    "\n",
    "    if normalize:\n",
    "        df_c1_normed, df_c2_normed = aqnorm.get_normalized_dfs(df_c1, df_c2, c1_samples, c2_samples, minrep, runtime_plots,pre_normed_intensity_file)#, \"./test_data/normed_intensities.tsv\")\n",
    "    else:\n",
    "        df_c1_normed = df_c1\n",
    "        df_c2_normed = df_c2\n",
    "    if results_dir != None:\n",
    "        write_out_normed_df(df_c1_normed,df_c2_normed, pep2prot, results_dir, condpair)\n",
    "    t_normalized = time()\n",
    "    normed_c1 = aqbg.ConditionBackgrounds(df_c1_normed, p2z)\n",
    "    #write_out_ion2nonan_ion2idx(normed_c1, \"./test_data/\", \"c1\")\n",
    "    normed_c2 = aqbg.ConditionBackgrounds(df_c2_normed, p2z)\n",
    "    #compare_context_boundaries_against_ref(\"./test_data/reference_context_boundaries_c2.tsv\",normed_c2)\n",
    "    #write_out_ion2nonan_ion2idx(normed_c2, \"./test_data/\", \"c2\")\n",
    "    t_bgdist_fin = time()\n",
    "    ions_to_check = normed_c1.ion2nonNanvals.keys() & normed_c2.ion2nonNanvals.keys()\n",
    "    use_ion_tree = list(ions_to_check)[0].startswith(\"SEQ_\") & use_iontree_if_possible\n",
    "    bgpair2diffDist = {}\n",
    "    deedpair2doublediffdist = {}\n",
    "    count_ions=0\n",
    "    for ion in ions_to_check:\n",
    "        t_ion = time()\n",
    "        vals1 = normed_c1.ion2nonNanvals.get(ion)\n",
    "        vals2 = normed_c2.ion2nonNanvals.get(ion)\n",
    "        diffDist = aqbg.get_subtracted_bg(bgpair2diffDist,normed_c1, normed_c2,ion, p2z)\n",
    "        t_subtract_end = time()\n",
    "        diffIon = aqdiff.DifferentialIon(vals1, vals2, diffDist, ion, outlier_correction)\n",
    "        t_diffion = time()\n",
    "        protein = pep2prot.get(ion)\n",
    "        prot_ions = prot2diffions.get(protein, list())\n",
    "        prot_ions.append(diffIon)\n",
    "        prot2diffions[protein] = prot_ions\n",
    "        peps.append(ion)\n",
    "        pep_pvals.append(diffIon.p_val)\n",
    "        pep_fcs.append(diffIon.fc)\n",
    "        pep_prots.append(protein)\n",
    "\n",
    "        if count_ions%2000==0:\n",
    "            print(f\"checked {count_ions} of {len(ions_to_check)} ions\")\n",
    "        \n",
    "        count_ions+=1\n",
    "\n",
    "        t_iterfin = time()\n",
    "        #print(f\"t_init {t_subtract_start-t_ion} t_diffdist {t_subtract_end -t_subtract_start} t_diffion {t_iterfin - t_ion}\")\n",
    "    count_prots = 0\n",
    "    for prot in prot2diffions.keys():\n",
    "        ions = prot2diffions.get(prot)\n",
    "        if len(ions)<min_num_ions:\n",
    "            continue\n",
    "        diffprot = aqdiff.DifferentialProtein(prot,ions, median_offset, dia_fragment_selection)\n",
    "        if use_ion_tree:\n",
    "            clustered_root_node = aqclust.get_scored_clusterselected_ions(prot, ions,normed_c1, normed_c2, bgpair2diffDist, p2z, deedpair2doublediffdist, pval_threshold_basis = cluster_threshold_pval, fcfc_threshold = cluster_threshold_fcfc, take_median_ion=take_median_ion)\n",
    "            #print(anytree.RenderTree(clustered_root_node))\n",
    "            #if not clustered_root_node.is_included:\n",
    "             #   continue\n",
    "            iontrees.append(clustered_root_node)\n",
    "            pval, fc, consistency_score, ions_included = aqclust.get_diffresults_from_clust_root_node(clustered_root_node)\n",
    "            num_peptides = len(anytree.findall(clustered_root_node, filter_ = lambda x : x.type == 'seq'))\n",
    "            if num_peptides < minpep:\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            pval, fc, consistency_score, ions_included = diffprot.pval, diffprot.fc, np.nan,diffprot.ions\n",
    "        \n",
    "        if get_ion2clust:\n",
    "            ionclust_protein = aqclust.find_fold_change_clusters_base_ions([[x] for x in ions],normed_c1,normed_c2, bgpair2diffDist,p2z, deedpair2doublediffdist, fc_threshold=cluster_threshold_fcfc, pval_threshold_basis=cluster_threshold_pval)\n",
    "            ion2clust.update({x.name:y for x,y in ionclust_protein.items()})\n",
    "        prots.append(prot)\n",
    "        pvals.append(pval)\n",
    "        fcs.append(fc)\n",
    "        consistency_scores.append(consistency_score)\n",
    "        numions.append(len(ions_included))\n",
    "        condpairs.append(aqutils.get_condpairname(condpair))\n",
    "        peps_included.extend(ions_included)\n",
    "        if count_prots%100==0:\n",
    "            print(f\"checked {count_prots} of {len(prot2diffions.keys())} prots\")\n",
    "        count_prots+=1\n",
    "    \n",
    "        pseudoint1_cond, pseudoint2_cond = aqdiff.calc_pseudo_intensities(ions, normed_c2, diffprot.fc)\n",
    "        pseudoint1.append(pseudoint1_cond)\n",
    "        pseudoint2.append(pseudoint2_cond)\n",
    "\n",
    "    fdrs = mt.multipletests(pvals, method='fdr_bh', is_sorted=False, returnsorted=False)[1]\n",
    "    pep_fdrs = mt.multipletests(pep_pvals, method='fdr_bh', is_sorted=False, returnsorted=False)[1]\n",
    "\n",
    "    res_df = pd.DataFrame({'condpair' : condpairs,'protein' : prots, 'fdr' : fdrs, 'pval':pvals, 'log2fc' : fcs, 'consistency_score' : consistency_scores,'num_ions' : numions, 'pseudoint1' :  pseudoint1, 'pseudoint2' : pseudoint2})\n",
    "    pep_df = pd.DataFrame({'condpair' : [aqutils.get_condpairname(condpair) for x in range(len(peps))], 'ion' : peps, 'protein' : pep_prots,'pval' : pep_pvals, 'log2fc' : pep_fcs})\n",
    "    pep_df[\"fdr\"] = pep_fdrs\n",
    "   # pep_df = pep_df[pep_df[\"ion\"].isin(peps_included)]\n",
    "\n",
    "    if runtime_plots:\n",
    "        aqviz.volcano_plot(res_df, significance_cutoff = volcano_fdr, log2fc_cutoff = volcano_fcthresh)\n",
    "        aqviz.volcano_plot(pep_df,significance_cutoff = volcano_fdr, log2fc_cutoff = volcano_fcthresh)\n",
    "\n",
    "    if results_dir!=None:\n",
    "        if annotation_file != None: #additional annotations can be added before saving\n",
    "            annot_df = pd.read_csv(annotation_file, sep = \"\\t\")\n",
    "            intersect_columns = annot_df.columns.intersection(pep_df.columns)\n",
    "            if(len(intersect_columns)>0):\n",
    "                print(list(intersect_columns))\n",
    "                res_df = res_df.merge(annot_df, on=list(intersect_columns), how= 'left')\n",
    "                pep_df = pep_df.merge(annot_df, on= list(intersect_columns), how = 'left')\n",
    "        if use_ion_tree:\n",
    "            aqclust.export_roots_to_json(iontrees,condpair,results_dir)\n",
    "        if get_ion2clust:\n",
    "            ion2clust_df = pd.DataFrame(ion2clust.items(), columns=['ion', 'cluster'])\n",
    "            ion2clust_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.ion2clust.tsv\", sep = \"\\t\", index=None)\n",
    "\n",
    "        res_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.results.tsv\", sep = \"\\t\", index=None)\n",
    "        pep_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.results.ions.tsv\", sep = \"\\t\", index=None)\n",
    "\n",
    "\n",
    "\n",
    "    return res_df, pep_df\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import os\n",
    "def write_out_normed_df(normed_df_1, normed_df_2, pep2prot, results_dir, condpair):\n",
    "    merged_df = normed_df_1.merge(normed_df_2, left_index = True, right_index = True)\n",
    "    merged_df = 2**merged_df\n",
    "    merged_df = merged_df.replace(np.nan, 0)\n",
    "    merged_df[\"protein\"] = list(map(lambda x : pep2prot.get(x),merged_df.index))\n",
    "    if not os.path.exists(f\"{results_dir}/\"):\n",
    "        os.makedirs(f\"{results_dir}/\")\n",
    "    merged_df.to_csv(f\"{results_dir}/{aqutils.get_condpairname(condpair)}.normed.tsv\", sep = \"\\t\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def merge_normed_dfs(normed_df_1, normed_df_2, condpair):\n",
    "    merged_df = normed_df_1.merge(normed_df_2, left_index = True, right_index = True)\n",
    "    merged_df = 2**merged_df\n",
    "    merged_df = merged_df.replace(np.nan, 0)\n",
    "    merged_df[\"condpair\"] = condpair\n",
    "    return merged_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read in proteomics datafiles, log the intensities\n",
    "def read_tables(peptides_tsv, samplemap_tsv, pepheader = None, protheader = None):\n",
    "    samplemap = pd.read_csv(samplemap_tsv, sep=\"\\t\")\n",
    "    peps = pd.read_csv(peptides_tsv,sep=\"\\t\")\n",
    "\n",
    "    if pepheader != None:\n",
    "        peps = peps.rename(columns = {pepheader : \"ion\"})\n",
    "    if protheader != None:\n",
    "        peps = peps.rename(columns = {protheader: \"protein\"})\n",
    "    peps = peps.set_index(\"ion\")\n",
    "    headers = ['protein'] + samplemap[\"sample\"].to_list()\n",
    "\n",
    "    for sample in samplemap[\"sample\"]:\n",
    "        peps[sample] = np.log2(peps[sample].replace(0, np.nan))\n",
    "    return peps[headers], samplemap"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "\n",
    "def write_out_ion2nonan_ion2idx(cb, outfolder, condname):\n",
    "    \n",
    "    ion2nan_conv = [[a, x.tolist()] for a, x in cb.ion2nonNanvals.items()]\n",
    "    \n",
    "    ion2nan_df = pd.DataFrame(ion2nan_conv)\n",
    "    display(ion2nan_df)\n",
    "    print(ion2nan_df.iloc[41775, 1])\n",
    "    idx2ion_df = pd.DataFrame(list(cb.idx2ion.items()))\n",
    "\n",
    "    ion2nan_df.to_csv(f\"{outfolder}/ion2nonans_{condname}.tsv\", sep = \"\\t\", index = False)\n",
    "    idx2ion_df.to_csv(f\"{outfolder}/idx2ion_{condname}.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def compare_context_boundaries_against_ref(ref_file, cond_bg):\n",
    "    ref_bounds = pd.read_csv(ref_file, sep = \"\\t\", names = [\"l_ref\", \"u_ref\"])\n",
    "    ref_bounds[\"l\"] = pd.Series(np.array(cond_bg.context_ranges).T[0])\n",
    "    ref_bounds[\"u\"] = pd.Series(np.array(cond_bg.context_ranges).T[1])\n",
    "    ref_bounds[\"l-ref\"] = (ref_bounds[\"l_ref\"] / ref_bounds[\"l\"]).abs()\n",
    "    ref_bounds[\"u-ref\"] = (ref_bounds[\"u_ref\"] / ref_bounds[\"u\"]).abs()\n",
    "    display(ref_bounds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#hide\n",
    "\n",
    "#protein_df, peptide_df = benchmark_proteomics(\"./test_data/peptides.txt\", \"./test_data/samples.map\", \"./test_data/prot2organism.tsv\")\n",
    "#protein_df.to_csv(\"./test_data/AP_protein_out.tsv\", sep = \"\\t\", index= False)\n",
    "#peptide_df.to_csv(\"./test_data/AP_peptide_out.tsv\", sep = \"\\t\", index= False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import sys\n",
    "# sys.path.append('/Users/constantin/workspace/EmpiRe/nbdev/MS-EmpiRe_Python')\n",
    "# from alphaquant.background_distributions import *\n",
    "# from alphaquant.normalization import *\n",
    "# from alphaquant.diff_analysis import *\n",
    "# from alphaquant.visualizations import *\n",
    "# from alphaquant.benchmarking import *\n",
    "# from alphaquant.diffquant_utils import *"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}