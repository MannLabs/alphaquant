{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import sys\n",
    "sys.path.append('/Users/constantin/workspace/EmpiRe/MS-EmpiRe_Python/')\n",
    "from ms_empire.diffquant_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_pvals(result_df):\n",
    "    pvals = result_df[\"peptide_pval\"].to_list()\n",
    "    plt.hist(pvals,99,cumulative=True,density=True, histtype='step')\n",
    "    x = np.linspace(0,1,100)\n",
    "    plt.plot(x, x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_bgdist(bgdist):\n",
    "    fc2counts_rescaled = tranform_fc2count_to_fc_space(bgdist.fc2counts, bgdist.cumulative[-1],1/100.0)\n",
    "    \n",
    "    plt.bar(list(fc2counts_rescaled.keys()), fc2counts_rescaled.values(),width=0.01,color='g')\n",
    "    axes2 = plt.twinx()\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    axes2.plot(x, norm.pdf(x, 0, bgdist.SD)/1.15)\n",
    "    axes2.set_ylim(0.0, 0.4)\n",
    "    plt.show()\n",
    "\n",
    "def tranform_fc2count_to_fc_space(fc2counts, num_fcs, rescale_factor):\n",
    "    fc2counts_fcscales = {}\n",
    "    for fc, count in fc2counts.items():\n",
    "        fc2counts_fcscales[fc*rescale_factor] = count/num_fcs\n",
    "\n",
    "    return fc2counts_fcscales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#interactive\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "def plot_betweencond_fcs(df_c1_normed, df_c2_normed, get_median):\n",
    "    if get_median:\n",
    "        df_c1_normed = df_c1_normed.median(axis = 1, skipna = True).to_frame()\n",
    "        df_c2_normed = df_c2_normed.median(axis = 1, skipna = True).to_frame()\n",
    "    both_idx = df_c1_normed.index.intersection(df_c2_normed.index)\n",
    "    df1 = df_c1_normed.loc[both_idx]\n",
    "    df2 = df_c2_normed.loc[both_idx]\n",
    "\n",
    "    for col1 in df1.columns:\n",
    "        for col2 in df2.columns:\n",
    "            diff_fcs = df1[col1].to_numpy() - df2[col2].to_numpy()\n",
    "            median = np.nanmedian(diff_fcs)\n",
    "            #plt.axvline(mode, color = 'blue')\n",
    "            plt.axvline(median, color = 'red')\n",
    "            plt.hist(diff_fcs,99,density=True, histtype='step', range=(-3.5,3.5))\n",
    "    plt.xlabel(\"log2(fc)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#interactive\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "def plot_withincond_fcs(df, xlim = None):\n",
    "    combs = list(itertools.combinations(df.columns, 2))\n",
    "    for cpair in combs:\n",
    "        col1 = cpair[0]\n",
    "        col2 = cpair[1]\n",
    "        diff_fcs = df[col1].to_numpy() - df[col2].to_numpy()\n",
    "        mode = stats.mode(diff_fcs, nan_policy='omit')[0][0]\n",
    "        median = np.nanmedian(diff_fcs)\n",
    "        #plt.axvline(mode, color = 'blue')\n",
    "        #plt.axvline(median, color = 'red')\n",
    "        plt.hist(diff_fcs,99,density=True, histtype='step',range=(-2,2))\n",
    "        plt.xlabel(\"log2 peptide fcs\")\n",
    "        \n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "def scatter_df_columns(merged_df, log_axes = False):\n",
    "    col = (0.2, 0.4, 0.6, 0.1)\n",
    "    ref_columns = list(filter(lambda x : \"_ref\" in x, merged_df.columns.to_list())) #filter the reference columns from the merged df\n",
    "\n",
    "    for ref in ref_columns:\n",
    "        compare = ref.replace(\"_ref\", \"\")\n",
    "        ax_p = merged_df.plot.scatter(x=ref,y=compare, color = col)\n",
    "        corr = merged_df[ref].corr(merged_df[compare])\n",
    "        plt.title(f\"{ref} vs. {compare} corr {corr}\")\n",
    "        x = np.linspace(0,merged_df[ref].max(),100)\n",
    "        plt.plot(x, x)\n",
    "        if log_axes:\n",
    "            plt.xscale('log')\n",
    "            plt.yscale('log')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_cumhist_dfcols(merged_df):\n",
    "    col = (0.2, 0.4, 0.6, 0.4)\n",
    "    ref_columns = list(filter(lambda x : \"_ref\" in x, merged_df.columns.to_list())) #filter the reference columns from the merged df\n",
    "\n",
    "    for ref in ref_columns:\n",
    "        compare = ref.replace(\"_ref\", \"\")\n",
    "        plt.hist(merged_df[ref], 100, density=True, histtype='step', label='reference')\n",
    "        plt.hist(merged_df[compare], 100, density=True, histtype='step',label='compare')\n",
    "        corr = merged_df[ref].corr(merged_df[compare])\n",
    "        plt.title(f\"{ref} vs. {compare} corr {corr}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib_venn import venn2\n",
    "from matplotlib import pyplot as plt\n",
    "def compare_peptid_protein_overlaps(protein_ref, protein_comp, peptide_ref, peptide_comp):\n",
    "    protIDs_ref = set(protein_ref[\"protein\"].to_list())\n",
    "    protIDs_comp = set(protein_comp[\"protein\"].to_list())\n",
    "    venn2([protIDs_ref, protIDs_comp], ('protIDs_ref', 'protIDs_comp'))\n",
    "    plt.show()\n",
    "    pepIDs_ref = set(peptide_ref[\"ion\"].to_list())\n",
    "    pepIDs_comp = set(peptide_comp[\"ion\"].to_list())\n",
    "    venn2([pepIDs_ref, pepIDs_comp], ('pepIDs_ref', 'pepIDs_comp'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_fold_change(df, key1, key2):\n",
    "    to_plot = df.copy()\n",
    "    to_plot[f'Ratio ({key1}/{key2})'] = np.log2(to_plot[key1] / to_plot[key2])\n",
    "    to_plot[f'Inten_{key1}'] = np.log10(to_plot[key1])\n",
    "\n",
    "    species = 'Human'\n",
    "    val = to_plot.loc[to_plot['species']==species, f'Ratio ({key1}/{key2})'].values\n",
    "    val = val[~np.isnan(val)&~np.isinf(val)&~np.isneginf(val)]\n",
    "    print(f'Species={species}, n={len(val)}, median={np.median(val)}, dev={np.std(val)}')\n",
    "    species='Ecoli'\n",
    "    val = to_plot.loc[to_plot['species']==species, f'Ratio ({key1}/{key2})'].values\n",
    "    val = val[~np.isnan(val)&~np.isinf(val)&~np.isneginf(val)]\n",
    "    print(f'species={species}, n={len(val)}, median={np.median(val)}, dev={np.std(val)}')\n",
    "\n",
    "    plt.figure(figsize=(7,7))\n",
    "    ax = sns.scatterplot(x=f'Ratio ({key1}/{key2})', y=f'Inten_{key1}', hue=\"species\", data=to_plot, alpha=0.5)\n",
    "    plt.title('Fold Change')\n",
    "    plt.xlim([-4.5, 6.5])\n",
    "    #plt.ylim([6,11.5])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#interactive\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def volcano_plot(result_df, fc_header = \"log2fc\", fdr_header = \"fdr\", significance_cutoff = 0.05, log2fc_cutoff = 0.5,ybound = None, xbound =None):\n",
    "    result_df[fdr_header] = result_df[fdr_header].replace(0, np.min(result_df[fdr_header].replace(0, 1.0)))\n",
    "    fdrs = result_df[fdr_header].to_numpy()\n",
    "    fcs = result_df[fc_header].to_numpy()\n",
    "    sighits_down = sum((fdrs<significance_cutoff) & (fcs <= -log2fc_cutoff))\n",
    "    sighits_up = sum((fdrs<significance_cutoff) & (fcs >= log2fc_cutoff))\n",
    "    plt.title(f\"{sighits_up} up, {sighits_down} down of {len(fcs)}\")\n",
    "    plt.scatter(result_df[fc_header],-np.log10(result_df[fdr_header]),s=10, c='grey', alpha = 0.1)\n",
    "    plt.xlabel('log2 FC',fontsize = 14)\n",
    "    plt.ylabel('-log10 FDR',fontsize = 14)\n",
    "\n",
    "    if ybound==None:\n",
    "        plt.ylim(0,max(-np.log10(result_df[fdr_header]))+0.5)\n",
    "    else:\n",
    "        plt.ylim(ybound)\n",
    "    if significance_cutoff>0:\n",
    "        plt.axhline(y=-np.log10(significance_cutoff), color='g', linestyle='-')\n",
    "    if log2fc_cutoff >0:\n",
    "        plt.axvline(x=log2fc_cutoff, color='g', linestyle='-')\n",
    "        plt.axvline(x=-log2fc_cutoff, color='g', linestyle='-')\n",
    "    maxfc = max(abs(result_df[fc_header]))+0.5\n",
    "    if xbound==None:\n",
    "        plt.xlim(-maxfc,maxfc)\n",
    "    else:\n",
    "        plt.xlim(xbound)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#interactive\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def beeswarm_ion_plot(protein,diffresults_df,normed_df, sample2cond,saveloc = None,ion_header = 'ion'):\n",
    "    diffresults_line = diffresults_df.loc[protein]\n",
    "    fdr = diffresults_line[\"fdr\"]\n",
    "    value_vars = set.intersection(set(normed_df.columns), set(sample2cond.keys()))\n",
    "    protein_df = normed_df.loc[[protein]]\n",
    "    df_melted = pd.melt(protein_df, value_vars= value_vars, id_vars=[ion_header], value_name=\"intensity\", var_name=\"sample\")\n",
    "    df_melted[\"condition\"] = [sample2cond.get(x) for x in df_melted[\"sample\"]]\n",
    "    pal2 = [(0.94, 0.94, 0.94),(1.0, 1.0, 1.0)]\n",
    "    ax = sns.boxplot(x=\"ion\", y=\"intensity\", hue=\"condition\", data=df_melted, palette=pal2)\n",
    "    ax = sns.swarmplot(x=\"ion\", y=\"intensity\", hue=\"condition\", data=df_melted, palette=\"Set2\", dodge=True)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    l = plt.legend(handles[2:4], labels[2:4])\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    if \"gene\" in diffresults_df.columns:\n",
    "        gene = diffresults_line[\"gene\"].values[0]\n",
    "        plt.title(f\"{gene} ({protein}) FDR: {fdr:e.1}\")\n",
    "    else:\n",
    "        plt.title(f\"{protein} FDR: {fdr:e}\")\n",
    "    if saveloc is not None:\n",
    "        plt.savefig(saveloc)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy.ma as ma\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "\n",
    "def compare_direction(array1, array2):\n",
    "    identical_elements  = array1 == array2\n",
    "    num_same_direction = np.sum(identical_elements)\n",
    "    return num_same_direction\n",
    "\n",
    "def compare_correlation(array1, array2):\n",
    "    corr = ma.corrcoef(ma.masked_invalid(array1), ma.masked_invalid(array2))[0][1]\n",
    "    return corr\n",
    "\n",
    "def get_condensed_distance_matrix(arrays, compare_function):\n",
    "\n",
    "    res = np.ones(int(len(arrays) * (len(arrays)-1)/2))\n",
    "    count = 0\n",
    "    for i in range(len(arrays)):\n",
    "        for j in range(i+1, len(arrays)):\n",
    "            array1 = arrays[i]\n",
    "            array2 = arrays[j]\n",
    "            distance = 1/compare_function(array1, array2)\n",
    "            res[count] = distance\n",
    "            count+=1\n",
    "\n",
    "    return res\n",
    "\n",
    "def clustersort_numerical_arrays(arrays, names , cluster_method ='average',compare_function = compare_direction):\n",
    "    condensed_distance_matrix = get_condensed_distance_matrix(arrays, compare_function)\n",
    "    linkage_matrix = hierarchy.linkage(condensed_distance_matrix, method = cluster_method)\n",
    "    sorted_array_idxs = hierarchy.leaves_list(linkage_matrix)\n",
    "\n",
    "    sorted_array = [arrays[x] for x in sorted_array_idxs]\n",
    "    sorted_names = [names[x] for x in sorted_array_idxs]\n",
    "    return sorted_array, sorted_names, linkage_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "def compare_direction(array1, array2):\n",
    "    identical_elements  = array1 == array2\n",
    "    num_same_direction = np.sum(identical_elements)\n",
    "    return num_same_direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy.ma as ma\n",
    "def compare_correlation(array1, array2):\n",
    "    corr = ma.corrcoef(ma.masked_invalid(array1), ma.masked_invalid(array2))[0][1]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import scipy.cluster.hierarchy as hierarchy\n",
    "import scipy.spatial.distance as dist\n",
    "def clustersort_numerical_arrays(arrays, names , cluster_method ='average',compare_function = compare_direction):\n",
    "    #condensed_distance_matrix = get_condensed_distance_matrix(arrays, compare_function)\n",
    "    condensed_distance_matrix = dist.pdist(arrays, lambda u, v: 1/(compare_function(u,v)+1))\n",
    "    linkage_matrix = hierarchy.linkage(condensed_distance_matrix, method = cluster_method)\n",
    "    sorted_array_idxs = hierarchy.leaves_list(linkage_matrix)\n",
    "\n",
    "    sorted_array = np.array([arrays[x] for x in sorted_array_idxs])\n",
    "    sorted_names = np.array([names[x] for x in sorted_array_idxs])\n",
    "    return sorted_array, sorted_names, linkage_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "def get_clustered_dataframe(overview_df, cluster_method ='average',compare_function = compare_direction, clust_rows = True, clust_columns = True):\n",
    "\n",
    "    df_numbered = overview_df.select_dtypes(include=np.number)\n",
    "    contains_floats = ['float' in str(x) for x in df_numbered.dtypes]\n",
    "    type = 'float' if True in contains_floats else 'int' \n",
    "    df_numbered = df_numbered.astype(type) #ensure that the df has no mixed types\n",
    "\n",
    "    rows = df_numbered.to_numpy()\n",
    "    rownames = list(df_numbered.index)\n",
    "    colnames = list(df_numbered.columns)\n",
    "\n",
    "    if clust_rows:\n",
    "        if(len(rownames)>10000):\n",
    "            print(f\"large number of rows, skipping cluster step of rows to avoid long runtime.\")\n",
    "        else:\n",
    "            print(f\"clustering on {len(rownames)} rows\")\n",
    "            rows, rownames, _ = clustersort_numerical_arrays(rows, rownames, cluster_method, compare_function)\n",
    "    if clust_columns:\n",
    "        if(len(colnames)>10000):\n",
    "            print(f\"large number of columns, skipping cluster step of columns to avoid long runtime\")\n",
    "        else:\n",
    "            print(f\"clustering on {len(colnames)} columns\")\n",
    "            columns, colnames,_ = clustersort_numerical_arrays(rows.T, colnames, cluster_method, compare_function)\n",
    "            rows = columns.T\n",
    "    print(\"finished clustering\")\n",
    "    df_clustered = pd.DataFrame(rows, index= rownames, columns= colnames ).reset_index()\n",
    "    return df_clustered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def get_heatmap(overview_df, diffresults_folder = os.path.join(\".\", \"diffresults\")):\n",
    "    clustered_df = get_clustered_dataframe(overview_df)\n",
    "    if diffresults_folder != None:\n",
    "        clustered_df.to_csv(os.path.join(diffresults_folder, \"regulation_overview.tsv\"), sep = \"\\t\", index = None)\n",
    "    plot_df = pd.melt(clustered_df, id_vars='index')\n",
    "    heatmap = hv.HeatMap(plot_df, label='Regulation overview')\n",
    "    return heatmap\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "import os\n",
    "def get_sample_overview_dataframe(diffresults_folder = os.path.join(\".\", \"diffresults\"), condpairs_to_compare = []):\n",
    "    \"\"\"\n",
    "    goes through the results folder and extracts up- and downregulated genes for each (specified) condition comparison\n",
    "    \"\"\"\n",
    "\n",
    "    if len(condpairs_to_compare) == 0:\n",
    "        condpairs_to_compare = [f.replace(\".results.tsv\", \"\").split(\"_VS_\") for f in os.listdir(diffresults_folder) if re.match(r'.*results.tsv', f)]\n",
    "\n",
    "    dfs = []\n",
    "    count = 0\n",
    "    for row in condpairs_to_compare:\n",
    "        c1 = row[0]\n",
    "        c2 = row[1]\n",
    "        results = initialize_result_dataframe(c1, c2, diffresults_folder)\n",
    "        if(type(results) == type(None)):\n",
    "            continue\n",
    "        site_df = results\n",
    "        positive_sites = list(set(site_df[(site_df[\"fdr\"]<0.05) & (site_df[\"log2fc\"]>0.5)][\"site_id\"]))\n",
    "        negative_sites = list(set(site_df[(site_df[\"fdr\"]<0.05) & (site_df[\"log2fc\"]<-0.5)][\"site_id\"]))\n",
    "        df_loc = pd.DataFrame([[1 for x in range(len(positive_sites))]+[-1 for x in range(len(negative_sites))]],columns=positive_sites+negative_sites)\n",
    "        df_loc[\"condpair\"] = get_condpairname([c1, c2])\n",
    "        #df_loc[\"num_regulated\"] = len(positive_sites) + len(negative_sites)\n",
    "        dfs.append(df_loc)\n",
    "        #print(count)\n",
    "        count+=1\n",
    "\n",
    "    result_df = pd.concat(dfs)\n",
    "    result_df = result_df.replace(np.nan, 0).set_index(\"condpair\")\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def initialize_result_dataframe(cond1, cond2, diffresults_folder = os.path.join(\".\", \"diffresults\")):\n",
    "    \"\"\"\n",
    "    reads the results dataframe for a given condpair\n",
    "    \"\"\"\n",
    "    condpair = get_condpairname([cond1, cond2])\n",
    "    diffresults = os.path.join(diffresults_folder, f\"{condpair}.results.tsv\")\n",
    "\n",
    "    try:\n",
    "        diffprots = pd.read_csv(diffresults, sep = \"\\t\")\n",
    "    except:\n",
    "        print(f\"no quantfiles found for {condpair}!\")\n",
    "        return None\n",
    "    diffprots = diffprots[(diffprots[\"condpair\"] == condpair)]\n",
    "\n",
    "    diffprots[\"-log10fdr\"] = -np.log10(diffprots[\"fdr\"])\n",
    "    diffprots = diffprots.set_index(\"protein\")\n",
    "    \n",
    "    return diffprots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def initialize_normed_peptides(cond1, cond2, diffresults_folder = os.path.join(\".\", \"diffresults\")):\n",
    "    \"\"\"\n",
    "    reads normed peptide data for a given condpair\n",
    "    \"\"\"\n",
    "    condpair = get_condpairname([cond1, cond2])\n",
    "    normed_peptides_tsv = os.path.join(diffresults_folder, f\"{condpair}.normed.tsv\")\n",
    "    try:\n",
    "        normed_peptides = pd.read_csv(normed_peptides_tsv, sep = \"\\t\")\n",
    "    except:\n",
    "        print(f\"no normed peptides found for {condpair}!\")\n",
    "        return None\n",
    "    \n",
    "    numeric_cols = list(normed_peptides.select_dtypes(include=np.number).columns)\n",
    "    #available_vals = list(set(samplemap_df[\"sample\"].values).intersection(set(normed_peptides.columns)))\n",
    "    normed_peptides[numeric_cols] = np.log2(normed_peptides[numeric_cols].replace(0, np.nan))\n",
    "    normed_peptides = normed_peptides.set_index(\"protein\")\n",
    "    return normed_peptides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "\n",
    "def initialize_sample2cond(samplemap):\n",
    "    samplemap_df = pd.read_csv(samplemap, sep = \"\\t\")\n",
    "    sample2cond = dict(zip(samplemap_df[\"sample\"], samplemap_df[\"condition\"]))\n",
    "    return samplemap_df, sample2cond"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
