{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp background_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConditionBackgrounds():\n",
    "\n",
    "    def __init__(self, normed_condition_df):\n",
    "        self.backgrounds = []\n",
    "        self.normed_condition_df = normed_condition_df\n",
    "        self.ion2background = {}\n",
    "        self.ion2nonNanvals = {}\n",
    "        self.init_ion2nonNanvals(self.normed_condition_df)\n",
    "        self.select_intensity_ranges()\n",
    "\n",
    "    def init_ion2nonNanvals(self, normed_condition_df):\n",
    "        for peptide, vals in normed_condition_df.iterrows():\n",
    "            self.ion2nonNanvals[peptide] = vals[vals.notna()].values\n",
    "\n",
    "\n",
    "    def select_intensity_ranges(self):\n",
    "        total_available_comparisons =0\n",
    "        num_contexts = 100\n",
    "        cumulative_counts = np.zeros(self.normed_condition_df.shape[0])\n",
    "\n",
    "        for idx ,count in enumerate(self.normed_condition_df.count(axis=1)):\n",
    "            total_available_comparisons+=count-1\n",
    "            cumulative_counts[idx] = int(total_available_comparisons/2)\n",
    "        \n",
    "        \n",
    "        #assign the context sizes\n",
    "        context_size = np.max([1000, int(total_available_comparisons/(1+num_contexts/2))])\n",
    "        halfcontext_size = int(context_size/2)\n",
    "        context_boundaries = np.zeros(3).astype(int)\n",
    "\n",
    "        middle_idx = int(np.searchsorted(cumulative_counts, halfcontext_size))\n",
    "        end_idx = int(np.searchsorted(cumulative_counts, context_size))\n",
    "\n",
    "\n",
    "        context_boundaries[0] = 0\n",
    "        context_boundaries[1] = middle_idx\n",
    "        context_boundaries[2] = end_idx\n",
    "        while context_boundaries[1] < len(cumulative_counts)-1:\n",
    "            self.backgrounds.append(BackGroundDistribution(context_boundaries[0], context_boundaries[2], self.ion2nonNanvals))\n",
    "            context_boundaries[0] = context_boundaries[1]\n",
    "            context_boundaries[1] = context_boundaries[2]\n",
    "            end_idx = np.searchsorted(cumulative_counts, context_size + cumulative_counts[context_boundaries[0]])\n",
    "            if end_idx > len(cumulative_counts)-(context_boundaries[1]-context_boundaries[0])/1.5:\n",
    "                end_idx = len(cumulative_counts)-1\n",
    "            context_boundaries[2] = end_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "\n",
    "class BackGroundDistribution:\n",
    "\n",
    "    fc_resolution_factor = 100\n",
    "    fc_conversion_factor = 1/fc_resolution_factor\n",
    "\n",
    "    def __init__(self, start_idx, end_idx, idx2noNanvals):\n",
    "        self.fc2counts = {} #binned Fold change Distribution\n",
    "        self.cumulative = np.array([])\n",
    "        self.zscores = np.array([])\n",
    "        self.min_fc =0\n",
    "        self.max_fc = 0\n",
    "        self.min_z=0\n",
    "        self.max_z=0\n",
    "        self.start_idx = int(start_idx)\n",
    "        self.end_idx = int(end_idx)\n",
    "        self.var = None\n",
    "        self.SD = None\n",
    "\n",
    "        anchor_fcs = self.generate_anchorfcs_from_intensity_range(idx2noNanvals)\n",
    "        shuffle(anchor_fcs)\n",
    "        self.generate_fc2counts_from_anchor_fcs(anchor_fcs)\n",
    "        self.cumulative = self.transform_fc2counts_into_cumulative()\n",
    "        self.calc_SD(0, self.cumulative)\n",
    "        self.zscores = self.transform_cumulative_into_z_values()\n",
    "\n",
    "    def generate_anchorfcs_from_intensity_range(self,idx2noNanvals):\n",
    "\n",
    "        anchor_fcs = []\n",
    "        for idx in range(self.start_idx, self.end_idx):\n",
    "            vals = idx2noNanvals[idx]\n",
    "            if vals.size < 2:\n",
    "                continue\n",
    "            anchor_idx =  np.random.randint(0, len(vals))\n",
    "            anchor_val = vals[anchor_idx]\n",
    "            vals = np.delete(vals, anchor_idx)\n",
    "            anchor_fcs.extend(vals-anchor_val)\n",
    "        return anchor_fcs\n",
    "\n",
    "\n",
    "    def generate_fc2counts_from_anchor_fcs(self,anchor_fcs):\n",
    "        \n",
    "        anchor_fcs = np.array(anchor_fcs)\n",
    "        for idx in range(1, anchor_fcs.shape[0]):\n",
    "            fc_binned = np.rint(self.fc_resolution_factor*(0.5*(anchor_fcs[idx-1] - anchor_fcs[idx]))).astype(np.long)\n",
    "            self.fc2counts[fc_binned] = self.fc2counts.setdefault(fc_binned, 0) + 1\n",
    "\n",
    "        self.min_fc = min(self.fc2counts.keys())\n",
    "        self.max_fc = max(self.fc2counts.keys())\n",
    "\n",
    "    \n",
    "    def transform_fc2counts_into_cumulative(self):\n",
    "        \n",
    "        cumulative = np.zeros(self.max_fc - self.min_fc +1).astype(np.long)\n",
    "\n",
    "        for entry in self.fc2counts.items():\n",
    "            cumulative[int(entry[0]-self.min_fc)] +=entry[1]\n",
    "        for idx in range(1,cumulative.shape[0]):\n",
    "            cumulative[idx] +=cumulative[idx-1]\n",
    "        \n",
    "        return cumulative\n",
    "\n",
    "    \n",
    "    def transform_cumulative_into_z_values(self):\n",
    "        total = self.cumulative[-1]\n",
    "        min_pval = 1/(total+1)\n",
    "        self.max_z = abs(norm.ppf(max(1e-9, min_pval)))\n",
    "        zscores = np.zeros(len(self.cumulative))\n",
    "        zero_pos = -self.min_fc\n",
    "\n",
    "        normfact_posvals = 1/(total-self.cumulative[zero_pos]+1)\n",
    "        normfact_negvals = 1/(self.cumulative[zero_pos-1]+1)\n",
    "        for i in range(len(self.cumulative)):\n",
    "            num_more_extreme = 0\n",
    "            if i == zero_pos:\n",
    "                zscores[i] = 0\n",
    "                continue\n",
    "            if i!=zero_pos and i<len(self.cumulative)-1:\n",
    "                num_more_extreme = self.cumulative[i] if i<zero_pos else  self.cumulative[-1] - self.cumulative[i+1]\n",
    "            \n",
    "            normfact = normfact_negvals if i<zero_pos else normfact_posvals\n",
    "            p_val = 0.5*max(1e-9, (num_more_extreme+1)*normfact)\n",
    "            sign = -1 if i<zero_pos else 1\n",
    "            zscores[i] = sign*norm.ppf(p_val) ##ppf is the inverese cumulative distribution function\n",
    "\n",
    "        return zscores\n",
    "\n",
    "\n",
    "    def calc_zscore_from_fc(self, fc):\n",
    "        if abs(fc)<1e-9:\n",
    "            return 0\n",
    "        k = int(fc * self.fc_resolution_factor)\n",
    "        rank = k-self.min_fc\n",
    "        if rank <0:\n",
    "            return -self.max_z\n",
    "        if rank >=len(self.cumulative):\n",
    "            return self.max_z\n",
    "        print(rank)\n",
    "        return self.zscores[rank]\n",
    "\n",
    "\n",
    "    def calc_SD(self, mean, cumulative):\n",
    "        sq_err = 0.0\n",
    "        previous =0\n",
    "        for i in range(len(cumulative)):\n",
    "            fc = (i+self.min_fc)*self.fc_conversion_factor\n",
    "            sq_err += (cumulative[i] - previous)*(fc-mean)**2\n",
    "            previous = cumulative[i]\n",
    "        total = cumulative[-1]\n",
    "        var = sq_err/total\n",
    "        self.var = var\n",
    "        self.SD = math.sqrt(var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#subtract two Empirical Backgrounds\n",
    "from scipy.stats import norm\n",
    "class SubtractedBackgrounds(BackGroundDistribution):\n",
    "\n",
    "    def __init__(self, from_dist, to_dist):\n",
    "        self.max_fc = None\n",
    "        self.min_fc = None\n",
    "        self.cumulative = None\n",
    "        self.subtract_distribs(from_dist, to_dist)\n",
    "        self.fc2counts = transform_cumulative_into_fc2count(self.cumulative,self.min_fc)\n",
    "        self.calc_SD(0, self.cumulative)\n",
    "        self.zscores = self.transform_cumulative_into_z_values()\n",
    "        \n",
    "    def subtract_distribs(self,from_dist, to_dist):\n",
    "        min_joined = from_dist.min_fc - to_dist.max_fc\n",
    "        max_joined = from_dist.max_fc - to_dist.min_fc\n",
    "\n",
    "        n_from = get_normed_freqs(from_dist.cumulative)\n",
    "        n_to = get_normed_freqs(to_dist.cumulative)\n",
    "\n",
    "        min_from = from_dist.min_fc\n",
    "        min_to = to_dist.min_fc\n",
    "\n",
    "        joined = np.zeros(max_joined-min_joined+1, dtype=\"long\")\n",
    "        \n",
    "        count_comparisons =0\n",
    "        for from_idx in range(len(n_from)):\n",
    "            fc_from = min_from + from_idx\n",
    "            freq_from = n_from[from_idx]\n",
    "            for to_idx in range(len(n_to)):\n",
    "                fc_to = min_to + to_idx\n",
    "                freq_to = n_to[to_idx]\n",
    "                fcdiff = fc_from - fc_to\n",
    "                joined_idx = fcdiff - min_joined\n",
    "                freq_multiplied = freq_from*freq_to\n",
    "                joined[joined_idx] += (freq_multiplied)\n",
    "                count_comparisons+=1\n",
    "        self.max_fc = max_joined\n",
    "        self.min_fc = min_joined\n",
    "        self.cumulative = get_cumul_from_freq(joined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "def test_subtract_distribs():\n",
    "    from_dist = [1,1,2,1,1]\n",
    "    to_dist = [1,1,2,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#get normalized freqs from cumulative\n",
    "\n",
    "def get_normed_freqs(cumulative):\n",
    "    normfact = 1e5 /cumulative[-1]\n",
    "    freqs =get_freq_from_cumul(cumulative)\n",
    "    for i in range(len(freqs)):\n",
    "        freqs[i] *= normfact\n",
    "    return freqs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#transform cumulative into frequency\n",
    "\n",
    "def get_freq_from_cumul(cumulative):\n",
    "    res = np.zeros(len(cumulative), dtype=\"long\")\n",
    "    res[0] = cumulative[0]\n",
    "    for i in range(1,len(cumulative)):\n",
    "        res[i] = cumulative[i]-cumulative[i-1]\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def transform_cumulative_into_fc2count(cumulative, min_fc):\n",
    "    res = {}\n",
    "    for idx in range(1, len(cumulative)):\n",
    "        fc = idx + min_fc\n",
    "        res[fc] = cumulative[idx] - cumulative[idx-1]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_cumul_from_freq(freq):\n",
    "    res = np.zeros(len(freq), dtype=\"long\")\n",
    "    res[0] = freq[0]\n",
    "    for i in range(1,len(freq)):\n",
    "        res[i] = res[i-1] + freq[i]\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test subtract background distribution\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx2nonnanvals = {}\n",
    "\n",
    "for idx in range(2000):\n",
    "    nonnanvals =  np.random.normal(loc=0, size=3)\n",
    "    idx2nonnanvals[idx] = nonnanvals\n",
    "    \n",
    "bgdist1 = BackGroundDistribution(0, 999, idx2nonnanvals)\n",
    "bgdist2 = BackGroundDistribution(1000, 1999, idx2nonnanvals)\n",
    "\n",
    "freqdist = get_normed_freqs(bgdist1.cumulative)\n",
    "plt.bar(range(len(freqdist)),freqdist,width=1,color='g')\n",
    "plt.show()\n",
    "\n",
    "subtracted_bgs = SubtractedBackgrounds(bgdist1, bgdist2)\n",
    "\n",
    "def tranform_fc2count_to_fc_space(fc2counts, num_fcs, rescale_factor):\n",
    "    fc2counts_fcscales = {}\n",
    "    for fc, count in fc2counts.items():\n",
    "        fc2counts_fcscales[fc*rescale_factor] = count/num_fcs\n",
    "\n",
    "    return fc2counts_fcscales\n",
    "\n",
    "fc2counts_rescaled = tranform_fc2count_to_fc_space(subtracted_bgs.fc2counts, subtracted_bgs.cumulative[-1],1/100.0)\n",
    "\n",
    "plt.bar(list(fc2counts_rescaled.keys()), fc2counts_rescaled.values(),width=0.01,color='g')\n",
    "axes2 = plt.twinx()\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "axes2.plot(x, norm.pdf(x, 0, subtracted_bgs.SD)*1.3, color = \"red\")\n",
    "axes2.set_ylim(0.0, 0.4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test background distribution\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "idx2nonnanvals = {}\n",
    "\n",
    "for idx in range(100000):\n",
    "    nonnanvals =  np.random.normal(loc=0, size=3)\n",
    "    idx2nonnanvals[idx] = nonnanvals\n",
    "    \n",
    "bgdist = BackGroundDistribution(0, 99999, idx2nonnanvals)\n",
    "\n",
    "def tranform_fc2count_to_fc_space(fc2counts, num_fcs, rescale_factor):\n",
    "    fc2counts_fcscales = {}\n",
    "    for fc, count in fc2counts.items():\n",
    "        fc2counts_fcscales[fc*rescale_factor] = count/num_fcs\n",
    "\n",
    "    return fc2counts_fcscales\n",
    "\n",
    "fc2counts_rescaled = tranform_fc2count_to_fc_space(bgdist.fc2counts, bgdist.cumulative[-1],1/100.0)\n",
    "\n",
    "plt.bar(list(fc2counts_rescaled.keys()), fc2counts_rescaled.values(),width=0.01,color='g',)\n",
    "axes2 = plt.twinx()\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "axes2.plot(x, norm.pdf(x, 0, bgdist.SD)/1.15)\n",
    "axes2.set_ylim(0.0, 0.4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
